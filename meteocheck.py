'''
*
* PROJET : MeteoCheck
* AUTEUR : Rymentz
* VERSIONS : v2.0.1
* NOTES : None
*
'''
import os
import pandas as pd
import asyncio
import datetime
import aiofiles
import aiohttp # UtilisÃ© pour les requÃªtes HTTP asynchrones
import sys
import traceback
import configparser
import json
import pytz # Pour la gestion des fuseaux horaires
import logging # Ajout pour un meilleur logging
import matplotlib
matplotlib.use('Agg')  # Backend non-interactif pour serveurs
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import seaborn as sns
import numpy as np
import io
import calendar
import math
from datetime import datetime as dt

# Configuration style moderne pour les graphiques
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

# Configuration des polices pour Ã©viter les warnings emoji
import warnings
import matplotlib.font_manager as fm

# DÃ©sactiver les warnings spÃ©cifiques aux glyphes manquants de maniÃ¨re plus robuste
warnings.filterwarnings('ignore', category=UserWarning, module='matplotlib.font_manager')
warnings.filterwarnings('ignore', category=UserWarning, message='.*Glyph.*missing.*')
warnings.filterwarnings('ignore', category=UserWarning, message='.*\\\\N.*missing.*')

# Function pour remplacer les emojis par des alternatives textuelles pour matplotlib
def replace_emojis_for_matplotlib(text):
    """Remplace les emojis par des alternatives textuelles pour Ã©viter les warnings matplotlib."""
    emoji_replacements = {
        # Emojis mÃ©tÃ©o de base
        'ğŸ“…': '[Cal]',
        'ğŸŒ§ï¸': '[Rain]',
        'ğŸ“Š': '[Chart]',
        'ğŸŸ£': '[Dot]',
        'â˜€ï¸': '[Sun]',
        'â„ï¸': '[Snow]',
        'ğŸ”¥': '[Fire]',
        'ğŸŒ¡ï¸': '[Temp]',
        'ğŸ’¨': '[Wind]',
        'ğŸˆ': '[Press]',
        'ğŸ’¦': '[Humid]',
        'ğŸŒ¦ï¸': '[Weather]',
        'ğŸ†': '[Trophy]',
        'ğŸ”®': '[Crystal]',
        'ğŸ“ˆ': '[Up]',
        'ğŸ“‰': '[Down]',
        'ğŸ“': '[Pin]',
        'ğŸŒ¤ï¸': '[PartCloud]',
        'ğŸŒ¸': '[Spring]',
        'ğŸ‚': '[Autumn]',
        'ğŸ–ï¸': '[Weekend]',
        'ğŸŒ…': '[Day]',
        'ğŸ’§': '[Drop]',
        'ğŸœï¸': '[Dry]',
        'ğŸ”´': '[Red]',
        'ğŸŸ¦': '[Blue]',
        'ğŸ’™': '[LBlue]',
        'âš ï¸': '[Warning]',
        'ğŸ’€': '[Danger]',
        'ğŸŒªï¸': '[Storm]',
        'ğŸ¥µ': '[Hot]',
        'ğŸ¥¶': '[Cold]',
        'ğŸŒ¬ï¸': '[WindStrong]',
        'ğŸƒ': '[WindLight]',
        'ğŸŒŠ': '[Wave]',
        
        # Emojis d'alerte et time
        'ğŸš¨': '[Alert]',
        'â°': '[Clock]',
        'â±ï¸': '[Timer]',
        'ğŸ¤–': '[Bot]',
        'ğŸ”§': '[Tool]',
        'ğŸ¯': '[Target]',
        'ğŸŒ‚': '[Umbrella]',
        'ğŸŒˆ': '[Rainbow]',
        
        # Formes et couleurs
        'ğŸ”µ': '[BlueDot]',
        'ğŸŸ¨': '[Yellow]',
        'ğŸŸ©': '[Green]',
        'ğŸŸª': '[Purple2]',
        'âš«': '[Black]',
        'âšª': '[White]',
        'ğŸ”¶': '[OrangeDiam]',
        'ğŸ”·': '[BlueDiam]',
        'ğŸ”¸': '[SmallOrangeDiam]',
        'ğŸ”¹': '[SmallBlueDiam]',
        'ğŸ”º': '[RedTriUp]',
        'ğŸ”»': '[RedTriDown]',
        'ğŸ’': '[Diamond]',
        'ğŸ”±': '[Trident]',
        'â­•': '[Circle]',
        'âŒ': '[X]',
        'â“': '[Question]',
        'â—': '[Exclamation]',
        'ğŸ’¯': '[100]',
        
        # ContrÃ´les et tech
        'ğŸ†”': '[ID]',
        'ğŸ†˜': '[SOS]',
        'ğŸ…°ï¸': '[A]',
        'ğŸ…±ï¸': '[B]',
        'ğŸ†': '[AB]',
        'ğŸ…¾ï¸': '[O]',
        'ğŸ”€': '[Shuffle]',
        'ğŸ”': '[Repeat]',
        'ğŸ”‚': '[RepeatOne]',
        'â­ï¸': '[NextTrack]',
        'â¯ï¸': '[PlayPause]',
        'â¹ï¸': '[Stop]',
        'âºï¸': '[Record]',
        'ğŸ¦': '[Cinema]',
        'ğŸ”…': '[DimBright]',
        'ğŸ”†': '[BrightUp]',
        'ğŸ“¶': '[Signal]',
        'ğŸ“³': '[Vibrate]',
        'ğŸ“´': '[PhoneOff]',
        
        # Symboles divers
        'â™€ï¸': '[Female]',
        'â™‚ï¸': '[Male]',
        'âš•ï¸': '[Medical]',
        'â™»ï¸': '[Recycle]',
        'âšœï¸': '[FleurDeLis]',
        'ğŸ”°': '[Beginner]',
        'ğŸ“›': '[NameBadge]',
        'â‡ï¸': '[Sparkle]',
        'âœ³ï¸': '[EightSpoke]',
        'â': '[CrossMark]',
        'ğŸŒ€': '[Cyclone]',
        'ğŸ’¤': '[Sleep]',
        'â™¨ï¸': '[HotSprings]',
        'ğŸ’«': '[Dizzy]',
        'ğŸŒŸ': '[GlowStar]',
        'â­': '[Star]',
        'ğŸŒ™': '[CrescentMoon]',
        'â˜„ï¸': '[Comet]',
        'ğŸŒ': '[EarthAfrica]',
        'ğŸŒ': '[EarthAmericas]',
        'ğŸŒ': '[EarthAsia]',
        'ğŸŒ‹': '[Volcano]',
        'ğŸ—»': '[MountFuji]',
        'ğŸ”ï¸': '[SnowMountain]',
        'ğŸŒ„': '[SunriseMountain]',
        'ğŸŒ†': '[Cityscape]',
        'ğŸŒ‡': '[Sunset]',
        'ğŸŒ‰': '[BridgeNight]',
        'ğŸŒŒ': '[MilkyWay]',
        'ğŸ†': '[Fireworks]',
        'ğŸ‡': '[Sparkler]',
        'ğŸŒƒ': '[NightStars]',
        'ğŸ™ï¸': '[Cityscape2]',
        'ğŸŒ ': '[ShootingStar]',
        
        # Emojis de direction
        'â†—ï¸': '[UpRight]',
        'â†˜ï¸': '[DownRight]',
        'â¡ï¸': '[Right]',
        
        # Emojis de nature/saisons
        'â˜ï¸': '[Cloud]',
        'ğŸŒ¥': '[CloudSun]',
        'â›…': '[PartlyCloudy]',
        
        # Coeurs et sentiments
        'ğŸ’›': '[YellowHeart]',
        'ğŸ’œ': '[PurpleHeart]',
        'ğŸ’š': '[GreenHeart]',
        'â¤ï¸': '[RedHeart]'
    }
    
    result = str(text)
    for emoji, replacement in emoji_replacements.items():
        result = result.replace(emoji, replacement)
    return result

# Trouver une police systÃ¨me qui supporte mieux les caractÃ¨res Unicode
available_fonts = [f.name for f in fm.fontManager.ttflist]
emoji_compatible_fonts = ['Segoe UI Emoji', 'Apple Color Emoji', 'Noto Color Emoji', 'Arial Unicode MS', 'DejaVu Sans', 'Liberation Sans']
selected_font = 'sans-serif'  # Fallback par dÃ©faut

for font in emoji_compatible_fonts:
    if font in available_fonts:
        selected_font = font
        break

plt.rcParams.update({
    'figure.facecolor': '#f8f9fa',
    'axes.facecolor': '#ffffff',
    'axes.edgecolor': '#dee2e6',
    'axes.linewidth': 0.8,
    'axes.grid': True,
    'grid.color': '#e9ecef',
    'grid.alpha': 0.6,
    'font.family': ['sans-serif'],
    'font.sans-serif': [selected_font, 'DejaVu Sans', 'Liberation Sans', 'Arial'],
    'font.size': 10,
    'axes.titlesize': 14,
    'axes.labelsize': 11,
    'xtick.labelsize': 9,
    'ytick.labelsize': 9,
    'legend.fontsize': 10,
    'figure.titlesize': 16,
    'axes.unicode_minus': False,  # Ã‰viter les problÃ¨mes avec les caractÃ¨res Unicode
    'text.usetex': False  # DÃ©sactiver LaTeX qui peut causer des problÃ¨mes avec Unicode
})

# Imports spÃ©cifiques Ã  aiogram 3.x
from aiogram import Bot, Dispatcher, types, Router
from aiogram.fsm.storage.memory import MemoryStorage
from aiogram.fsm.context import FSMContext # Si vous prÃ©voyez d'utiliser FSM plus tard
from aiogram.filters import Command
from aiogram.exceptions import TelegramAPIError # Pour la gestion des erreurs de l'API Telegram
from aiogram.types import BufferedInputFile # Pour l'envoi de fichiers en mÃ©moire

# Configuration and setup
script_dir = os.path.dirname(os.path.realpath(__file__))
os.chdir(script_dir)
config_path = os.path.join(script_dir, 'config.ini')

config = configparser.ConfigParser()
config.read(config_path)

TOKEN_TELEGRAM = config['KEYS']['TELEGRAM_BOT_TOKEN']
VILLE = config['LOCATION']['VILLE']
LATITUDE = config['LOCATION']['LATITUDE']
LONGITUDE = config['LOCATION']['LONGITUDE']

weather_url = f"https://api.open-meteo.com/v1/forecast?latitude={LATITUDE}&longitude={LONGITUDE}&hourly=temperature_2m,precipitation_probability,precipitation,pressure_msl,windspeed_10m,uv_index,relativehumidity_2m&timezone=GMT&forecast_days=2&past_days=2&models=best_match&timeformat=unixtime"

# ================================
# SYSTÃˆME DE CACHE PRÃ‰VISIONS
# ================================
cached_forecast_data = {
    'df_seven_hours': pd.DataFrame(),
    'df_twenty_four_hours': pd.DataFrame(),
    'last_update': None,
    'cache_duration_minutes': 5  # Cache valide pendant 5 minutes
}

def is_cache_valid():
    """VÃ©rifie si le cache des prÃ©visions est encore valide."""
    if cached_forecast_data['last_update'] is None:
        return False
    
    now = pd.Timestamp.now(tz='UTC')
    time_since_update = (now - cached_forecast_data['last_update']).total_seconds() / 60
    return time_since_update < cached_forecast_data['cache_duration_minutes']

async def get_cached_forecast_data():
    """Retourne les donnÃ©es de prÃ©vision depuis le cache si valide, sinon depuis l'API."""
    if is_cache_valid():
        # Cache valide, retourner les donnÃ©es stockÃ©es
        return (cached_forecast_data['df_seven_hours'].copy(),
                cached_forecast_data['df_twenty_four_hours'].copy())
    else:
        # Cache expirÃ©, appeler l'API et mettre Ã  jour le cache
        await log_message("Cache des prÃ©visions expirÃ©, rÃ©cupÃ©ration depuis l'API...")
        df_seven, df_twenty_four = await get_weather_data()
        
        # Mettre Ã  jour le cache
        cached_forecast_data['df_seven_hours'] = df_seven.copy()
        cached_forecast_data['df_twenty_four_hours'] = df_twenty_four.copy()
        cached_forecast_data['last_update'] = pd.Timestamp.now(tz='UTC')
        
        await log_message(f"Cache des prÃ©visions mis Ã  jour avec {len(df_seven)} + {len(df_twenty_four)} entrÃ©es")
        return df_seven, df_twenty_four

# Initialisation du Bot et du Dispatcher pour aiogram 3.x
bot = Bot(token=TOKEN_TELEGRAM)
storage = MemoryStorage()
dp = Dispatcher(storage=storage)
router = Router() # CrÃ©ation d'un routeur principal pour les handlers

csv_filename = "weather_data.csv"

# Initialize CSV file if not exists
if not os.path.exists(csv_filename):
    df_initial = pd.DataFrame(columns=['time', 'temperature_2m', 'precipitation_probability', 'precipitation', 'pressure_msl', 'windspeed_10m', 'uv_index', 'relativehumidity_2m'])
    df_initial.to_csv(csv_filename, index=False)

# Logging functions
def log_uncaught_exceptions(exc_type, exc_value, exc_traceback):
    error_message = "".join(traceback.format_exception(exc_type, exc_value, exc_traceback))
    try:
        # Essayer d'obtenir la boucle d'Ã©vÃ©nements en cours pour y soumettre la tÃ¢che de log
        loop = asyncio.get_running_loop()
        loop.create_task(log_message(f"Uncaught exception: {error_message}"))
    except RuntimeError:  # Aucune boucle d'Ã©vÃ©nements en cours (par exemple, si l'erreur se produit trÃ¨s tÃ´t)
        # ExÃ©cuter de maniÃ¨re synchrone comme fallback (crÃ©e une nouvelle boucle temporaire)
        asyncio.run(log_message(f"Uncaught exception (no running loop): {error_message}"))

sys.excepthook = log_uncaught_exceptions

async def log_message(message: str):
    async with aiofiles.open("log_meteocheck.log", mode='a', encoding='utf-8') as f:
        await f.write(f"{datetime.datetime.now(pytz.UTC)} - {message}\n")

def clean_csv_file():
    try:
        df = pd.read_csv(csv_filename)
        if df.empty:
            print("Fichier CSV vide, rien Ã  nettoyer.")
            return

        correct_columns = ['time', 'temperature_2m', 'precipitation_probability', 'precipitation', 'pressure_msl', 'windspeed_10m', 'uv_index', 'relativehumidity_2m']
        
        df = df.reindex(columns=correct_columns)
        
        # S'assurer que la colonne 'time' existe avant de la manipuler
        if 'time' in df.columns:
            df['time'] = df['time'].astype(str).str.replace(' ', 'T', regex=False).str.replace('+00:00', 'Z', regex=False)
            df['time'] = pd.to_datetime(df['time'], utc=True, errors='coerce')
            
            invalid_entries = df['time'].isna().sum()
            df = df.dropna(subset=['time'])
            if invalid_entries > 0:
                print(f"{invalid_entries} entrÃ©es invalides supprimÃ©es du CSV aprÃ¨s conversion de date.")
            
            df = df.sort_values('time')
            df['time'] = df['time'].dt.strftime('%Y-%m-%dT%H:%M:%SZ')
        else:
            print("Colonne 'time' manquante dans le CSV. Impossible de nettoyer les dates.")

        df.to_csv(csv_filename, index=False)
        print("Fichier CSV nettoyÃ© avec succÃ¨s.")
    except pd.errors.EmptyDataError:
        print("Fichier CSV vide ou mal formatÃ© lors du nettoyage.")
    except Exception as e:
        print(f"Erreur lors du nettoyage du fichier CSV : {str(e)}")
        # Log l'erreur pour un dÃ©bogage plus facile
        asyncio.run(log_message(f"Erreur critique lors du nettoyage du CSV: {str(e)}"))


# Alert tracking
sent_alerts = {
    'temperature': None,
    'precipitation': None,
    'windspeed': None,
    'uv_index': None,
    'pressure_msl': None,
    'data_freshness': None  # Pour tracking des alertes de fraÃ®cheur des donnÃ©es
}

# Advanced record tracking system
predicted_records = {
    'temperature_2m': {'max': {}, 'min': {}},
    'precipitation': {'max': {}},
    'windspeed_10m': {'max': {}},
    'pressure_msl': {'max': {}},
    'uv_index': {'max': {}}
}

# Structure: predicted_records[metric][type][record_id] = {
#   'value': float,
#   'time': datetime,
#   'confidence': float,
#   'first_detected': datetime,
#   'last_seen': datetime,
#   'notified': bool
# }

# History of sent record alerts (to avoid spam but allow important updates)
record_alert_history = []
# Structure: [{'type': str, 'metric': str, 'value': float, 'time': datetime, 'sent_at': datetime}]

# Alert and message sending functions
async def schedule_jobs():
    """TÃ¢che planifiÃ©e pour vÃ©rifier la mÃ©tÃ©o pÃ©riodiquement."""
    while True:
        await check_weather()
        # VÃ©rifier les changements dans les records prÃ©vus (notifications d'annulation)
        await check_predicted_record_changes()
        # VÃ©rifier la fraÃ®cheur des donnÃ©es (alerte si >24h)
        await check_data_freshness()
        await asyncio.sleep(60)

async def send_alert(message_text, row=None, alert_column=None):
    """Envoie une alerte Ã  tous les utilisateurs enregistrÃ©s."""
    if row is not None and alert_column is not None:
        # La fonction check_records envoie elle-mÃªme des alertes si un record est battu.
        # Pour Ã©viter les alertes en double, on ne fait pas d'await ici directement.
        # check_records appellera send_alert pour le message de record.
        await check_records(row, alert_column)

    try:
        # Utilisation de aiofiles pour lire chat_ids.json de maniÃ¨re asynchrone
        if os.path.exists('chat_ids.json'):
            async with aiofiles.open('chat_ids.json', 'r') as file:
                content = await file.read()
                chats = json.loads(content)
        else:
            chats = []

        send_tasks = [send_message_with_retry(chat_id, message_text) for chat_id in chats]
        await asyncio.gather(*send_tasks)
        await log_message(f"Sent alert: {message_text}")
    except FileNotFoundError:
        await log_message("Erreur dans send_alert: chat_ids.json non trouvÃ©.")
    except json.JSONDecodeError:
        await log_message("Erreur dans send_alert: Impossible de dÃ©coder chat_ids.json.")
    except Exception as e:
        await log_message(f"Error in send_alert: {str(e)}")

async def send_message_with_retry(chat_id, message_text, max_retries=3):
    """Tente d'envoyer un message avec plusieurs essais en cas d'erreur API."""
    for attempt in range(max_retries):
        try:
            await bot.send_message(chat_id=chat_id, text=message_text)
            return
        except TelegramAPIError as e: # Utilisation de l'exception importÃ©e
            await log_message(f"Tentative {attempt + 1} d'envoi au chat {chat_id} Ã©chouÃ©e: {e}")
            if attempt < max_retries - 1:
                await asyncio.sleep(1) # Attendre avant de rÃ©essayer
            else:
                await log_message(f"Ã‰chec final de l'envoi du message au chat {chat_id} aprÃ¨s {max_retries} tentatives : {e}")
                # Ne pas print directement, mais logger l'Ã©chec
        except Exception as e_general: # Capturer d'autres exceptions potentielles
            await log_message(f"Erreur inattendue lors de l'envoi au chat {chat_id} (tentative {attempt+1}): {e_general}")
            if attempt < max_retries - 1:
                await asyncio.sleep(1)
            else:
                await log_message(f"Ã‰chec final (erreur inattendue) de l'envoi au chat {chat_id} aprÃ¨s {max_retries} tentatives: {e_general}")


async def send_summary_base(chat_id, df_period, period_name, ville_name):
    """Fonction de base pour gÃ©nÃ©rer et envoyer des rÃ©sumÃ©s."""
    if df_period.empty:
        await log_message(f"Aucune donnÃ©e disponible pour {period_name}")
        await bot.send_message(chat_id, f"Pas de donnÃ©es disponibles pour {period_name}.")
        return
    
    summary = generate_summary(df_period)
    await log_message(f"RÃ©sumÃ© pour {period_name} gÃ©nÃ©rÃ© avec succÃ¨s")
    
    message_text = f"RÃ©sumÃ© {period_name} pour {ville_name}:\n\n{summary}"
    await bot.send_message(chat_id, message_text)
    await log_message(f"RÃ©sumÃ© {period_name} envoyÃ© avec succÃ¨s Ã  chat_id: {chat_id}")

async def send_month_summary(chat_id):
    try:
        await log_message(f"DÃ©but de send_month_summary pour chat_id: {chat_id}")
        df = pd.read_csv(csv_filename)
        df['time'] = pd.to_datetime(df['time'], utc=True, errors='coerce').dropna()
        
        now = pd.Timestamp.now(tz='UTC')
        # Mois dernier : du premier jour du mois prÃ©cÃ©dent au premier jour du mois actuel (exclus)
        first_day_current_month = now.replace(day=1, hour=0, minute=0, second=0, microsecond=0)
        first_day_last_month = (first_day_current_month - pd.DateOffset(months=1))
        
        df_last_month = df[(df['time'] >= first_day_last_month) & (df['time'] < first_day_current_month)]
        await log_message(f"DonnÃ©es filtrÃ©es pour le mois dernier ({first_day_last_month.strftime('%Y-%m')}): {len(df_last_month)} entrÃ©es")
        
        await send_summary_base(chat_id, df_last_month, "du mois dernier", VILLE)
    
    except pd.errors.EmptyDataError:
        await handle_summary_error(chat_id, "Le fichier CSV est vide ou mal formatÃ©.")
    except FileNotFoundError:
        await handle_summary_error(chat_id, f"Le fichier {csv_filename} n'a pas Ã©tÃ© trouvÃ©.")
    except aiohttp.ClientError as e: # Erreur rÃ©seau lors de l'envoi du message
        await handle_summary_error(chat_id, f"Erreur de connexion lors de l'envoi du message: {str(e)}", is_network_error=True)
    except Exception as e:
        await handle_summary_error(chat_id, f"Erreur inattendue dans send_month_summary: {str(e)}")

async def send_year_summary(chat_id):
    try:
        await log_message(f"DÃ©but de send_year_summary pour chat_id: {chat_id}")
        df = pd.read_csv(csv_filename)
        df['time'] = pd.to_datetime(df['time'], utc=True, errors='coerce').dropna()
        
        now = pd.Timestamp.now(tz='UTC')
        current_year = now.year
        df_current_year = df[(df['time'].dt.year == current_year) & (df['time'] < now)]
        await log_message(f"DonnÃ©es filtrÃ©es pour l'annÃ©e en cours ({current_year}): {len(df_current_year)} entrÃ©es")

        await send_summary_base(chat_id, df_current_year, "de l'annÃ©e en cours", VILLE)

    except pd.errors.EmptyDataError:
        await handle_summary_error(chat_id, "Le fichier CSV est vide ou mal formatÃ©.")
    except FileNotFoundError:
        await handle_summary_error(chat_id, f"Le fichier {csv_filename} n'a pas Ã©tÃ© trouvÃ©.")
    except aiohttp.ClientError as e:
        await handle_summary_error(chat_id, f"Erreur de connexion lors de l'envoi du message: {str(e)}", is_network_error=True)
    except Exception as e:
        await handle_summary_error(chat_id, f"Erreur inattendue dans send_year_summary: {str(e)}")

async def send_all_summary(chat_id):
    try:
        await log_message(f"DÃ©but de send_all_summary pour chat_id: {chat_id}")
        df = pd.read_csv(csv_filename)
        df['time'] = pd.to_datetime(df['time'], utc=True, errors='coerce').dropna()
        
        await log_message(f"DonnÃ©es lues pour le rÃ©sumÃ© complet: {len(df)} entrÃ©es")
        await send_summary_base(chat_id, df, "de toutes les donnÃ©es mÃ©tÃ©o", VILLE)

    except pd.errors.EmptyDataError:
        await handle_summary_error(chat_id, "Le fichier CSV est vide ou mal formatÃ©.")
    except FileNotFoundError:
        await handle_summary_error(chat_id, f"Le fichier {csv_filename} n'a pas Ã©tÃ© trouvÃ©.")
    except aiohttp.ClientError as e:
        await handle_summary_error(chat_id, f"Erreur de connexion lors de l'envoi du message: {str(e)}", is_network_error=True)
    except Exception as e:
        await handle_summary_error(chat_id, f"Erreur inattendue dans send_all_summary: {str(e)}")

async def handle_summary_error(chat_id, error_msg, is_network_error=False):
    """GÃ¨re les erreurs communes pour les fonctions de rÃ©sumÃ©."""
    await log_message(error_msg)
    if is_network_error:
        await bot.send_message(chat_id, "Erreur de connexion. Veuillez rÃ©essayer plus tard.")
    else:
        await bot.send_message(chat_id, f"Erreur : {error_msg}")


async def get_weather_data():
    """RÃ©cupÃ¨re les donnÃ©es mÃ©tÃ©o de l'API et met Ã  jour le CSV."""
    try:
        now = pd.Timestamp.now(tz='UTC').floor('h')
        async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=60)) as session:
            async with session.get(weather_url) as resp:
                resp.raise_for_status() # LÃ¨ve une exception pour les codes HTTP 4xx/5xx
                data = await resp.json()
                
                if 'hourly' not in data or not isinstance(data['hourly'], dict):
                    await log_message("Format de donnÃ©es API inattendu: 'hourly' manquant ou incorrect.")
                    return pd.DataFrame(), pd.DataFrame()

                columns = ['time', 'temperature_2m', 'precipitation_probability', 'precipitation', 'pressure_msl', 'windspeed_10m', 'uv_index', 'relativehumidity_2m']
                
                # VÃ©rifier que toutes les colonnes attendues sont prÃ©sentes dans les donnÃ©es API
                for col in columns:
                    if col not in data['hourly']:
                        await log_message(f"Colonne API manquante: '{col}' dans data['hourly']")
                        # Retourner des DataFrames vides si une colonne essentielle manque
                        if col == 'time': return pd.DataFrame(), pd.DataFrame()
                        # Pour les autres colonnes, on pourrait initialiser avec des NaN si nÃ©cessaire
                        # mais pour la cohÃ©rence, retourner vide est plus sÃ»r.
                        return pd.DataFrame(), pd.DataFrame()

                df_api = pd.DataFrame({col: data['hourly'][col] for col in columns})
                df_api['time'] = pd.to_datetime(df_api['time'], unit='s', utc=True)
                
                # Lecture du CSV existant
                if os.path.exists(csv_filename) and os.path.getsize(csv_filename) > 0:
                    try:
                        df_existing = pd.read_csv(csv_filename)
                        df_existing['time'] = pd.to_datetime(df_existing['time'], utc=True, errors='coerce')
                        df_existing.dropna(subset=['time'], inplace=True) # S'assurer que les dates sont valides
                    except pd.errors.EmptyDataError:
                         df_existing = pd.DataFrame(columns=columns)
                         df_existing['time'] = pd.to_datetime(df_existing['time'], utc=True) # Assurer le dtype
                else:
                    df_existing = pd.DataFrame(columns=columns)
                    df_existing['time'] = pd.to_datetime(df_existing['time'], utc=True) # Assurer le dtype

                # DonnÃ©es des derniÃ¨res 24h de l'API pour combler les manques
                twenty_four_hours_ago = now - pd.Timedelta(hours=24)
                last_twenty_four_hours_df_api = df_api[(df_api['time'] >= twenty_four_hours_ago) & (df_api['time'] < now)].copy() # .copy() pour Ã©viter SettingWithCopyWarning

                if not last_twenty_four_hours_df_api.empty:
                    missing_data = last_twenty_four_hours_df_api[~last_twenty_four_hours_df_api['time'].isin(df_existing['time'])].copy()
                    if not missing_data.empty:
                        missing_data['time'] = missing_data['time'].dt.strftime('%Y-%m-%dT%H:%M:%SZ')
                        # S'assurer que le header n'est Ã©crit que si le fichier est vide ou n'existe pas
                        header_needed = not os.path.exists(csv_filename) or os.path.getsize(csv_filename) == 0
                        missing_data.to_csv(csv_filename, mode='a', header=header_needed, index=False)
                        await log_message(f"Enregistrement de {len(missing_data)} nouvelles donnÃ©es manquantes dans le CSV.")
                        
                        # VÃ©rifier les records sur les nouvelles donnÃ©es historiques rÃ©elles
                        for _, row in missing_data.iterrows():
                            # Reconvertir le temps en datetime pour check_records
                            row_copy = row.copy()
                            row_copy['time'] = pd.to_datetime(row_copy['time'], utc=True)
                            
                            # VÃ©rifier les records pour les mÃ©triques principales
                            for metric in ['temperature_2m', 'precipitation', 'windspeed_10m', 'pressure_msl', 'uv_index']:
                                if metric in row_copy and pd.notna(row_copy[metric]):
                                    await check_records(row_copy, metric, is_forecast=False)
                
                # PrÃ©visions pour les prochaines heures
                seven_hours_later = now + pd.Timedelta(hours=7)
                next_seven_hours_df = df_api[(df_api['time'] > now) & (df_api['time'] <= seven_hours_later)].copy()
                
                twenty_four_hours_later = now + pd.Timedelta(hours=24)
                next_twenty_four_hours_df = df_api[(df_api['time'] > now) & (df_api['time'] <= twenty_four_hours_later)].copy()
                
                return next_seven_hours_df, next_twenty_four_hours_df

    except aiohttp.ClientError as e: # Erreurs rÃ©seau spÃ©cifiques Ã  aiohttp
        await log_message(f"Erreur rÃ©seau dans get_weather_data: {str(e)}")
    except json.JSONDecodeError as e:
        await log_message(f"Erreur de dÃ©codage JSON dans get_weather_data: {str(e)}")
    except KeyError as e:
        await log_message(f"ClÃ© manquante dans les donnÃ©es API (get_weather_data): {str(e)}")
    except Exception as e:
        await log_message(f"Erreur inattendue dans get_weather_data: {str(e)}\n{traceback.format_exc()}")
    return pd.DataFrame(), pd.DataFrame()

async def get_last_recorded_time():
    """RÃ©cupÃ¨re la derniÃ¨re heure enregistrÃ©e depuis les donnÃ©es historiques CSV."""
    try:
        if not os.path.exists(csv_filename) or os.path.getsize(csv_filename) == 0:
            return None
        
        df = pd.read_csv(csv_filename)
        if df.empty:
            return None
        
        df['time'] = pd.to_datetime(df['time'], utc=True, errors='coerce')
        df.dropna(subset=['time'], inplace=True)
        
        if df.empty:
            return None
        
        # Obtenir la derniÃ¨re entrÃ©e chronologique
        df_sorted = df.sort_values('time')
        last_entry = df_sorted.iloc[-1]
        last_data_time = last_entry['time']
        
        # Convertir en heure locale pour l'affichage
        last_data_local = last_data_time.tz_convert('Europe/Berlin')
        return last_data_local.strftime('%d/%m Ã  %H:%M')
        
    except Exception as e:
        await log_message(f"Erreur dans get_last_recorded_time: {str(e)}")
        return None

async def check_weather():
    """VÃ©rifie la mÃ©tÃ©o et envoie des alertes si nÃ©cessaire."""
    await log_message("Fonction check_weather exÃ©cutÃ©e")
    try:
        # Utiliser le cache au lieu d'appeler directement l'API
        df_next_seven_hours, df_next_twenty_four_hours = await get_cached_forecast_data()
        
        if df_next_seven_hours.empty and df_next_twenty_four_hours.empty:
            await log_message("Aucune donnÃ©e obtenue de get_weather_data dans check_weather. Prochaine vÃ©rification dans 1 minute.")
            return

        # RÃ©cupÃ©rer la derniÃ¨re heure enregistrÃ©e une seule fois
        last_recorded_time = await get_last_recorded_time()
        last_recorded_text = f"(derniÃ¨re mesure: {last_recorded_time})" if last_recorded_time else "(aucune mesure historique)"

        # Alertes pour les 7 prochaines heures
        for _, row in df_next_seven_hours.iterrows():
            # S'assurer que row est bien une Series Pandas et non un tuple si iterrows est mal utilisÃ©
            if not isinstance(row, pd.Series): 
                await log_message(f"Format de ligne inattendu dans df_next_seven_hours: {type(row)}")
                continue

            time_local = row['time'].tz_convert('Europe/Berlin')
            # Comparaison de date uniquement pour sent_alerts
            alert_date_key = time_local.date()

            if row['temperature_2m'] > 35 or row['temperature_2m'] < -10:
                if sent_alerts['temperature'] != alert_date_key:
                    emoji = "ğŸ”¥" if row['temperature_2m'] > 35 else "â„ï¸"
                    await send_alert(f"{emoji} Alerte mÃ©tÃ©o : TempÃ©rature prÃ©vue de {row['temperature_2m']:.1f}Â°C Ã  {time_local.strftime('%H:%M')} Ã  {VILLE}.", row, 'temperature_2m')
                    sent_alerts['temperature'] = alert_date_key
            
            if row['precipitation_probability'] > 80 and row['precipitation'] > 15:
                if sent_alerts['precipitation'] != alert_date_key:
                    await send_alert(f"ğŸŒ§ï¸ Alerte mÃ©tÃ©o : Fortes pluies prÃ©vues de {row['precipitation']:.1f}mm Ã  {time_local.strftime('%H:%M')} Ã  {VILLE}.", row, 'precipitation')
                    sent_alerts['precipitation'] = alert_date_key
            
            if row['windspeed_10m'] > 60: # km/h
                if sent_alerts['windspeed'] != alert_date_key:
                    emoji = "ğŸŒªï¸" if row['windspeed_10m'] > 75 else "ğŸ’¨"
                    wind_type = "tempÃ©tueux" if row['windspeed_10m'] > 75 else "fort"
                    await send_alert(f"{emoji} Alerte mÃ©tÃ©o : Vent {wind_type} prÃ©vu de {row['windspeed_10m']:.1f}km/h Ã  {time_local.strftime('%H:%M')} Ã  {VILLE}.", row, 'windspeed_10m')
                    sent_alerts['windspeed'] = alert_date_key
            
            if row['uv_index'] > 8:
                if sent_alerts['uv_index'] != alert_date_key:
                    await send_alert(f"â˜€ï¸ Alerte mÃ©tÃ©o : Index UV prÃ©vu de {row['uv_index']:.1f} Ã  {time_local.strftime('%H:%M')} Ã  {VILLE} {last_recorded_text}.", row, 'uv_index')
                    sent_alerts['uv_index'] = alert_date_key

        # DÃ©tection de bombe mÃ©tÃ©orologique amÃ©liorÃ©e pour les 24 prochaines heures
        if len(df_next_twenty_four_hours) >= 24:
            await detect_meteorological_bomb(df_next_twenty_four_hours)
    
    except KeyError as e:
        await log_message(f"Erreur de clÃ© dans check_weather (probablement une colonne manquante dans le DataFrame): {str(e)}")
    except Exception as e:
        await log_message(f"Erreur inattendue dans check_weather: {str(e)}\n{traceback.format_exc()}")


async def detect_meteorological_bomb(df_forecast):
    """DÃ©tection avancÃ©e de bombe mÃ©tÃ©orologique selon les critÃ¨res scientifiques.
    
    CritÃ¨res officiels :
    - Latitude 46Â°N (votre ville) : seuil ~22 hPa/24h (ajustÃ© par sin(latitude))
    - Recherche de la plus forte baisse sur toute pÃ©riode de 24h consÃ©cutives
    - Conditions mÃ©tÃ©o associÃ©es : vents forts + prÃ©cipitations
    """
    global sent_alerts
    
    try:
        if len(df_forecast) < 24:
            return
            
        # Calcul du seuil ajustÃ© par latitude (formule scientifique standard)
        CITY_LAT = float(LATITUDE)  # Latitude depuis config.ini
        base_threshold = 24.0  # hPa/24h Ã  60Â°N (rÃ©fÃ©rence)
        latitude_factor = np.sin(np.radians(60)) / np.sin(np.radians(CITY_LAT))
        adjusted_threshold = base_threshold * latitude_factor  # ~22.1 hPa pour 46Â°N
        
        # Recherche de la plus forte baisse sur toutes les fenÃªtres de 24h
        max_pressure_drop = 0
        bomb_start_idx = None
        bomb_end_idx = None
        
        for start_idx in range(len(df_forecast) - 23):
            end_idx = start_idx + 23
            pressure_start = df_forecast.iloc[start_idx]['pressure_msl']
            pressure_end = df_forecast.iloc[end_idx]['pressure_msl']
            pressure_drop = pressure_start - pressure_end
            
            if pressure_drop > max_pressure_drop:
                max_pressure_drop = pressure_drop
                bomb_start_idx = start_idx
                bomb_end_idx = end_idx
        
        # VÃ©rification du seuil de bombe mÃ©tÃ©orologique
        if max_pressure_drop >= adjusted_threshold and bomb_start_idx is not None:
            bomb_start_time = df_forecast.iloc[bomb_start_idx]['time']
            bomb_end_time = df_forecast.iloc[bomb_end_idx]['time']
            bomb_start_local = bomb_start_time.tz_convert('Europe/Berlin')
            bomb_end_local = bomb_end_time.tz_convert('Europe/Berlin')
            
            alert_date_key = bomb_start_local.date()
            
            if sent_alerts['pressure_msl'] != alert_date_key:
                # Analyse des conditions mÃ©tÃ©o associÃ©es
                bomb_period = df_forecast.iloc[bomb_start_idx:bomb_end_idx+1]
                max_wind = bomb_period['windspeed_10m'].max()
                total_precip = bomb_period['precipitation'].sum()
                
                # Classification de l'intensitÃ©
                if max_pressure_drop >= adjusted_threshold * 1.5:  # ~33 hPa
                    intensity = "EXTRÃŠME"
                    emoji = "ğŸŒªï¸ğŸ’€"
                elif max_pressure_drop >= adjusted_threshold * 1.2:  # ~27 hPa
                    intensity = "MAJEURE"
                    emoji = "ğŸŒªï¸âš ï¸"
                else:
                    intensity = "MODÃ‰RÃ‰E"
                    emoji = "ğŸŒªï¸"
                
                # Message d'alerte dÃ©taillÃ©
                message = (
                    f"{emoji} BOMBE MÃ‰TÃ‰OROLOGIQUE {intensity} DÃ‰TECTÃ‰E !\n\n"
                    f"ğŸ“‰ Chute de pression : {max_pressure_drop:.1f} hPa en 24h\n"
                    f"ğŸ¯ Seuil scientifique (46Â°N) : {adjusted_threshold:.1f} hPa\n"
                    f"â° PÃ©riode : {bomb_start_local.strftime('%d/%m %H:%M')} â†’ {bomb_end_local.strftime('%d/%m %H:%M')}\n"
                    f"ğŸ’¨ Vent max prÃ©vu : {max_wind:.1f} km/h\n"
                    f"ğŸŒ§ï¸ PrÃ©cipitations : {total_precip:.1f} mm\n\n"
                    f"âš ï¸ RISQUES : Vents violents, pluies torrentielles, conditions dangereuses"
                )
                
                # Envoyer l'alerte sans vÃ©rification de records (Ã©viter rÃ©cursion)
                await send_alert(message)
                sent_alerts['pressure_msl'] = alert_date_key
                
                await log_message(f"Bombe mÃ©tÃ©orologique dÃ©tectÃ©e : {max_pressure_drop:.1f} hPa en 24h (seuil: {adjusted_threshold:.1f})")
        
        # Alerte prÃ©ventive si proche du seuil (80% du seuil)
        elif max_pressure_drop >= adjusted_threshold * 0.8:
            bomb_start_time = df_forecast.iloc[bomb_start_idx]['time']
            bomb_start_local = bomb_start_time.tz_convert('Europe/Berlin')
            alert_date_key = bomb_start_local.date()
            
            if sent_alerts['pressure_msl'] != alert_date_key:
                await send_alert(
                    f"âš ï¸ Surveillance mÃ©tÃ©o : Forte baisse de pression prÃ©vue de {max_pressure_drop:.1f} hPa en 24h "
                    f"(proche du seuil de bombe mÃ©tÃ©orologique: {adjusted_threshold:.1f} hPa). "
                    f"DÃ©but prÃ©vu : {bomb_start_local.strftime('%d/%m Ã  %H:%M')}."
                )
                sent_alerts['pressure_msl'] = alert_date_key
                
    except Exception as e:
        await log_message(f"Erreur dans detect_meteorological_bomb: {str(e)}\n{traceback.format_exc()}")

async def check_data_freshness():
    """VÃ©rifie si la derniÃ¨re donnÃ©e historisÃ©e date de plus de 24h et envoie une alerte."""
    global sent_alerts
    
    try:
        # VÃ©rifier que le fichier CSV existe et n'est pas vide
        if not os.path.exists(csv_filename) or os.path.getsize(csv_filename) == 0:
            await log_message("Fichier CSV inexistant ou vide pour vÃ©rification fraÃ®cheur donnÃ©es.")
            return
        
        # Lire le CSV et obtenir la derniÃ¨re entrÃ©e
        df = pd.read_csv(csv_filename)
        if df.empty:
            await log_message("CSV vide pour vÃ©rification fraÃ®cheur donnÃ©es.")
            return
        
        # Convertir la colonne time et trier par date
        df['time'] = pd.to_datetime(df['time'], utc=True, errors='coerce')
        df.dropna(subset=['time'], inplace=True)
        
        if df.empty:
            await log_message("Aucune donnÃ©e temporelle valide pour vÃ©rification fraÃ®cheur donnÃ©es.")
            return
        
        # Obtenir la derniÃ¨re entrÃ©e chronologique
        df_sorted = df.sort_values('time')
        last_entry = df_sorted.iloc[-1]
        last_data_time = last_entry['time']
        
        # Heure actuelle
        now = pd.Timestamp.now(tz='UTC')
        
        # Calculer la diffÃ©rence en heures
        time_diff = now - last_data_time
        hours_since_last_data = time_diff.total_seconds() / 3600
        
        # Seuil de 24 heures
        alert_threshold_hours = 24
        
        # Convertir en heure locale pour l'affichage
        last_data_local = last_data_time.tz_convert('Europe/Berlin')
        last_data_str = last_data_local.strftime('%d/%m/%Y Ã  %H:%M')
        
        # VÃ©rifier si une alerte doit Ãªtre envoyÃ©e
        current_date = now.date()
        
        if hours_since_last_data > alert_threshold_hours:
            # Ã‰viter le spam : ne pas envoyer plus d'une alerte par jour
            if sent_alerts['data_freshness'] != current_date:
                # Formater le message d'alerte
                if hours_since_last_data > 48:
                    urgency_emoji = "ğŸš¨"
                    urgency_text = "CRITIQUE"
                    days_old = int(hours_since_last_data // 24)
                    time_description = f"{days_old} jour{'s' if days_old > 1 else ''}"
                elif hours_since_last_data > 36:
                    urgency_emoji = "âš ï¸"
                    urgency_text = "URGENT"
                    time_description = f"{hours_since_last_data:.1f} heures"
                else:
                    urgency_emoji = "â°"
                    urgency_text = "ATTENTION"
                    time_description = f"{hours_since_last_data:.1f} heures"
                
                alert_message = (
                    f"{urgency_emoji} {urgency_text} - DonnÃ©es mÃ©tÃ©o obsolÃ¨tes !\n\n"
                    f"ğŸ“Š DerniÃ¨re donnÃ©e historisÃ©e : {last_data_str}\n"
                    f"â±ï¸ Ã‚ge des donnÃ©es : {time_description}\n"
                    f"ğŸ”´ Seuil dÃ©passÃ© : {alert_threshold_hours}h\n\n"
                    f"ğŸ¤– L'API OpenMeteo a peut-Ãªtre changÃ© ou le service est interrompu.\n"
                    f"ğŸ”§ VÃ©rification et correction nÃ©cessaires."
                )
                
                # Envoyer l'alerte
                await send_alert(alert_message)
                sent_alerts['data_freshness'] = current_date
                
                await log_message(f"Alerte fraÃ®cheur donnÃ©es envoyÃ©e: {hours_since_last_data:.1f}h depuis derniÃ¨re donnÃ©e")
            else:
                await log_message(f"DonnÃ©es obsolÃ¨tes ({hours_since_last_data:.1f}h) mais alerte dÃ©jÃ  envoyÃ©e aujourd'hui")
        else:
            # DonnÃ©es fraÃ®ches : rÃ©initialiser le tracking si nÃ©cessaire
            if sent_alerts['data_freshness'] is not None:
                await log_message(f"DonnÃ©es redevenues fraÃ®ches ({hours_since_last_data:.1f}h), rÃ©initialisation tracking alertes")
                sent_alerts['data_freshness'] = None
            
    except pd.errors.EmptyDataError:
        await log_message("Fichier CSV vide lors de la vÃ©rification de fraÃ®cheur.")
    except Exception as e:
        await log_message(f"Erreur dans check_data_freshness: {str(e)}\n{traceback.format_exc()}")


def calculate_confidence_score(forecast_time, current_time):
    """Calcule un score de confiance basÃ© sur la proximitÃ© temporelle de la prÃ©vision.
    
    Args:
        forecast_time: Datetime de la prÃ©vision
        current_time: Datetime actuel
    
    Returns:
        float: Score entre 0 et 1 (1 = trÃ¨s fiable, 0 = peu fiable)
    """
    try:
        time_diff_hours = abs((forecast_time - current_time).total_seconds()) / 3600
        
        if time_diff_hours <= 3:
            return 1.0  # TrÃ¨s fiable (0-3h)
        elif time_diff_hours <= 12:
            return 0.8  # Fiable (3-12h)
        elif time_diff_hours <= 24:
            return 0.6  # ModÃ©rÃ©ment fiable (12-24h)
        elif time_diff_hours <= 48:
            return 0.4  # Peu fiable (24-48h)
        else:
            return 0.2  # TrÃ¨s peu fiable (48h+)
    except:
        return 0.5  # Fallback

async def check_predicted_record_changes():
    """VÃ©rifie les changements dans les records prÃ©vus et notifie si nÃ©cessaire."""
    global predicted_records
    
    try:
        current_time = pd.Timestamp.now(tz='UTC')
        changes_detected = []
        
        for metric in predicted_records:
            for record_type in predicted_records[metric]:
                records_to_remove = []
                
                for record_id, record_info in predicted_records[metric][record_type].items():
                    # VÃ©rifier si le record est trop ancien sans mise Ã  jour
                    time_since_last_seen = (current_time - record_info['last_seen']).total_seconds() / 3600
                    time_until_forecast = (record_info['time'] - current_time).total_seconds() / 3600
                    
                    # DÃ©lai d'expiration adaptatif selon la proximitÃ© du record
                    if time_until_forecast <= 6:
                        # Record trÃ¨s proche : expiration aprÃ¨s 2h sans mise Ã  jour
                        expiration_hours = 2
                    elif time_until_forecast <= 24:
                        # Record proche : expiration aprÃ¨s 6h sans mise Ã  jour
                        expiration_hours = 6
                    else:
                        # Record lointain : expiration aprÃ¨s 12h sans mise Ã  jour
                        expiration_hours = 12
                    
                    # VÃ©rifier si le record a expirÃ© (pas vu depuis trop longtemps)
                    if time_since_last_seen > expiration_hours:
                        # Record disparu - notification rapide d'annulation
                        if record_info['notified']:
                            changes_detected.append({
                                'type': 'expired',
                                'metric': metric,
                                'record_type': record_type,
                                'value': record_info['value'],
                                'time': record_info['time'],
                                'confidence': record_info['confidence'],
                                'missing_hours': time_since_last_seen
                            })
                        records_to_remove.append(record_id)
                    
                    # Nettoyage supplÃ©mentaire : supprimer les records passÃ©s
                    elif time_until_forecast < -2:  # Record passÃ© depuis plus de 2h
                        records_to_remove.append(record_id)
                
                # Supprimer les records expirÃ©s
                for record_id in records_to_remove:
                    del predicted_records[metric][record_type][record_id]
        
        # Envoyer les notifications de changements
        for change in changes_detected:
            await notify_record_change(change)
            
    except Exception as e:
        await log_message(f"Erreur dans check_predicted_record_changes: {str(e)}")

async def notify_record_change(change_info):
    """Notifie un changement dans les records prÃ©vus."""
    try:
        metric_info = get_metric_info(change_info['metric'])
        time_local = change_info['time'].tz_convert('Europe/Berlin')
        
        if change_info['type'] == 'expired':
            confidence_text = f"{change_info['confidence']*100:.0f}%"
            missing_hours = change_info.get('missing_hours', 0)
            
            # DÃ©terminer l'urgence du message selon la proximitÃ©
            time_until_forecast = (change_info['time'] - pd.Timestamp.now(tz='UTC')).total_seconds() / 3600
            
            if time_until_forecast <= 6:
                urgency_emoji = "âš ï¸"
                urgency_text = "URGENT - "
            elif time_until_forecast <= 24:
                urgency_emoji = "ğŸ“‰"
                urgency_text = ""
            else:
                urgency_emoji = "ğŸ“‹"
                urgency_text = ""
            
            message = (
                f"{urgency_emoji} {urgency_text}Mise Ã  jour prÃ©visions : Le record potentiel de {metric_info['name']} "
                f"({change_info['value']:.1f}{metric_info['unit']}) prÃ©vu pour "
                f"{time_local.strftime('%d/%m Ã  %H:%M')} n'apparaÃ®t plus dans les prÃ©visions depuis "
                f"{missing_hours:.1f}h. (Confiance Ã©tait de {confidence_text})"
            )
            await send_alert(message)
            await log_message(f"Record potentiel expirÃ© notifiÃ©: {change_info['metric']} {change_info['value']} (disparu depuis {missing_hours:.1f}h)")
            
    except Exception as e:
        await log_message(f"Erreur dans notify_record_change: {str(e)}")

async def update_predicted_records(row_alert, alert_column, is_forecast=True):
    """Met Ã  jour le systÃ¨me de suivi des records prÃ©vus."""
    global predicted_records
    
    if not is_forecast:
        return  # On ne suit que les prÃ©visions
    
    try:
        # VÃ©rifier que la mÃ©trique est supportÃ©e
        if alert_column not in predicted_records:
            await log_message(f"MÃ©trique {alert_column} non supportÃ©e pour le suivi des records prÃ©vus.")
            return
        
        current_time = pd.Timestamp.now(tz='UTC')
        forecast_time = row_alert['time']
        confidence = calculate_confidence_score(forecast_time, current_time)
        
        # Identifier les types de records Ã  vÃ©rifier selon la mÃ©trique
        record_types = ['max']
        if alert_column == 'temperature_2m' and 'min' in predicted_records[alert_column]:
            record_types.append('min')
        
        for record_type in record_types:
            # VÃ©rifier que le type de record existe pour cette mÃ©trique
            if record_type not in predicted_records[alert_column]:
                continue
                
            value = row_alert[alert_column]
            
            # CrÃ©er un ID unique pour ce record basÃ© sur la mÃ©trique, type et valeur
            record_id = f"{alert_column}_{record_type}_{value:.2f}_{forecast_time.strftime('%Y%m%d%H')}"
            
            # VÃ©rifier si c'est un nouveau record ou une mise Ã  jour
            existing_record = predicted_records[alert_column][record_type].get(record_id)
            
            if existing_record:
                # Mise Ã  jour d'un record existant
                existing_record['last_seen'] = current_time
                existing_record['confidence'] = max(existing_record['confidence'], confidence)
            else:
                # Nouveau record potentiel
                predicted_records[alert_column][record_type][record_id] = {
                    'value': value,
                    'time': forecast_time,
                    'confidence': confidence,
                    'first_detected': current_time,
                    'last_seen': current_time,
                    'notified': False
                }
                
    except Exception as e:
        await log_message(f"Erreur dans update_predicted_records: {str(e)}")

async def should_notify_record(record_info, metric, record_type):
    """DÃ©termine si un record doit Ãªtre notifiÃ© en Ã©vitant le spam."""
    global record_alert_history
    
    try:
        current_time = pd.Timestamp.now(tz='UTC')
        
        # CritÃ¨res pour notifier :
        # 1. Confiance suffisante (>= 0.6)
        # 2. Pas dÃ©jÃ  notifiÃ© rÃ©cemment pour une valeur similaire
        # 3. Record pas trop lointain (< 48h, limite de l'API)
        
        if record_info['confidence'] < 0.6:
            return False
        
        time_diff_hours = abs((record_info['time'] - current_time).total_seconds()) / 3600
        if time_diff_hours > 48:  # Limite de l'API
            return False
        
        # VÃ©rifier l'historique rÃ©cent (dÃ©lai adaptatif selon proximitÃ© du record)
        # Plus le record est proche, plus on peut notifier frÃ©quemment les changements
        if time_diff_hours <= 3:
            # Record dans les 3h : notifications toutes les 30 minutes
            lookback_hours = 0.5
        elif time_diff_hours <= 12:
            # Record dans les 12h : notifications toutes les 2h
            lookback_hours = 2
        elif time_diff_hours <= 24:
            # Record dans les 24h : notifications toutes les 6h
            lookback_hours = 6
        else:
            # Record plus lointain : notifications toutes les 12h
            lookback_hours = 12
            
        cutoff_time = current_time - pd.Timedelta(hours=lookback_hours)
        recent_alerts = [
            alert for alert in record_alert_history 
            if alert['sent_at'] > cutoff_time 
            and alert['metric'] == metric 
            and alert['type'] == record_type
        ]
        
        # Ã‰viter les notifications rÃ©pÃ©titives pour des valeurs similaires
        for alert in recent_alerts:
            value_diff = abs(alert['value'] - record_info['value'])
            # Seuils adaptatifs selon la mÃ©trique
            if metric == 'temperature_2m':
                threshold = 0.1  # 0.1Â°C pour tempÃ©rature
            elif metric == 'precipitation':
                threshold = 0.5  # 0.5mm pour prÃ©cipitations
            elif metric == 'windspeed_10m':
                threshold = 2.0  # 2 km/h pour vent
            elif metric == 'pressure_msl':
                threshold = 1.0  # 1 hPa pour pression
            elif metric == 'uv_index':
                threshold = 0.2  # 0.2 pour UV
            else:
                threshold = 0.5  # DÃ©faut
                
            if value_diff < threshold:
                return False
        
        return True
        
    except Exception as e:
        await log_message(f"Erreur dans should_notify_record: {str(e)}")
        return False

async def log_record_alert(metric, record_type, value, forecast_time):
    """Enregistre l'envoi d'une alerte de record."""
    global record_alert_history
    
    try:
        current_time = pd.Timestamp.now(tz='UTC')
        
        # Ajouter Ã  l'historique
        record_alert_history.append({
            'type': record_type,
            'metric': metric,
            'value': value,
            'time': forecast_time,
            'sent_at': current_time
        })
        
        # Nettoyer l'historique (garder seulement les 48 derniÃ¨res heures)
        cutoff_time = current_time - pd.Timedelta(hours=48)
        record_alert_history = [
            alert for alert in record_alert_history 
            if alert['sent_at'] > cutoff_time
        ]
        
    except Exception as e:
        await log_message(f"Erreur dans log_record_alert: {str(e)}")

async def check_records(row_alert, alert_column, is_forecast=True):
    """VÃ©rifie si une valeur entrante bat un record annuel ET historique absolu.
    Args:
        is_forecast: True pour prÃ©visions (message 'potentiel'), False pour donnÃ©es historiques (message 'nouveau record')
    
    VÃ©rifie 2 types de records :
    - Record annuel : comparaison avec l'annÃ©e en cours uniquement
    - Record historique absolu : comparaison avec tout l'historique disponible
    
    Version amÃ©liorÃ©e avec gestion intelligente des notifications pour les prÃ©visions.
    """
    try:
        if not os.path.exists(csv_filename) or os.path.getsize(csv_filename) == 0:
            await log_message("Fichier CSV vide ou inexistant, impossible de vÃ©rifier les records.")
            return

        df = pd.read_csv(csv_filename)
        if df.empty:
            await log_message("Fichier CSV lu mais vide, impossible de vÃ©rifier les records.")
            return

        df['time'] = pd.to_datetime(df['time'], utc=True, errors='coerce')
        df.dropna(subset=['time'], inplace=True)

        # S'assurer que la colonne d'alerte existe et est numÃ©rique
        if alert_column not in df.columns:
            await log_message(f"Colonne {alert_column} non trouvÃ©e dans le CSV pour vÃ©rifier les records.")
            return
        if not pd.api.types.is_numeric_dtype(df[alert_column]):
            await log_message(f"Colonne {alert_column} n'est pas numÃ©rique dans le CSV pour vÃ©rifier les records.")
            return

        current_year = pd.Timestamp.now(tz='UTC').year
        df_current_year = df[df['time'].dt.year == current_year].copy()
        time_local = row_alert['time'].tz_convert('Europe/Berlin')

        # Mettre Ã  jour le suivi des records prÃ©vus si c'est une prÃ©vision
        if is_forecast:
            await update_predicted_records(row_alert, alert_column, is_forecast)

        record_detected = False

        # === VÃ‰RIFICATION RECORDS ANNUELS (annÃ©e courante) ===
        if df_current_year.empty:
            await log_message(f"Aucune donnÃ©e pour l'annÃ©e en cours ({current_year}), impossible de vÃ©rifier les records annuels pour {alert_column}.")
            # Si c'est la premiÃ¨re donnÃ©e de l'annÃ©e, elle Ã©tablit le record initial
            if not is_forecast:  # Seulement pour les donnÃ©es rÃ©elles
                await send_alert(f"ğŸ† Info mÃ©tÃ©o : PremiÃ¨re donnÃ©e de l'annÃ©e pour {alert_column} : {row_alert[alert_column]} Ã  {time_local.strftime('%H:%M')}.")
        else:
            # VÃ©rification du record max annuel
            max_value_year = df_current_year[alert_column].max()
            if pd.notna(row_alert[alert_column]) and row_alert[alert_column] > max_value_year:
                # Trouver la date de l'ancien record
                max_idx = df_current_year[alert_column].idxmax()
                previous_record_time = df_current_year.loc[max_idx, 'time'].tz_convert('Europe/Berlin')
                previous_record_date = previous_record_time.strftime('%d/%m/%Y')
                
                record_detected = True
                record_info = {
                    'value': row_alert[alert_column],
                    'time': row_alert['time'],
                    'confidence': calculate_confidence_score(row_alert['time'], pd.Timestamp.now(tz='UTC')) if is_forecast else 1.0,
                    'notified': False
                }
                
                if is_forecast:
                    # Pour les prÃ©visions, vÃ©rifier si on doit notifier
                    if await should_notify_record(record_info, alert_column, 'max'):
                        prefix = "Potentiel nouveau"
                        suffix = "prÃ©vu"
                        confidence_text = f" (confiance: {record_info['confidence']*100:.0f}%)" if record_info['confidence'] < 1.0 else ""
                        await send_alert(f"ğŸ† Alerte mÃ©tÃ©o : {prefix} record annuel {current_year} (max) pour {alert_column} : {row_alert[alert_column]} (prÃ©cÃ©dent: {max_value_year} le {previous_record_date}) {suffix} Ã  {time_local.strftime('%H:%M')}{confidence_text}.")
                        await log_record_alert(alert_column, 'max', row_alert[alert_column], row_alert['time'])
                        # Marquer comme notifiÃ© dans le systÃ¨me de suivi
                        for record_id, stored_record in predicted_records[alert_column]['max'].items():
                            if abs(stored_record['value'] - row_alert[alert_column]) < 0.01:
                                stored_record['notified'] = True
                                break
                else:
                    # Pour les donnÃ©es historiques, toujours notifier
                    prefix = "Nouveau"
                    suffix = "confirmÃ©"
                    await send_alert(f"ğŸ† Alerte mÃ©tÃ©o : {prefix} record annuel {current_year} (max) pour {alert_column} : {row_alert[alert_column]} (prÃ©cÃ©dent: {max_value_year} le {previous_record_date}) {suffix} Ã  {time_local.strftime('%H:%M')}.")

            # VÃ©rification du record min annuel (spÃ©cifiquement pour la tempÃ©rature)
            if alert_column == 'temperature_2m':
                min_value_year = df_current_year[alert_column].min()
                if pd.notna(row_alert[alert_column]) and row_alert[alert_column] < min_value_year:
                    # Trouver la date de l'ancien record
                    min_idx = df_current_year[alert_column].idxmin()
                    previous_record_time = df_current_year.loc[min_idx, 'time'].tz_convert('Europe/Berlin')
                    previous_record_date = previous_record_time.strftime('%d/%m/%Y')
                    
                    record_detected = True
                    record_info = {
                        'value': row_alert[alert_column],
                        'time': row_alert['time'],
                        'confidence': calculate_confidence_score(row_alert['time'], pd.Timestamp.now(tz='UTC')) if is_forecast else 1.0,
                        'notified': False
                    }
                    
                    if is_forecast:
                        # Pour les prÃ©visions, vÃ©rifier si on doit notifier
                        if await should_notify_record(record_info, alert_column, 'min'):
                            prefix = "Potentiel nouveau"
                            suffix = "prÃ©vu"
                            confidence_text = f" (confiance: {record_info['confidence']*100:.0f}%)" if record_info['confidence'] < 1.0 else ""
                            await send_alert(f"ğŸ† Alerte mÃ©tÃ©o : {prefix} record annuel {current_year} (min) pour {alert_column} : {row_alert[alert_column]} (prÃ©cÃ©dent: {min_value_year} le {previous_record_date}) {suffix} Ã  {time_local.strftime('%H:%M')}{confidence_text}.")
                            await log_record_alert(alert_column, 'min', row_alert[alert_column], row_alert['time'])
                            # Marquer comme notifiÃ© dans le systÃ¨me de suivi
                            for record_id, stored_record in predicted_records[alert_column]['min'].items():
                                if abs(stored_record['value'] - row_alert[alert_column]) < 0.01:
                                    stored_record['notified'] = True
                                    break
                    else:
                        # Pour les donnÃ©es historiques, toujours notifier
                        prefix = "Nouveau"
                        suffix = "confirmÃ©"
                        await send_alert(f"ğŸ† Alerte mÃ©tÃ©o : {prefix} record annuel {current_year} (min) pour {alert_column} : {row_alert[alert_column]} (prÃ©cÃ©dent: {min_value_year} le {previous_record_date}) {suffix} Ã  {time_local.strftime('%H:%M')}.")

        # === VÃ‰RIFICATION RECORDS HISTORIQUES ABSOLUS (tout l'historique) ===
        available_years = sorted(df['time'].dt.year.unique())
        first_year = min(available_years)
        
        # Record max historique absolu
        max_value_absolute = df[alert_column].max()
        if pd.notna(row_alert[alert_column]) and row_alert[alert_column] > max_value_absolute:
            # Trouver la date de l'ancien record historique absolu
            max_absolute_idx = df[alert_column].idxmax()
            previous_absolute_record_time = df.loc[max_absolute_idx, 'time'].tz_convert('Europe/Berlin')
            previous_absolute_record_date = previous_absolute_record_time.strftime('%d/%m/%Y')
            
            record_detected = True
            record_info = {
                'value': row_alert[alert_column],
                'time': row_alert['time'],
                'confidence': calculate_confidence_score(row_alert['time'], pd.Timestamp.now(tz='UTC')) if is_forecast else 1.0,
                'notified': False
            }
            
            if is_forecast:
                # Pour les records historiques absolus, seuil de confiance plus Ã©levÃ©
                if record_info['confidence'] >= 0.7 and await should_notify_record(record_info, alert_column, 'max'):
                    prefix = "Potentiel nouveau"
                    suffix = "prÃ©vu"
                    confidence_text = f" (confiance: {record_info['confidence']*100:.0f}%)" if record_info['confidence'] < 1.0 else ""
                    await send_alert(f"ğŸ”¥ RECORD HISTORIQUE : {prefix} record absolu (max) pour {alert_column} : {row_alert[alert_column]} (prÃ©cÃ©dent: {max_value_absolute} le {previous_absolute_record_date}) {suffix} Ã  {time_local.strftime('%H:%M')} ! DonnÃ©es depuis {first_year}{confidence_text}.")
                    await log_record_alert(alert_column, 'max_absolute', row_alert[alert_column], row_alert['time'])
            else:
                # Pour les donnÃ©es historiques, toujours notifier
                prefix = "Nouveau"
                suffix = "confirmÃ©"
                await send_alert(f"ğŸ”¥ RECORD HISTORIQUE : {prefix} record absolu (max) pour {alert_column} : {row_alert[alert_column]} (prÃ©cÃ©dent: {max_value_absolute} le {previous_absolute_record_date}) {suffix} Ã  {time_local.strftime('%H:%M')} ! DonnÃ©es depuis {first_year}.")

        # Record min historique absolu (spÃ©cifiquement pour la tempÃ©rature)
        if alert_column == 'temperature_2m':
            min_value_absolute = df[alert_column].min()
            if pd.notna(row_alert[alert_column]) and row_alert[alert_column] < min_value_absolute:
                # Trouver la date de l'ancien record historique absolu (min)
                min_absolute_idx = df[alert_column].idxmin()
                previous_absolute_min_record_time = df.loc[min_absolute_idx, 'time'].tz_convert('Europe/Berlin')
                previous_absolute_min_record_date = previous_absolute_min_record_time.strftime('%d/%m/%Y')
                
                record_detected = True
                record_info = {
                    'value': row_alert[alert_column],
                    'time': row_alert['time'],
                    'confidence': calculate_confidence_score(row_alert['time'], pd.Timestamp.now(tz='UTC')) if is_forecast else 1.0,
                    'notified': False
                }
                
                if is_forecast:
                    # Pour les records historiques absolus, seuil de confiance plus Ã©levÃ©
                    if record_info['confidence'] >= 0.7 and await should_notify_record(record_info, alert_column, 'min'):
                        prefix = "Potentiel nouveau"
                        suffix = "prÃ©vu"
                        confidence_text = f" (confiance: {record_info['confidence']*100:.0f}%)" if record_info['confidence'] < 1.0 else ""
                        await send_alert(f"ğŸ¥¶ RECORD HISTORIQUE : {prefix} record absolu (min) pour {alert_column} : {row_alert[alert_column]} (prÃ©cÃ©dent: {min_value_absolute} le {previous_absolute_min_record_date}) {suffix} Ã  {time_local.strftime('%H:%M')} ! DonnÃ©es depuis {first_year}{confidence_text}.")
                        await log_record_alert(alert_column, 'min_absolute', row_alert[alert_column], row_alert['time'])
                else:
                    # Pour les donnÃ©es historiques, toujours notifier
                    prefix = "Nouveau"
                    suffix = "confirmÃ©"
                    await send_alert(f"ğŸ¥¶ RECORD HISTORIQUE : {prefix} record absolu (min) pour {alert_column} : {row_alert[alert_column]} (prÃ©cÃ©dent: {min_value_absolute} le {previous_absolute_min_record_date}) {suffix} Ã  {time_local.strftime('%H:%M')} ! DonnÃ©es depuis {first_year}.")

    except pd.errors.EmptyDataError:
        await log_message("Fichier CSV vide lors de la vÃ©rification des records.")
    except FileNotFoundError:
        await log_message(f"Fichier {csv_filename} non trouvÃ© lors de la vÃ©rification des records.")
    except KeyError as e:
        await log_message(f"Erreur de clÃ© dans check_records (colonne manquante?): {str(e)}")
    except Exception as e:
        await log_message(f"Erreur inattendue dans check_records: {str(e)}\n{traceback.format_exc()}")


def calculate_sunshine_hours(df_calc):
    """Calcule les heures d'ensoleillement estimÃ©es Ã  partir d'un DataFrame.
    OptimisÃ© pour la localisation configurÃ©e avec calculs astronomiques amÃ©liorÃ©s."""
    # CrÃ©er une copie pour Ã©viter SettingWithCopyWarning si df_calc est une slice
    df = df_calc.copy()
    
    # Assurer que 'time' est datetime et localisÃ©
    if not pd.api.types.is_datetime64_any_dtype(df['time']):
        df['time'] = pd.to_datetime(df['time'], utc=True, errors='coerce')
        df.dropna(subset=['time'], inplace=True)

    if df['time'].dt.tz is None:
         df['time'] = df['time'].dt.tz_localize('UTC')

    df['local_time'] = df['time'].dt.tz_convert('Europe/Berlin')
    
    # CoordonnÃ©es de la ville pour calculs astronomiques plus prÃ©cis
    CITY_LAT = float(LATITUDE)  # Latitude depuis config.ini
    
    # Calcul approximatif du lever/coucher du soleil pour la localisation
    # BasÃ© sur l'Ã©quation du temps et la dÃ©clinaison solaire
    def get_daylight_hours_city(day_of_year):
        """Calcule les heures approximatives de lever/coucher du soleil pour la ville."""
        
        # DÃ©clinaison solaire (approximation)
        declination = 23.45 * math.sin(math.radians(360 * (284 + day_of_year) / 365))
        
        # Angle horaire du coucher du soleil
        try:
            cos_hour_angle = -math.tan(math.radians(CITY_LAT)) * math.tan(math.radians(declination))
            # Limiter entre -1 et 1 pour Ã©viter les erreurs de domaine
            cos_hour_angle = max(-1, min(1, cos_hour_angle))
            hour_angle = math.degrees(math.acos(cos_hour_angle))
            
            # Heures de lever et coucher (approximatives, en heures dÃ©cimales)
            sunrise_hour = 12 - hour_angle / 15
            sunset_hour = 12 + hour_angle / 15
            
            # Ajustements pour l'Ã©quation du temps et l'heure d'Ã©tÃ© (approximatifs)
            # Correction pour le fuseau horaire Europe/Berlin
            sunrise_hour += 0.5  # Correction approximative
            sunset_hour += 0.5
            
            return max(4, sunrise_hour), min(22, sunset_hour)  # Limites raisonnables
        except:
            # Fallback vers les valeurs saisonniÃ¨res si le calcul Ã©choue
            if 80 <= day_of_year <= 266:  # Printemps/Ã‰tÃ© approximatif
                return 6, 20
            else:  # Automne/Hiver
                return 8, 17
    
    # Calcul du jour de l'annÃ©e et application des heures de jour prÃ©cises
    df['day_of_year'] = df['local_time'].dt.dayofyear
    df['hour'] = df['local_time'].dt.hour + df['local_time'].dt.minute / 60.0
    df['is_daytime'] = False
    
    # Appliquer le calcul astronomique pour chaque jour unique
    for day_of_year in df['day_of_year'].unique():
        if pd.notna(day_of_year):
            sunrise, sunset = get_daylight_hours_city(int(day_of_year))
            day_mask = df['day_of_year'] == day_of_year
            df.loc[day_mask, 'is_daytime'] = (df.loc[day_mask, 'hour'] >= sunrise) & (df.loc[day_mask, 'hour'] <= sunset)
    
    # CritÃ¨res d'ensoleillement amÃ©liorÃ©s pour la rÃ©gion
    if 'uv_index' in df.columns and pd.api.types.is_numeric_dtype(df['uv_index']):
        # Seuils UV adaptatifs selon la saison pour la localisation
        def get_uv_threshold(month):
            """Seuils UV optimisÃ©s pour la latitude et climat local."""
            if month in [12, 1, 2]:      # Hiver : soleil plus faible
                return 1.0
            elif month in [3, 4, 10, 11]: # Inter-saisons
                return 1.5
            else:                         # Printemps/Ã‰tÃ© : seuil plus Ã©levÃ©
                return 2.0
        
        df['month'] = df['local_time'].dt.month
        df['uv_threshold'] = df['month'].apply(get_uv_threshold)
        
        # Conditions d'ensoleillement : jour + UV suffisant + pas de forte pluie
        uv_condition = df['uv_index'].fillna(0) > df['uv_threshold']
        
        # Condition mÃ©tÃ©o : pas de fortes prÃ©cipitations (nuages Ã©pais)
        if 'precipitation' in df.columns and pd.api.types.is_numeric_dtype(df['precipitation']):
            no_heavy_rain = df['precipitation'].fillna(0) < 2.0  # Moins de 2mm/h
        else:
            no_heavy_rain = True
        
        # Condition d'humiditÃ© : Ã©viter les brouillards Ã©pais (climat lacustre)
        if 'relativehumidity_2m' in df.columns and pd.api.types.is_numeric_dtype(df['relativehumidity_2m']):
            no_thick_fog = df['relativehumidity_2m'].fillna(100) < 95  # Moins de 95% d'humiditÃ©
        else:
            no_thick_fog = True
        
        # Combinaison des conditions pour un ensoleillement effectif
        df['is_sunny'] = df['is_daytime'] & uv_condition & no_heavy_rain & no_thick_fog
        sunshine_hours = df['is_sunny'].sum()
    else:
        # Fallback si pas de donnÃ©es UV : estimation basÃ©e sur les conditions mÃ©tÃ©o seules
        if ('precipitation' in df.columns and
            'relativehumidity_2m' in df.columns and
            pd.api.types.is_numeric_dtype(df['precipitation']) and
            pd.api.types.is_numeric_dtype(df['relativehumidity_2m'])):
            
            # Estimation sans UV : conditions mÃ©tÃ©o favorables
            good_weather = (df['precipitation'].fillna(0) < 1.0) & (df['relativehumidity_2m'].fillna(100) < 85)
            df['is_sunny'] = df['is_daytime'] & good_weather
            sunshine_hours = df['is_sunny'].sum() * 0.7  # Facteur de correction sans UV
        else:
            # Estimation trÃ¨s approximative basÃ©e sur les heures de jour seules
            sunshine_hours = df['is_daytime'].sum() * 0.4  # 40% d'ensoleillement moyen

    return sunshine_hours


def is_month_complete(df_month, year, month, metric_column=None):
    """VÃ©rifie si un mois a au moins une donnÃ©e par jour pour une mÃ©trique spÃ©cifique (sauf pour le mois en cours)."""
    if df_month.empty:
        return False
    
    # Le mois en cours est toujours acceptÃ© (mÃªme s'il est incomplet)
    current_time = pd.Timestamp.now(tz='UTC')
    current_year = current_time.year
    current_month = current_time.month
    
    if year == current_year and month == current_month:
        return True
    
    # Pour les mois historiques, vÃ©rifier qu'on a au moins une donnÃ©e par jour pour la mÃ©trique
    days_in_month = calendar.monthrange(year, month)[1]
    
    # Si une mÃ©trique spÃ©cifique est demandÃ©e, filtrer seulement sur cette mÃ©trique
    if metric_column and metric_column in df_month.columns:
        df_filtered = df_month.dropna(subset=[metric_column]).copy()
    else:
        df_filtered = df_month.copy()
    
    if df_filtered.empty:
        return False
    
    # Compter les jours uniques avec des donnÃ©es (pour cette mÃ©trique)
    df_filtered['date'] = df_filtered['time'].dt.date
    unique_days = df_filtered['date'].nunique()
    
    # Exiger au moins 80% des jours du mois pour considÃ©rer le mois comme complet
    # (permet une petite tolÃ©rance pour les pannes/maintenance)
    required_days = max(1, int(days_in_month * 0.8))
    
    return unique_days >= required_days

def filter_complete_months_only(df_input, exclude_current_month=False, metric_column=None):
    """Filtre un DataFrame pour ne garder que les mois avec des donnÃ©es complÃ¨tes pour une mÃ©trique spÃ©cifique.
    
    Args:
        df_input: DataFrame avec colonne 'time'
        exclude_current_month: Si True, exclut aussi le mois en cours
        metric_column: Si spÃ©cifiÃ©, filtre seulement sur cette mÃ©trique
    
    Returns:
        DataFrame filtrÃ©
    """
    if df_input.empty:
        return df_input
    
    df = df_input.copy()
    if not pd.api.types.is_datetime64_any_dtype(df['time']):
        df['time'] = pd.to_datetime(df['time'], utc=True, errors='coerce')
        df.dropna(subset=['time'], inplace=True)
    
    if df['time'].dt.tz is None:
        df['time'] = df['time'].dt.tz_localize('UTC')
    
    # Ajouter colonnes annÃ©e/mois pour le groupement
    df['year'] = df['time'].dt.year
    df['month'] = df['time'].dt.month
    
    # Identifier les mois complets pour la mÃ©trique spÃ©cifiÃ©e
    complete_months = []
    
    for (year, month), group in df.groupby(['year', 'month']):
        if is_month_complete(group, year, month, metric_column):
            # Si on veut exclure le mois en cours et que c'est le mois en cours, skip
            current_time = pd.Timestamp.now(tz='UTC')
            if exclude_current_month and year == current_time.year and month == current_time.month:
                continue
            complete_months.append((year, month))
    
    # Filtrer le DataFrame pour ne garder que les mois complets
    if not complete_months:
        return pd.DataFrame(columns=df.columns)
    
    mask = df[['year', 'month']].apply(tuple, axis=1).isin(complete_months)
    return df[mask].drop(['year', 'month'], axis=1)

def calculate_monthly_sunshine(df_calc):
    """Calcule les heures d'ensoleillement par mois (seulement pour les mois complets)."""
    df = df_calc.copy()
    if df.empty:
        return pd.Series(dtype=float)

    # Filtrer pour ne garder que les mois complets (incluant le mois en cours) pour l'ensoleillement (UV principalement)
    df_complete = filter_complete_months_only(df, exclude_current_month=False, metric_column='uv_index')
    
    if df_complete.empty:
        return pd.Series(dtype=float)

    if not pd.api.types.is_datetime64_any_dtype(df_complete['time']):
        df_complete['time'] = pd.to_datetime(df_complete['time'], utc=True, errors='coerce')
    df_complete.dropna(subset=['time'], inplace=True)
    if df_complete['time'].dt.tz is None:
         df_complete['time'] = df_complete['time'].dt.tz_localize('UTC')
    
    # Grouper par mois et appliquer le calcul d'ensoleillement
    # apply peut Ãªtre lent sur de gros dataframes, mais pour des donnÃ©es mensuelles, c'est acceptable.
    monthly_sunshine = df_complete.groupby(pd.Grouper(key='time', freq='MS')).apply(calculate_sunshine_hours) # MS for Month Start
    
    # Formatter l'index pour la lisibilitÃ©
    if not monthly_sunshine.empty:
        monthly_sunshine.index = monthly_sunshine.index.strftime('%Y-%m')
    
    return monthly_sunshine


def generate_summary(df_summary):
    """GÃ©nÃ¨re un texte de rÃ©sumÃ© mÃ©tÃ©o Ã  partir d'un DataFrame."""
    df = df_summary.copy() # Travailler sur une copie
    if df.empty:
        return "Aucune donnÃ©e Ã  rÃ©sumer."

    # Assurer que 'time' est datetime et UTC
    if not pd.api.types.is_datetime64_any_dtype(df['time']):
        df['time'] = pd.to_datetime(df['time'], utc=True, errors='coerce')
    df.dropna(subset=['time'], inplace=True)
    if df['time'].dt.tz is None:
        df['time'] = df['time'].dt.tz_localize('UTC')

    # Calculs statistiques (s'assurer que les colonnes existent et sont numÃ©riques)
    # Fonction utilitaire pour obtenir une statistique ou une valeur par dÃ©faut
    def get_stat(df_stat, column, operation):
        if column not in df_stat.columns or not pd.api.types.is_numeric_dtype(df_stat[column]) or df_stat[column].isnull().all():
            return pd.NA, pd.NaT if operation in ['idxmax', 'idxmin'] else pd.NA
        
        if operation == 'max': return df_stat[column].max()
        if operation == 'min': return df_stat[column].min()
        if operation == 'idxmax': return df_stat[column].idxmax() if not df_stat[column].empty else pd.NaT
        if operation == 'idxmin': return df_stat[column].idxmin() if not df_stat[column].empty else pd.NaT
        if operation == 'mean': return df_stat[column].mean()
        if operation == 'sum': return df_stat[column].sum()
        if operation == 'nunique_rainy': # Cas spÃ©cial pour les jours de pluie
            df_stat['day_for_rain'] = df_stat['time'].dt.date
            daily_precip = df_stat.groupby('day_for_rain')[column].sum()
            return daily_precip[daily_precip > 0.1].count()
        return pd.NA

    # PrÃ©cipitations journaliÃ¨res
    if 'precipitation' in df.columns and pd.api.types.is_numeric_dtype(df['precipitation']):
        df['day'] = df['time'].dt.date
        # Calculer la somme des prÃ©cipitations par jour, gÃ©rer les NaN en les remplaÃ§ant par 0 pour la somme
        df['daily_precipitation'] = df.groupby('day')['precipitation'].transform(lambda x: x.fillna(0).sum())
    else:
        df['daily_precipitation'] = 0 # Colonne par dÃ©faut si 'precipitation' manque

    # Calculs mensuels pour ensoleillement et prÃ©cipitations
    df['local_time'] = df['time'].dt.tz_convert('Europe/Berlin')
    df['year_month'] = df['local_time'].dt.to_period('M')
    
    # Calculer l'ensoleillement mensuel
    sunniest_month = "N/A"
    rainiest_month = "N/A"
    
    try:
        monthly_sunshine = df.groupby('year_month').apply(calculate_sunshine_hours)
        if not monthly_sunshine.empty:
            sunniest_period = monthly_sunshine.idxmax()
            sunniest_month = f"{sunniest_period.strftime('%B %Y')} ({monthly_sunshine.max():.1f}h)"
    except Exception:
        pass
    
    # Calculer les prÃ©cipitations mensuelles
    try:
        if 'precipitation' in df.columns and pd.api.types.is_numeric_dtype(df['precipitation']):
            monthly_precip = df.groupby('year_month')['precipitation'].sum()
            if not monthly_precip.empty:
                rainiest_period = monthly_precip.idxmax()
                rainiest_month = f"{rainiest_period.strftime('%B %Y')} ({monthly_precip.max():.1f}mm)"
    except Exception:
        pass

    max_temp, idx_hot_day = get_stat(df, 'temperature_2m', 'max'), get_stat(df, 'temperature_2m', 'idxmax')
    min_temp, idx_cold_day = get_stat(df, 'temperature_2m', 'min'), get_stat(df, 'temperature_2m', 'idxmin')
    max_precipitation, idx_rain_day = get_stat(df, 'daily_precipitation', 'max'), get_stat(df, 'daily_precipitation', 'idxmax')
    max_uv_index, idx_uv_day = get_stat(df, 'uv_index', 'max'), get_stat(df, 'uv_index', 'idxmax')
    max_wind_speed, idx_wind_day = get_stat(df, 'windspeed_10m', 'max'), get_stat(df, 'windspeed_10m', 'idxmax')
    avg_temp = get_stat(df, 'temperature_2m', 'mean')
    max_humidity, idx_humid_day = get_stat(df, 'relativehumidity_2m', 'max'), get_stat(df, 'relativehumidity_2m', 'idxmax')
    min_humidity, idx_dry_day = get_stat(df, 'relativehumidity_2m', 'min'), get_stat(df, 'relativehumidity_2m', 'idxmin')
    rainy_days = get_stat(df, 'precipitation', 'nunique_rainy')


    # Formatter les dates pour l'affichage (convertir en 'Europe/Berlin')
    def format_date_from_idx(idx, df_ref):
        if pd.isna(idx) or idx not in df_ref.index: return "N/A"
        return df_ref.loc[idx, 'time'].tz_convert('Europe/Berlin').strftime("%Y-%m-%d")

    hot_day_berlin = format_date_from_idx(idx_hot_day, df)
    cold_day_berlin = format_date_from_idx(idx_cold_day, df)
    # Pour rain_day, l'index vient de 'daily_precipitation' qui peut avoir un index diffÃ©rent aprÃ¨s groupby.
    # On utilise l'index original du DataFrame oÃ¹ 'daily_precipitation' a Ã©tÃ© assignÃ©.
    rain_day_berlin = format_date_from_idx(idx_rain_day, df) if pd.notna(idx_rain_day) else "N/A"

    uv_day_berlin = format_date_from_idx(idx_uv_day, df)
    wind_day_berlin = format_date_from_idx(idx_wind_day, df)
    humid_day_berlin = format_date_from_idx(idx_humid_day, df)
    dry_day_berlin = format_date_from_idx(idx_dry_day, df)

    # CrÃ©er le rÃ©sumÃ© en gÃ©rant les valeurs N/A
    summary_parts = [
        f"ğŸŒ¡ï¸ Jour le plus chaud: {hot_day_berlin} ({max_temp:.1f}Â°C)" if pd.notna(max_temp) else "ğŸŒ¡ï¸ Jour le plus chaud: N/A",
        f"â„ï¸ Jour le plus froid: {cold_day_berlin} ({min_temp:.1f}Â°C)" if pd.notna(min_temp) else "â„ï¸ Jour le plus froid: N/A",
        f"ğŸŒ§ï¸ Jour le plus pluvieux: {rain_day_berlin} ({max_precipitation:.1f}mm)" if pd.notna(max_precipitation) else "ğŸŒ§ï¸ Jour le plus pluvieux: N/A",
        f"â˜€ï¸ Jour avec l'index UV le plus Ã©levÃ©: {uv_day_berlin} (index {max_uv_index:.1f})" if pd.notna(max_uv_index) else "â˜€ï¸ Index UV max: N/A",
        f"ğŸ’¨ Jour le plus venteux: {wind_day_berlin} ({max_wind_speed:.1f} km/h)" if pd.notna(max_wind_speed) else "ğŸ’¨ Vent max: N/A",
        f"ğŸŒ‚ Nombre de jours de pluie (>0.1mm): {rainy_days}" if pd.notna(rainy_days) else "ğŸŒ‚ Jours de pluie: N/A",
        f"ğŸŒ¡ï¸ TempÃ©rature moyenne: {avg_temp:.1f}Â°C" if pd.notna(avg_temp) else "ğŸŒ¡ï¸ Temp. moyenne: N/A",
        f"ğŸŒ§ï¸ Mois le plus pluvieux: {rainiest_month}",
        f"ğŸ’¦ Jour le plus humide: {humid_day_berlin} ({max_humidity:.1f}%)" if pd.notna(max_humidity) else "ğŸ’¦ HumiditÃ© max: N/A",
        f"ğŸœï¸ Jour le plus sec: {dry_day_berlin} ({min_humidity:.1f}%)" if pd.notna(min_humidity) else "ğŸœï¸ HumiditÃ© min: N/A",
        f"â˜€ï¸ Mois le plus ensoleillÃ©: {sunniest_month}"
    ]
    return "\n".join(summary_parts)

# --- Fonctions utilitaires pour graphiques et dates ---
def parse_date_input(date_str):
    """Parse et valide une date d'entrÃ©e (format YYYY-MM-DD)."""
    try:
        return pd.to_datetime(date_str, format='%Y-%m-%d', utc=True)
    except (ValueError, TypeError):
        return None

async def create_graph_image(fig):
    """Convertit une figure matplotlib en BytesIO pour Telegram."""
    buf = io.BytesIO()
    
    # Remplacer les emojis dans tous les textes du graphique avant de sauvegarder
    try:
        for ax in fig.get_axes():
            # Titre principal
            if ax.get_title():
                ax.set_title(replace_emojis_for_matplotlib(ax.get_title()))
            
            # Labels des axes
            if ax.get_xlabel():
                ax.set_xlabel(replace_emojis_for_matplotlib(ax.get_xlabel()))
            if ax.get_ylabel():
                ax.set_ylabel(replace_emojis_for_matplotlib(ax.get_ylabel()))
            
            # LÃ©gende
            legend = ax.get_legend()
            if legend:
                for text in legend.get_texts():
                    text.set_text(replace_emojis_for_matplotlib(text.get_text()))
            
            # Annotations et textes
            for text in ax.texts:
                text.set_text(replace_emojis_for_matplotlib(text.get_text()))
            
            # Labels des ticks si ils contiennent des emojis
            for label in ax.get_xticklabels():
                label.set_text(replace_emojis_for_matplotlib(label.get_text()))
            for label in ax.get_yticklabels():
                label.set_text(replace_emojis_for_matplotlib(label.get_text()))
        
        # Titre gÃ©nÃ©ral de la figure
        if hasattr(fig, '_suptitle') and fig._suptitle:
            fig.suptitle(replace_emojis_for_matplotlib(fig._suptitle.get_text()))
    except Exception as e:
        await log_message(f"Erreur lors du remplacement des emojis dans le graphique: {str(e)}")
    
    # Sauvegarder avec gestion d'erreur amÃ©liorÃ©e
    try:
        fig.savefig(buf, format='png', dpi=150, bbox_inches='tight')
    except Exception as e:
        await log_message(f"Erreur lors de la sauvegarde du graphique: {str(e)}")
        # Fallback: essayer une sauvegarde simple sans bbox_inches
        try:
            fig.savefig(buf, format='png', dpi=100)
        except Exception as e2:
            await log_message(f"Erreur fallback sauvegarde graphique: {str(e2)}")
            raise e2
    
    buf.seek(0)
    plt.close(fig)
    return buf

async def send_graph(chat_id, fig, caption):
    """Envoie un graphique via Telegram."""
    try:
        buf = await create_graph_image(fig)
        input_file = BufferedInputFile(buf.getvalue(), filename="graph.png")
        await bot.send_photo(chat_id=chat_id, photo=input_file, caption=caption)
        await log_message(f"Graphique envoyÃ© avec succÃ¨s Ã  chat_id: {chat_id}")
    except Exception as e:
        await log_message(f"Erreur envoi graphique Ã  {chat_id}: {str(e)}")
        await bot.send_message(chat_id, f"Erreur lors de la gÃ©nÃ©ration du graphique: {str(e)}")

def get_metric_info(metric):
    """Retourne les informations d'affichage pour une mÃ©trique."""
    metrics = {
        'temperature_2m': {'name': 'TempÃ©rature', 'unit': 'Â°C', 'emoji': 'ğŸŒ¡ï¸'},
        'precipitation': {'name': 'PrÃ©cipitations', 'unit': 'mm', 'emoji': 'ğŸŒ§ï¸'},
        'windspeed_10m': {'name': 'Vitesse du vent', 'unit': 'km/h', 'emoji': 'ğŸ’¨'},
        'pressure_msl': {'name': 'Pression', 'unit': 'hPa', 'emoji': 'ğŸˆ'},
        'uv_index': {'name': 'Indice UV', 'unit': '', 'emoji': 'â˜€ï¸'},
        'relativehumidity_2m': {'name': 'HumiditÃ©', 'unit': '%', 'emoji': 'ğŸ’¦'},
        'precipitation_probability': {'name': 'ProbabilitÃ© pluie', 'unit': '%', 'emoji': 'ğŸŒ¦ï¸'}
    }
    return metrics.get(metric, {'name': metric, 'unit': '', 'emoji': 'ğŸ“Š'})

# --- DÃ©finition des Handlers avec le Router ---
@router.message(Command("start"))
async def start_command(message: types.Message):
    chat_id = message.chat.id
    is_new_user = True
    
    chats = []
    # Utilisation de aiofiles pour lire/Ã©crire chat_ids.json
    if os.path.exists('chat_ids.json'):
        try:
            async with aiofiles.open('chat_ids.json', 'r', encoding='utf-8') as file:
                content = await file.read()
                chats = json.loads(content)
            if chat_id in chats:
                is_new_user = False
            else:
                chats.append(chat_id)
        except (json.JSONDecodeError, FileNotFoundError) as e:
            await log_message(f"Erreur lecture chat_ids.json pour start: {e}. Initialisation avec nouveau user.")
            chats = [chat_id] # repartir d'une liste fraÃ®che
    else:
        chats = [chat_id]
    
    try:
        async with aiofiles.open('chat_ids.json', 'w', encoding='utf-8') as file:
            await file.write(json.dumps(chats))
    except Exception as e:
        await log_message(f"Erreur Ã©criture chat_ids.json pour start: {e}")

    welcome_ville = VILLE if VILLE else "votre localitÃ©" # Fallback si VILLE n'est pas dÃ©fini
    if is_new_user:
        welcome_message = (
            f"Bienvenue sur le bot mÃ©tÃ©o de {welcome_ville}! ğŸŒ¤ï¸\n\n"
            "ğŸ“Š **Commandes de base :**\n"
            "/weather - MÃ©tÃ©o actuelle (prÃ©visions du cache)\n"
            "/forecast - PrÃ©visions dÃ©taillÃ©es des prochaines heures\n"
            "/sunshine - Graphique ensoleillement mensuel par annÃ©e\n\n"
            "ğŸ“… **RÃ©sumÃ©s par pÃ©riode :**\n"
            "/month - RÃ©sumÃ© du mois dernier\n"
            "/year - RÃ©sumÃ© de l'annÃ©e en cours\n"
            "/all - RÃ©sumÃ© de toutes les donnÃ©es historiques\n"
            "/daterange YYYY-MM-DD YYYY-MM-DD - RÃ©sumÃ© pÃ©riode personnalisÃ©e\n\n"
            "ğŸ“ˆ **Graphiques et analyses :**\n"
            "/forecastgraph - Graphique prÃ©visions 24h (tempÃ©rature + prÃ©cipitations)\n"
            "/graph <mÃ©trique> [jours] - 2 graphiques: courbe + barres\n"
            "   MÃ©triques: temperature, rain, wind, pressure, uv, humidity\n"
            "/heatmap [annÃ©e|all] - Calendrier thermique (style GitHub)\n"
            "/yearcompare [mÃ©trique] - Comparaison entre annÃ©es\n"
            "/sunshinelist - Liste mensuelle d'ensoleillement estimÃ©\n"
            "/top10 <mÃ©trique> - Classement des valeurs extrÃªmes\n\n"
            f"ğŸ’¡ **Exemples pratiques :**\n"
            f"/weather - MÃ©tÃ©o actuelle avec heure de mise Ã  jour\n"
            f"/graph rain 7 - Pluie: courbe + barres des 7 derniers jours\n"
            f"/heatmap all - Calendrier multi-annÃ©es des tempÃ©ratures\n"
            f"/yearcompare temperature - Comparer les annÃ©es\n"
            f"/daterange 2024-06-01 2024-08-31 - Analyse Ã©tÃ© 2024\n\n"
            f"ğŸ¯ **Info importante :** Les graphiques affichent `[Temp]`, `[Rain]` etc. au lieu d'emojis pour Ã©viter les erreurs d'affichage.\n\n"
            f"Explorez la mÃ©tÃ©o de {welcome_ville} avec ces outils d'analyse avancÃ©s!"
        )
        await message.reply(welcome_message)
    else:
        welcome_back_message = (
            "Bon retour ! ğŸŒ¤ï¸ Votre bot mÃ©tÃ©o est prÃªt.\n\n"
            "âš¡ **Commandes rapides :**\n"
            "â€¢ /weather - MÃ©tÃ©o actuelle (avec heure de mise Ã  jour)\n"
            "â€¢ /forecast - PrÃ©visions dÃ©taillÃ©es\n"
            "â€¢ /graph temp 7 - Courbe + barres tempÃ©rature 7j\n"
            "â€¢ /heatmap all - Calendrier thermique multi-annÃ©es\n"
            "â€¢ /yearcompare rain - Comparer les prÃ©cipitations\n"
            "â€¢ /forecastgraph - Graphique prÃ©visions 24h\n\n"
            "ğŸ¯ **Rappel :** Les graphiques utilisent `[Temp]`, `[Rain]` etc. pour Ã©viter les erreurs d'affichage.\n\n"
            "ğŸ’¡ **MÃ©triques :** temperature, rain, wind, pressure, uv, humidity\n\n"
            "Que souhaitez-vous analyser aujourd'hui ?"
        )
        await message.reply(welcome_back_message)

@router.message(Command("weather"))
async def get_latest_info_command(message: types.Message):
    try:
        await log_message("DÃ©but de get_latest_info_command avec double contexte temporel")
        
        # Utiliser le cache des prÃ©visions pour obtenir les donnÃ©es actuelles
        df_seven, df_twenty_four = await get_cached_forecast_data()
        
        # RÃ©cupÃ©rer la derniÃ¨re heure enregistrÃ©e depuis les donnÃ©es historiques
        last_recorded_time = await get_last_recorded_time()
        
        # Obtenir l'heure de la derniÃ¨re mise Ã  jour du cache
        cache_update_time = cached_forecast_data['last_update']
        if cache_update_time:
            cache_update_display = cache_update_time.tz_convert('Europe/Berlin').strftime("%H:%M:%S")
        else:
            cache_update_display = "Inconnue"
        
        response_parts = [f"ğŸŒ¡ï¸ **MÃ©tÃ©o actuelle Ã  {VILLE}**\n"]
        
        # === SECTION 1: PRÃ‰VISIONS ===
        forecast_info = None
        if not df_seven.empty:
            # DonnÃ©es de prÃ©vision 7h
            forecast_info = df_seven.iloc[0].to_dict()
            forecast_time_display = forecast_info['time'].tz_convert('Europe/Berlin').strftime("%d/%m Ã  %H:%M")
            data_source = "prÃ©visions 7h (cache)"
        elif not df_twenty_four.empty:
            # Fallback vers cache 24h
            forecast_info = df_twenty_four.iloc[0].to_dict()
            forecast_time_display = forecast_info['time'].tz_convert('Europe/Berlin').strftime("%d/%m Ã  %H:%M")
            data_source = "prÃ©visions 24h (cache)"
        
        if forecast_info:
            response_parts.append(f"ğŸ“Š **PRÃ‰VISIONS:**")
            response_parts.append(f"ğŸ“… PrÃ©vision pour: {forecast_time_display}")
            response_parts.append(f"ğŸ”„ DerniÃ¨re maj: {cache_update_display}")
            response_parts.append(f"ğŸŒ¡ï¸ TempÃ©rature: {forecast_info.get('temperature_2m', 'N/A')}Â°C")
            response_parts.append(f"ğŸŒ§ï¸ ProbabilitÃ© de pluie: {forecast_info.get('precipitation_probability', 'N/A')}%")
            response_parts.append(f"ğŸ’§ PrÃ©cipitations: {forecast_info.get('precipitation', 'N/A')}mm")
            response_parts.append(f"ğŸ’¨ Vent: {forecast_info.get('windspeed_10m', 'N/A')}km/h")
            response_parts.append(f"â˜€ï¸ Indice UV: {forecast_info.get('uv_index', 'N/A')}")
            response_parts.append(f"ğŸˆ Pression: {forecast_info.get('pressure_msl', 'N/A')} hPa")
            response_parts.append(f"ğŸ’¦ HumiditÃ©: {forecast_info.get('relativehumidity_2m', 'N/A')}%")
            response_parts.append("")  # Ligne vide de sÃ©paration
        
        # === SECTION 2: DERNIÃˆRE MESURE ENREGISTRÃ‰E ===
        response_parts.append(f"ğŸ“Š **DERNIÃˆRE MESURE ENREGISTRÃ‰E:**")
        
        if last_recorded_time:
            # Lire les derniÃ¨res donnÃ©es historiques du CSV
            try:
                if os.path.exists(csv_filename) and os.path.getsize(csv_filename) > 0:
                    df = pd.read_csv(csv_filename)
                    if not df.empty:
                        df['time'] = pd.to_datetime(df['time'], utc=True, errors='coerce')
                        df.dropna(subset=['time'], inplace=True)
                        df.sort_values(by='time', inplace=True)
                        
                        if not df.empty:
                            historical_info = df.iloc[-1].to_dict()
                            response_parts.append(f"ğŸ“… DerniÃ¨re mesure: {last_recorded_time}")
                            response_parts.append(f"ğŸŒ¡ï¸ TempÃ©rature: {historical_info.get('temperature_2m', 'N/A')}Â°C")
                            response_parts.append(f"ğŸŒ§ï¸ ProbabilitÃ© de pluie: {historical_info.get('precipitation_probability', 'N/A')}%")
                            response_parts.append(f"ğŸ’§ PrÃ©cipitations: {historical_info.get('precipitation', 'N/A')}mm")
                            response_parts.append(f"ğŸ’¨ Vent: {historical_info.get('windspeed_10m', 'N/A')}km/h")
                            response_parts.append(f"â˜€ï¸ Indice UV: {historical_info.get('uv_index', 'N/A')}")
                            response_parts.append(f"ğŸˆ Pression: {historical_info.get('pressure_msl', 'N/A')} hPa")
                            response_parts.append(f"ğŸ’¦ HumiditÃ©: {historical_info.get('relativehumidity_2m', 'N/A')}%")
                        else:
                            response_parts.append(f"âŒ DonnÃ©es historiques invalides")
                    else:
                        response_parts.append(f"âŒ Fichier de donnÃ©es historiques vide")
                else:
                    response_parts.append(f"âŒ Aucun fichier de donnÃ©es historiques")
            except Exception as e:
                await log_message(f"Erreur lecture donnÃ©es historiques: {str(e)}")
                response_parts.append(f"âŒ Erreur lecture donnÃ©es historiques")
        else:
            response_parts.append(f"âŒ Aucune mesure historique disponible")
        
        # Si aucune prÃ©vision n'est disponible, afficher un message d'erreur
        if not forecast_info:
            response_parts.insert(1, f"âŒ **Aucune prÃ©vision disponible actuellement**\n")
            await log_message("Aucune prÃ©vision disponible dans les caches pour /weather")
        
        await log_message(f"RÃ©ponse /weather avec double contexte temporel prÃ©parÃ©e, tentative d'envoi")
        await message.reply("\n".join(response_parts))
        await log_message("RÃ©ponse /weather avec double contexte temporel envoyÃ©e avec succÃ¨s")

    except Exception as e:
        await log_message(f"Error in get_latest_info_command: {str(e)}\n{traceback.format_exc()}")
        await message.reply(f"Erreur lors de l'obtention des informations : {str(e)}")


@router.message(Command("forecast"))
async def get_forecast_command(message: types.Message): # RenommÃ© pour clartÃ©
    try:
        # Utiliser le cache au lieu d'appeler directement l'API
        df_next_seven_hours, _ = await get_cached_forecast_data()
        if df_next_seven_hours.empty:
            await message.reply("Aucune donnÃ©e de prÃ©vision disponible pour le moment.")
            return
        
        # Prendre les 6 prochaines heures de prÃ©vision
        forecast_df = df_next_seven_hours.head(6)
        response = f"ğŸ”® PrÃ©visions mÃ©tÃ©o pour {VILLE} (prochaines heures):\n\n"
        
        for _, row in forecast_df.iterrows():
            time_local = row['time'].tz_convert('Europe/Berlin').strftime("%H:%M")
            temp = row.get('temperature_2m', float('nan'))
            precip = row.get('precipitation', float('nan'))
            precip_prob = row.get('precipitation_probability', float('nan'))
            wind = row.get('windspeed_10m', float('nan'))
            uv = row.get('uv_index', float('nan'))
            humidity = row.get('relativehumidity_2m', float('nan'))
            
            temp_emoji = "ğŸ¥µ" if temp > 30 else "ğŸ¥¶" if temp < 10 else "ğŸŒ¡ï¸"
            precip_emoji = "ğŸŒ§ï¸" if precip > 0.1 else "â˜€ï¸" # Seuil pour pluie
            wind_emoji = "ğŸŒ¬ï¸" if wind > 30 else "ğŸƒ" # Seuil pour vent fort
            
            response += f"â° {time_local}:\n"
            response += f"{temp_emoji} {temp:.1f}Â°C | "
            response += f"{precip_emoji} {precip:.1f}mm ({precip_prob:.0f}%) | "
            response += f"{wind_emoji} {wind:.1f}km/h | "
            response += f"â˜€ï¸ UV: {uv:.1f} | "
            response += f"ğŸ’¦ {humidity:.0f}%\n\n"
        
        await message.reply(response)
    except Exception as e:
        await log_message(f"Error in get_forecast_command: {str(e)}\n{traceback.format_exc()}")
        await message.reply("Erreur lors de l'obtention des prÃ©visions.")


@router.message(Command("sunshine"))
async def get_sunshine_summary_command(message: types.Message):
    """GÃ©nÃ¨re un graphique en barres de l'ensoleillement mensuel par annÃ©e."""
    try:
        if not os.path.exists(csv_filename) or os.path.getsize(csv_filename) == 0:
            await message.reply("Aucune donnÃ©e disponible pour calculer l'ensoleillement.")
            return
            
        df = pd.read_csv(csv_filename)
        if df.empty:
            await message.reply("Aucune donnÃ©e disponible pour calculer l'ensoleillement (fichier vide).")
            return

        df['time'] = pd.to_datetime(df['time'], utc=True, errors='coerce')
        df.dropna(subset=['time'], inplace=True)

        if df.empty:
            await message.reply("Aucune donnÃ©e temporelle valide pour calculer l'ensoleillement.")
            return

        # Filtrer pour ne garder que les mois complets (incluant le mois en cours) pour l'ensoleillement (UV principalement)
        df_complete = filter_complete_months_only(df, exclude_current_month=False, metric_column='uv_index')

        # Convertir en heure locale et extraire annÃ©e/mois
        df_complete['local_time'] = df_complete['time'].dt.tz_convert('Europe/Berlin')
        df_complete['year'] = df_complete['local_time'].dt.year
        df_complete['month'] = df_complete['local_time'].dt.month
        
        # VÃ©rifier qu'on a au moins quelques mois de donnÃ©es
        available_years = sorted(df_complete['year'].unique())
        if len(available_years) == 0:
            await message.reply(f"Pas encore de donnÃ©es d'ensoleillement calculÃ©es pour {VILLE}.")
            return

        # Calculer l'ensoleillement mensuel pour chaque annÃ©e
        monthly_sunshine_data = []
        
        for year in available_years:
            year_data = df_complete[df_complete['year'] == year].copy()
            if not year_data.empty:
                # Grouper par mois et calculer l'ensoleillement pour chaque mois
                for month in range(1, 13):
                    month_data = year_data[year_data['month'] == month]
                    if not month_data.empty:  # Suppression du check >= 24 car le filtrage est fait en amont
                        sunshine_hours = calculate_sunshine_hours(month_data)
                        monthly_sunshine_data.append({
                            'year': year,
                            'month': month,
                            'sunshine_hours': sunshine_hours
                        })

        if not monthly_sunshine_data:
            await message.reply("Pas assez de donnÃ©es pour calculer l'ensoleillement mensuel.")
            return

        sunshine_df = pd.DataFrame(monthly_sunshine_data)
        
        # PrÃ©parer les donnÃ©es pour le graphique en barres groupÃ©es
        pivot_data = sunshine_df.pivot(index='month', columns='year', values='sunshine_hours')
        
        # CrÃ©er le graphique moderne en barres groupÃ©es
        fig, ax = plt.subplots(1, 1, figsize=(16, 10))
        fig.patch.set_facecolor('#f8f9fa')
        
        # Palette de couleurs moderne pour l'ensoleillement
        sunshine_colors = ['#f39c12', '#e67e22', '#d35400', '#f1c40f', '#f4d03f',
                          '#3498db', '#2980b9', '#9b59b6', '#8e44ad', '#2ecc71']
        
        # Noms des mois
        month_names = ['Jan', 'FÃ©v', 'Mar', 'Avr', 'Mai', 'Jun',
                      'Jul', 'AoÃ»', 'Sep', 'Oct', 'Nov', 'DÃ©c']
        
        # CrÃ©er les barres groupÃ©es
        x = np.arange(len(month_names))  # positions des mois
        n_years = len(available_years)
        width = 0.8 / n_years  # largeur de chaque barre
        
        current_year = pd.Timestamp.now(tz='Europe/Berlin').year
        
        # Tracer les barres pour chaque annÃ©e
        for i, year in enumerate(available_years):
            if year in pivot_data.columns:
                values = []
                for month in range(1, 13):
                    if month in pivot_data.index and pd.notna(pivot_data.loc[month, year]):
                        values.append(pivot_data.loc[month, year])
                    else:
                        values.append(0)  # 0 pour les mois sans donnÃ©es
                
                color = sunshine_colors[i % len(sunshine_colors)]
                offset = (i - n_years/2 + 0.5) * width
                
                # Style spÃ©cial pour l'annÃ©e courante
                if year == current_year:
                    bars = ax.bar(x + offset, values, width,
                                 label=f'â˜€ï¸ {year} (actuelle)', color=color,
                                 alpha=0.9, edgecolor='white', linewidth=2,
                                 zorder=5)
                    # Ajouter des valeurs sur les barres de l'annÃ©e courante
                    for j, bar in enumerate(bars):
                        if values[j] > 0:
                            ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,
                                   f'{values[j]:.0f}h', ha='center', va='bottom',
                                   fontsize=9, fontweight='bold', color=color)
                else:
                    ax.bar(x + offset, values, width,
                          label=f'ğŸŒ¤ï¸ {year}', color=color,
                          alpha=0.7, edgecolor='white', linewidth=1,
                          zorder=3)
        
        # Mise en Ã©vidence du mois actuel
        current_month = pd.Timestamp.now(tz='Europe/Berlin').month
        ax.axvspan(current_month - 1 - 0.4, current_month - 1 + 0.4,
                  alpha=0.2, color='#f39c12', zorder=1,
                  label=f"ğŸ“ Mois actuel ({month_names[current_month-1]})")
        
        # Titre moderne avec emojis
        ax.set_title(f'â˜€ï¸ Ensoleillement mensuel par annÃ©e - {VILLE}\n'
                    f'ğŸ“Š Comparaison de {len(available_years)} annÃ©es de donnÃ©es',
                    fontsize=18, fontweight='bold', color='#2c3e50', pad=25)
        
        # Labels modernes avec emojis
        ax.set_xlabel('ğŸ“… Mois', fontsize=14, color='#2c3e50', fontweight='bold')
        ax.set_ylabel('â˜€ï¸ Heures d\'ensoleillement', fontsize=14, color='#2c3e50', fontweight='bold')
        
        # Configurer l'axe X avec les noms des mois
        ax.set_xticks(x)
        ax.set_xticklabels(month_names)
        
        # Style moderne des axes
        ax.spines['top'].set_visible(False)
        ax.spines['right'].set_visible(False)
        ax.spines['left'].set_color('#bdc3c7')
        ax.spines['bottom'].set_color('#bdc3c7')
        ax.tick_params(colors='#34495e', labelsize=11)
        
        # LÃ©gende moderne
        legend = ax.legend(bbox_to_anchor=(1.02, 1), loc='upper left',
                          frameon=True, shadow=True, fancybox=True,
                          framealpha=0.95, edgecolor='#bdc3c7')
        legend.get_frame().set_facecolor('#ffffff')
        
        # Zones saisonniÃ¨res en arriÃ¨re-plan
        ax.axvspan(-0.5, 1.5, alpha=0.05, color='#74b9ff')    # Hiver
        ax.axvspan(1.5, 4.5, alpha=0.05, color='#55a3ff')     # Printemps
        ax.axvspan(4.5, 7.5, alpha=0.05, color='#fdcb6e')     # Ã‰tÃ©
        ax.axvspan(7.5, 10.5, alpha=0.05, color='#e17055')    # Automne
        ax.axvspan(10.5, 11.5, alpha=0.05, color='#74b9ff')   # Hiver
        
        # Grille moderne
        ax.grid(True, alpha=0.3, linestyle=':', linewidth=1, axis='y')
        
        plt.tight_layout()
        
        # Statistiques pour la lÃ©gende
        stats_text = ""
        if len(available_years) > 1:
            # Calculer la moyenne par mois sur toutes les annÃ©es
            monthly_averages = sunshine_df.groupby('month')['sunshine_hours'].mean()
            best_month = monthly_averages.idxmax()
            worst_month = monthly_averages.idxmin()
            
            stats_text += f"ğŸ“Š Statistiques globales:\n"
            stats_text += f"â˜€ï¸ Meilleur mois: {month_names[best_month-1]} ({monthly_averages[best_month]:.1f}h)\n"
            stats_text += f"â˜ï¸ Moins ensoleillÃ©: {month_names[worst_month-1]} ({monthly_averages[worst_month]:.1f}h)\n"
            
            # DonnÃ©es pour le mois actuel
            current_month_data = sunshine_df[sunshine_df['month'] == current_month]
            if not current_month_data.empty:
                current_month_avg = current_month_data['sunshine_hours'].mean()
                stats_text += f"ğŸ“ Mois actuel (moy.): {current_month_avg:.1f}h"
        
        caption = (f"â˜€ï¸ Ensoleillement mensuel en barres - {len(available_years)} annÃ©es\n"
                  f"ğŸ“… AnnÃ©es: {min(available_years)}-{max(available_years)}\n"
                  f"{stats_text}")
        
        await send_graph(message.chat.id, fig, caption)
        
    except pd.errors.EmptyDataError:
        await message.reply("Le fichier de donnÃ©es est vide, impossible de calculer l'ensoleillement.")
    except FileNotFoundError:
        await message.reply("Fichier de donnÃ©es non trouvÃ© pour calculer l'ensoleillement.")
    except Exception as e:
        await log_message(f"Error in get_sunshine_summary_command: {str(e)}\n{traceback.format_exc()}")
        await message.reply("Erreur lors de l'obtention du rÃ©sumÃ© de l'ensoleillement.")


@router.message(Command("month"))
async def get_month_summary_command(message: types.Message): # RenommÃ©
    await send_month_summary(message.chat.id)

@router.message(Command("year"))
async def get_year_summary_command(message: types.Message): # RenommÃ©
    await send_year_summary(message.chat.id)

@router.message(Command("all"))
async def get_all_summary_command(message: types.Message): # RenommÃ©
    await send_all_summary(message.chat.id)

@router.message(Command("daterange"))
async def get_daterange_summary_command(message: types.Message):
    """GÃ©nÃ¨re un rÃ©sumÃ© entre deux dates. Usage: /daterange 2024-01-01 2024-12-31"""
    try:
        # Parser les arguments
        args = message.text.split()
        if len(args) != 3:
            await message.reply(
                "Usage: /daterange YYYY-MM-DD YYYY-MM-DD\n"
                "Exemple: /daterange 2024-01-01 2024-12-31"
            )
            return
        
        start_date = parse_date_input(args[1])
        end_date = parse_date_input(args[2])
        
        if not start_date or not end_date:
            await message.reply(
                "Format de date invalide. Utilisez YYYY-MM-DD\n"
                "Exemple: /daterange 2024-01-01 2024-12-31"
            )
            return
        
        if start_date > end_date:
            await message.reply("La date de dÃ©but doit Ãªtre antÃ©rieure Ã  la date de fin.")
            return
        
        # Lire et filtrer les donnÃ©es
        if not os.path.exists(csv_filename) or os.path.getsize(csv_filename) == 0:
            await message.reply("Aucune donnÃ©e mÃ©tÃ©o disponible.")
            return
        
        df = pd.read_csv(csv_filename)
        if df.empty:
            await message.reply("Aucune donnÃ©e disponible dans le fichier.")
            return
        
        df['time'] = pd.to_datetime(df['time'], utc=True, errors='coerce')
        df.dropna(subset=['time'], inplace=True)
        
        # Filtrer selon la pÃ©riode
        df_period = df[(df['time'] >= start_date) & (df['time'] <= end_date)].copy()
        
        if df_period.empty:
            period_str = f"{start_date.strftime('%Y-%m-%d')} Ã  {end_date.strftime('%Y-%m-%d')}"
            await message.reply(f"Aucune donnÃ©e disponible pour la pÃ©riode sÃ©lectionnÃ©e ({period_str}).")
            return
        
        # GÃ©nÃ©rer le rÃ©sumÃ©
        summary = generate_summary(df_period)
        period_str = f"du {start_date.strftime('%d/%m/%Y')} au {end_date.strftime('%d/%m/%Y')}"
        
        message_text = f"ğŸ“… RÃ©sumÃ© mÃ©tÃ©o {period_str} pour {VILLE}:\n\n{summary}"
        await message.reply(message_text)
        await log_message(f"RÃ©sumÃ© pÃ©riode {period_str} envoyÃ© Ã  chat_id: {message.chat.id}")
        
    except Exception as e:
        await log_message(f"Erreur dans daterange_command: {str(e)}\n{traceback.format_exc()}")
        await message.reply("Erreur lors de la gÃ©nÃ©ration du rÃ©sumÃ© pour cette pÃ©riode.")

@router.message(Command("top10"))
async def get_top10_command(message: types.Message):
    """Affiche le top 10 des valeurs pour une mÃ©trique. Usage: /top10 temperature"""
    try:
        # Parser les arguments
        args = message.text.split()
        if len(args) != 2:
            metrics_list = "temperature, rain, wind, pressure, uv, humidity"
            await message.reply(
                f"Usage: /top10 <mÃ©trique>\n"
                f"MÃ©triques disponibles: {metrics_list}\n"
                f"Exemple: /top10 temperature"
            )
            return
        
        metric_arg = args[1].lower()
        
        # Mapping des arguments vers les colonnes CSV
        metric_mapping = {
            'temperature': 'temperature_2m',
            'temp': 'temperature_2m',
            'rain': 'precipitation',
            'precipitation': 'precipitation',
            'wind': 'windspeed_10m',
            'pressure': 'pressure_msl',
            'uv': 'uv_index',
            'humidity': 'relativehumidity_2m'
        }
        
        if metric_arg not in metric_mapping:
            await message.reply(
                f"MÃ©trique '{metric_arg}' non reconnue.\n"
                f"Utilisez: temperature, rain, wind, pressure, uv, humidity"
            )
            return
        
        column_name = metric_mapping[metric_arg]
        metric_info = get_metric_info(column_name)
        
        # Lire les donnÃ©es
        if not os.path.exists(csv_filename) or os.path.getsize(csv_filename) == 0:
            await message.reply("Aucune donnÃ©e mÃ©tÃ©o disponible.")
            return
        
        df = pd.read_csv(csv_filename)
        if df.empty:
            await message.reply("Aucune donnÃ©e disponible.")
            return
        
        df['time'] = pd.to_datetime(df['time'], utc=True, errors='coerce')
        df.dropna(subset=['time'], inplace=True)
        
        # Filtrer pour ne garder que les mois complets (incluant le mois en cours) pour cette mÃ©trique
        df_complete = filter_complete_months_only(df, exclude_current_month=False, metric_column=column_name)
        
        if column_name not in df_complete.columns:
            await message.reply(f"DonnÃ©es pour {metric_info['name']} non disponibles.")
            return
        
        # Nettoyer les donnÃ©es et enlever les NaN
        df_clean = df_complete.dropna(subset=[column_name]).copy()
        if df_clean.empty:
            await message.reply(f"Aucune donnÃ©e valide pour {metric_info['name']}.")
            return
        
        # Top 10 des valeurs maximales
        top_max = df_clean.nlargest(10, column_name)
        # Top 10 des valeurs minimales (pour tempÃ©rature principalement)
        top_min = df_clean.nsmallest(10, column_name) if metric_arg in ['temperature', 'temp'] else None
        
        # Construire le message
        response = f"{metric_info['emoji']} **Top 10 - {metric_info['name']}** Ã  {VILLE}\n\n"
        
        # Top maximales
        response += f"ğŸ”¥ **Valeurs les plus Ã©levÃ©es:**\n"
        for i, (_, row) in enumerate(top_max.iterrows(), 1):
            time_local = row['time'].tz_convert('Europe/Berlin')
            date_str = time_local.strftime('%d/%m/%Y Ã  %H:%M')
            value = row[column_name]
            response += f"{i:2d}. {value:.1f}{metric_info['unit']} - {date_str}\n"
        
        # Top minimales (seulement pour tempÃ©rature)
        if top_min is not None:
            response += f"\nâ„ï¸ **Valeurs les plus basses:**\n"
            for i, (_, row) in enumerate(top_min.iterrows(), 1):
                time_local = row['time'].tz_convert('Europe/Berlin')
                date_str = time_local.strftime('%d/%m/%Y Ã  %H:%M')
                value = row[column_name]
                response += f"{i:2d}. {value:.1f}{metric_info['unit']} - {date_str}\n"
        
        await message.reply(response)
        await log_message(f"Top 10 {metric_info['name']} envoyÃ© Ã  chat_id: {message.chat.id}")
        
    except Exception as e:
        await log_message(f"Erreur dans top10_command: {str(e)}\n{traceback.format_exc()}")
        await message.reply("Erreur lors de la gÃ©nÃ©ration du top 10.")

@router.message(Command("forecastgraph"))
async def get_forecast_graph_command(message: types.Message):
    """GÃ©nÃ¨re un graphique des prÃ©visions mÃ©tÃ©o pour les prochaines 24h."""
    try:
        # Utiliser le cache au lieu d'appeler directement l'API
        _, df_next_twenty_four_hours = await get_cached_forecast_data()
        
        if df_next_twenty_four_hours.empty:
            await message.reply("Aucune donnÃ©e de prÃ©vision disponible pour le moment.")
            return
        
        # Limiter aux 24 prochaines heures
        forecast_df = df_next_twenty_four_hours.head(24).copy()
        
        if forecast_df.empty:
            await message.reply("DonnÃ©es de prÃ©vision insuffisantes.")
            return
        
        # Convertir en heure locale pour l'affichage
        forecast_df['local_time'] = forecast_df['time'].dt.tz_convert('Europe/Berlin')
        
        # CrÃ©er le graphique avec style moderne
        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10))
        fig.suptitle(f'ğŸŒ¤ï¸ PrÃ©visions mÃ©tÃ©o pour {VILLE} - Prochaines 24h',
                    fontsize=18, fontweight='bold', y=0.95, color='#2c3e50')
        
        # Graphique tempÃ©rature avec gradient
        temps = forecast_df['local_time']
        temperatures = forecast_df['temperature_2m']
        
        # Ligne principale tempÃ©rature avec gradient de couleur
        points = ax1.scatter(temps, temperatures, c=temperatures, cmap='RdYlBu_r',
                           s=60, alpha=0.8, edgecolors='white', linewidth=1.5, zorder=5)
        ax1.plot(temps, temperatures, linewidth=3, alpha=0.7, color='#34495e', zorder=4)
        
        # Zone de fond gradient selon tempÃ©rature
        for i in range(len(forecast_df)-1):
            temp = forecast_df.iloc[i]['temperature_2m']
            if temp > 25:
                color = '#ff6b6b'  # Rouge moderne
                alpha = 0.15
            elif temp < 5:
                color = '#74b9ff'  # Bleu moderne
                alpha = 0.15
            else:
                color = '#55a3ff'  # Vert moderne
                alpha = 0.08
            ax1.axvspan(temps.iloc[i], temps.iloc[i+1], color=color, alpha=alpha)
        
        ax1.set_ylabel('ğŸŒ¡ï¸ TempÃ©rature (Â°C)', fontsize=12, color='#2c3e50')
        ax1.tick_params(colors='#34495e')
        
        # Colorbar pour la tempÃ©rature
        cbar = plt.colorbar(points, ax=ax1, pad=0.02, aspect=30)
        cbar.set_label('Â°C', rotation=0, labelpad=15, color='#2c3e50')
        
        # Graphique prÃ©cipitations moderne avec gradient MeteoSuisse
        def get_precipitation_color(precip_mm):
            """Couleurs graduÃ©es selon l'intensitÃ© des prÃ©cipitations (style MeteoSuisse)."""
            if precip_mm < 0.1:
                return '#f8f9fa'      # Blanc/transparent (pas de pluie)
            elif precip_mm < 1.0:
                return '#cce7ff'      # Bleu trÃ¨s clair (bruine)
            elif precip_mm < 2.5:
                return '#74b9ff'      # Bleu clair (faible)
            elif precip_mm < 5.0:
                return '#4a90e2'      # Bleu moyen (modÃ©rÃ©)
            elif precip_mm < 10.0:
                return '#2563eb'      # Bleu foncÃ© (fort)
            elif precip_mm < 25.0:
                return '#7c3aed'      # Violet (trÃ¨s fort)
            elif precip_mm < 50.0:
                return '#dc2626'      # Rouge (intense)
            else:
                return '#991b1b'      # Rouge foncÃ© (extrÃªme)
        
        colors_precip = [get_precipitation_color(p) for p in forecast_df['precipitation']]
        bars = ax2.bar(temps, forecast_df['precipitation'], width=0.03,
                      color=colors_precip, alpha=0.9, edgecolor='white', linewidth=0.5)
        
        # Ajouter lÃ©gende des couleurs prÃ©cipitations (style MeteoSuisse)
        max_precip = forecast_df['precipitation'].max()
        if max_precip > 0.1:  # Seulement si il y a des prÃ©cipitations
            legend_text = "PrÃ©cipitations: "
            if max_precip >= 25.0:
                legend_text += "ğŸ”´ ExtrÃªme"
            elif max_precip >= 10.0:
                legend_text += "ğŸŸ£ TrÃ¨s fort"
            elif max_precip >= 5.0:
                legend_text += "ğŸ”µ Fort"
            elif max_precip >= 2.5:
                legend_text += "ğŸŸ¦ ModÃ©rÃ©"
            elif max_precip >= 1.0:
                legend_text += "ğŸ’™ Faible"
            else:
                legend_text += "ğŸ’§ Bruine"
            
            ax2.text(0.02, 0.95, legend_text, transform=ax2.transAxes,
                    fontsize=10, verticalalignment='top',
                    bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))
        
        # Ligne probabilitÃ© avec style moderne
        ax2_twin = ax2.twinx()
        ax2_twin.plot(temps, forecast_df['precipitation_probability'],
                     color='#00b894', linewidth=3, marker='o', markersize=4,
                     alpha=0.9, label='ProbabilitÃ© pluie', markerfacecolor='white',
                     markeredgecolor='#00b894', markeredgewidth=2)
        
        ax2.set_ylabel('ğŸ’§ PrÃ©cipitations (mm)', color='#2c3e50')
        ax2_twin.set_ylabel('â˜” ProbabilitÃ© (%)', color='#00b894')
        ax2.set_xlabel('ğŸ• Heure locale', color='#2c3e50')
        
        # Style des axes
        for ax in [ax1, ax2, ax2_twin]:
            ax.tick_params(colors='#34495e')
            ax.spines['top'].set_visible(False)
            ax.spines['right'].set_visible(False) if ax != ax2_twin else None
            ax.spines['left'].set_color('#bdc3c7')
            ax.spines['bottom'].set_color('#bdc3c7')
        
        # Formatage des axes temporels
        for ax in [ax1, ax2]:
            ax.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))
            ax.xaxis.set_major_locator(mdates.HourLocator(interval=3))
            plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)
        
        # LÃ©gendes
        lines1, labels1 = ax2.get_legend_handles_labels()
        lines2, labels2 = ax2_twin.get_legend_handles_labels()
        ax2.legend(lines1 + lines2, labels1 + labels2, loc='upper left')
        
        plt.tight_layout()
        
        # Ajouter des informations textuelles
        temp_moy = forecast_df['temperature_2m'].mean()
        precip_total = forecast_df['precipitation'].sum()
        
        caption = (f"ğŸ”® PrÃ©visions 24h pour {VILLE}\n"
                  f"ğŸŒ¡ï¸ TempÃ©rature moyenne: {temp_moy:.1f}Â°C\n"
                  f"ğŸŒ§ï¸ PrÃ©cipitations totales prÃ©vues: {precip_total:.1f}mm")
        
        await send_graph(message.chat.id, fig, caption)
        
    except Exception as e:
        await log_message(f"Erreur dans forecastgraph_command: {str(e)}\n{traceback.format_exc()}")
        await message.reply("Erreur lors de la gÃ©nÃ©ration du graphique de prÃ©visions.")

@router.message(Command("graph"))
async def get_graph_data_command(message: types.Message):
    """GÃ©nÃ¨re 2 graphiques pour une mÃ©trique spÃ©cifique (courbe + barres). Usage: /graph temperature"""
    try:
        # Parser les arguments
        args = message.text.split()
        if len(args) not in [2, 3]:
            await message.reply(
                "Usage: /graph <mÃ©trique> [jours]\n"
                "MÃ©triques: temperature, rain, wind, pressure, uv, humidity\n"
                "Exemple: /graph temperature 30"
            )
            return
        
        metric_arg = args[1].lower()
        days = int(args[2]) if len(args) == 3 else 30
        
        if days <= 0 or days > 365:
            await message.reply("Le nombre de jours doit Ãªtre entre 1 et 365.")
            return
        
        # Mapping des arguments
        metric_mapping = {
            'temperature': 'temperature_2m',
            'temp': 'temperature_2m',
            'rain': 'precipitation',
            'precipitation': 'precipitation',
            'wind': 'windspeed_10m',
            'pressure': 'pressure_msl',
            'uv': 'uv_index',
            'humidity': 'relativehumidity_2m'
        }
        
        if metric_arg not in metric_mapping:
            await message.reply(
                f"MÃ©trique '{metric_arg}' non reconnue.\n"
                f"Utilisez: temperature, rain, wind, pressure, uv, humidity"
            )
            return
        
        column_name = metric_mapping[metric_arg]
        metric_info = get_metric_info(column_name)
        
        # Lire et filtrer les donnÃ©es
        if not os.path.exists(csv_filename) or os.path.getsize(csv_filename) == 0:
            await message.reply("Aucune donnÃ©e mÃ©tÃ©o disponible.")
            return
        
        df = pd.read_csv(csv_filename)
        if df.empty:
            await message.reply("Aucune donnÃ©e disponible.")
            return
        
        df['time'] = pd.to_datetime(df['time'], utc=True, errors='coerce')
        df.dropna(subset=['time'], inplace=True)
        
        # Filtrer pour ne garder que les mois complets (incluant le mois en cours) pour cette mÃ©trique
        df_complete = filter_complete_months_only(df, exclude_current_month=False, metric_column=column_name)
        
        if column_name not in df_complete.columns:
            await message.reply(f"DonnÃ©es pour {metric_info['name']} non disponibles.")
            return
        
        # Filtrer les derniers N jours
        now = pd.Timestamp.now(tz='UTC')
        start_date = now - pd.Timedelta(days=days)
        df_period = df_complete[(df_complete['time'] >= start_date) & (df_complete['time'] <= now)].copy()
        
        if df_period.empty:
            await message.reply(f"Aucune donnÃ©e disponible pour les {days} derniers jours.")
            return
        
        # Nettoyer les donnÃ©es
        df_period = df_period.dropna(subset=[column_name])
        if df_period.empty:
            await message.reply(f"Aucune donnÃ©e valide pour {metric_info['name']} sur cette pÃ©riode.")
            return
        
        # Convertir en heure locale
        df_period['local_time'] = df_period['time'].dt.tz_convert('Europe/Berlin')
        
        # Couleurs modernes selon la mÃ©trique
        colors = {
            'temperature_2m': '#e74c3c',      # Rouge moderne
            'precipitation': '#3498db',       # Bleu moderne
            'windspeed_10m': '#2ecc71',      # Vert moderne
            'pressure_msl': '#9b59b6',       # Violet moderne
            'uv_index': '#f39c12',           # Orange moderne
            'relativehumidity_2m': '#1abc9c' # Turquoise moderne
        }
        
        color = colors.get(column_name, '#34495e')
        
        # Statistiques communes
        data_values = df_period[column_name]
        mean_val = data_values.mean()
        max_val = data_values.max()
        min_val = data_values.min()
        
        base_caption = (f"{metric_info['emoji']} {metric_info['name']} - {days} derniers jours\n"
                       f"ğŸ“Š Moyenne: {mean_val:.1f}{metric_info['unit']}\n"
                       f"ğŸ“ˆ Maximum: {max_val:.1f}{metric_info['unit']}\n"
                       f"ğŸ“‰ Minimum: {min_val:.1f}{metric_info['unit']}")
        
        # === GRAPHIQUE 1: COURBE (style actuel) ===
        fig1, ax1 = plt.subplots(1, 1, figsize=(14, 8))
        
        if metric_arg in ['rain', 'precipitation']:
            # Graphique en barres pour les prÃ©cipitations avec gradient MeteoSuisse
            def get_precipitation_color(precip_mm):
                """Couleurs graduÃ©es selon l'intensitÃ© des prÃ©cipitations (style MeteoSuisse)."""
                if precip_mm < 0.1:
                    return '#f8f9fa'      # Blanc/transparent (pas de pluie)
                elif precip_mm < 1.0:
                    return '#cce7ff'      # Bleu trÃ¨s clair (bruine)
                elif precip_mm < 2.5:
                    return '#74b9ff'      # Bleu clair (faible)
                elif precip_mm < 5.0:
                    return '#4a90e2'      # Bleu moyen (modÃ©rÃ©)
                elif precip_mm < 10.0:
                    return '#2563eb'      # Bleu foncÃ© (fort)
                elif precip_mm < 25.0:
                    return '#7c3aed'      # Violet (trÃ¨s fort)
                elif precip_mm < 50.0:
                    return '#dc2626'      # Rouge (intense)
                else:
                    return '#991b1b'      # Rouge foncÃ© (extrÃªme)
            
            colors_precip = [get_precipitation_color(p) for p in df_period[column_name]]
            bars = ax1.bar(df_period['local_time'], df_period[column_name],
                          width=0.02, color=colors_precip, alpha=0.9, edgecolor='white', linewidth=0.5)
            
            # Ajouter lÃ©gende des couleurs si prÃ©cipitations significatives
            max_precip = df_period[column_name].max()
            if max_precip > 0.1:
                legend_text = "IntensitÃ© max: "
                if max_precip >= 25.0:
                    legend_text += "ğŸ”´ ExtrÃªme"
                elif max_precip >= 10.0:
                    legend_text += "ğŸŸ£ TrÃ¨s fort"
                elif max_precip >= 5.0:
                    legend_text += "ğŸ”µ Fort"
                elif max_precip >= 2.5:
                    legend_text += "ğŸŸ¦ ModÃ©rÃ©"
                elif max_precip >= 1.0:
                    legend_text += "ğŸ’™ Faible"
                else:
                    legend_text += "ğŸ’§ Bruine"
                
                ax1.text(0.02, 0.95, legend_text, transform=ax1.transAxes,
                        fontsize=10, verticalalignment='top',
                        bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))
        else:
            # Graphique en ligne moderne avec zone remplie
            ax1.fill_between(df_period['local_time'], df_period[column_name],
                            alpha=0.3, color=color, interpolate=True)
            ax1.plot(df_period['local_time'], df_period[column_name],
                    color=color, linewidth=3, alpha=0.9, marker='o',
                    markersize=2, markerfacecolor='white', markeredgecolor=color)
            
            # Moyenne mobile avec style moderne
            if len(df_period) > 24:
                df_period['moving_avg'] = df_period[column_name].rolling(window=24, center=True).mean()
                ax1.plot(df_period['local_time'], df_period['moving_avg'],
                        color='#2c3e50', linewidth=3, alpha=0.8,
                        linestyle='--', label='ğŸ“ˆ Moyenne mobile 24h')
                ax1.legend(loc='upper right', frameon=True, shadow=True,
                          fancybox=True, framealpha=0.9)
        
        # Titre et style pour graphique 1
        ax1.set_title(f'ğŸ“Š {metric_info["emoji"]} {metric_info["name"]} (courbe) - {days} derniers jours Ã  {VILLE}',
                     fontsize=16, fontweight='bold', color='#2c3e50', pad=20)
        ax1.set_ylabel(f'{metric_info["emoji"]} {metric_info["name"]} ({metric_info["unit"]})',
                      fontsize=12, color='#2c3e50')
        ax1.set_xlabel('ğŸ“… Date', fontsize=12, color='#2c3e50')
        
        # Style moderne des axes
        ax1.spines['top'].set_visible(False)
        ax1.spines['right'].set_visible(False)
        ax1.spines['left'].set_color('#bdc3c7')
        ax1.spines['bottom'].set_color('#bdc3c7')
        ax1.tick_params(colors='#34495e')
        
        # Formatage temporal et grille
        if days <= 7:
            ax1.xaxis.set_major_formatter(mdates.DateFormatter('%d/%m\n%H:%M'))
            ax1.xaxis.set_major_locator(mdates.HourLocator(interval=12))
        elif days <= 30:
            ax1.xaxis.set_major_formatter(mdates.DateFormatter('%d/%m'))
            ax1.xaxis.set_major_locator(mdates.DayLocator(interval=3))
        else:
            ax1.xaxis.set_major_formatter(mdates.DateFormatter('%d/%m'))
            ax1.xaxis.set_major_locator(mdates.WeekdayLocator(interval=1))
        
        plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45, fontsize=10)
        ax1.grid(True, alpha=0.3, linestyle=':', linewidth=0.5)
        plt.tight_layout()
        
        # Envoyer le premier graphique (courbe)
        caption1 = f"ğŸ“Š Graphique en courbe\n{base_caption}"
        await send_graph(message.chat.id, fig1, caption1)
        
        # === GRAPHIQUE 2: BARRES VERTICALES (style sunshine - par mois/annÃ©e) ===
        fig2, ax2 = plt.subplots(1, 1, figsize=(16, 10))
        fig2.patch.set_facecolor('#f8f9fa')
        
        # PrÃ©parer donnÃ©es mensuelles groupÃ©es par annÃ©e (style sunshine)
        df_bars = df_period.copy()
        df_bars['year'] = df_bars['local_time'].dt.year
        df_bars['month'] = df_bars['local_time'].dt.month
        
        # Calculer valeurs mensuelles selon le type de mÃ©trique
        if metric_arg in ['rain', 'precipitation']:
            monthly_data = df_bars.groupby(['year', 'month'])[column_name].sum().reset_index()
        else:
            monthly_data = df_bars.groupby(['year', 'month'])[column_name].mean().reset_index()
        
        if monthly_data.empty:
            # Fallback vers donnÃ©es journaliÃ¨res si pas assez pour mensuel
            df_bars['date'] = df_bars['local_time'].dt.date
            if metric_arg in ['rain', 'precipitation']:
                daily_data = df_bars.groupby('date')[column_name].sum().reset_index()
            else:
                daily_data = df_bars.groupby('date')[column_name].mean().reset_index()
            
            daily_data['datetime'] = pd.to_datetime(daily_data['date'])
            bars = ax2.bar(daily_data['datetime'], daily_data[column_name],
                          width=0.8, color=color, alpha=0.8, edgecolor='white', linewidth=1)
            
            ax2.set_title(f'ğŸ“Š {metric_info["emoji"]} {metric_info["name"]} (barres journaliÃ¨res) - {days} derniers jours Ã  {VILLE}',
                         fontsize=16, fontweight='bold', color='#2c3e50', pad=20)
            ax2.xaxis.set_major_formatter(mdates.DateFormatter('%d/%m'))
            ax2.xaxis.set_major_locator(mdates.DayLocator(interval=max(1, days//15)))
        else:
            # Style sunshine : barres groupÃ©es par annÃ©e pour chaque mois
            available_years = sorted(monthly_data['year'].unique())
            available_months = sorted(monthly_data['month'].unique())
            
            # Noms des mois
            month_names = ['Jan', 'FÃ©v', 'Mar', 'Avr', 'Mai', 'Jun',
                          'Jul', 'AoÃ»', 'Sep', 'Oct', 'Nov', 'DÃ©c']
            
            # Couleurs pour les annÃ©es
            year_colors = ['#e74c3c', '#3498db', '#2ecc71', '#f39c12', '#9b59b6']
            
            # CrÃ©er les barres groupÃ©es
            x_positions = np.arange(len(available_months))
            n_years = len(available_years)
            width = 0.8 / n_years
            
            for i, year in enumerate(available_years):
                year_data = monthly_data[monthly_data['year'] == year]
                values = []
                
                for month in available_months:
                    month_row = year_data[year_data['month'] == month]
                    if not month_row.empty:
                        values.append(month_row[column_name].iloc[0])
                    else:
                        values.append(0)
                
                year_color = year_colors[i % len(year_colors)]
                offset = (i - n_years/2 + 0.5) * width
                
                bars = ax2.bar(x_positions + offset, values, width,
                              label=f'ğŸ“… {year}', color=year_color,
                              alpha=0.8, edgecolor='white', linewidth=1)
                
                # Ajouter valeurs sur les barres
                for j, bar in enumerate(bars):
                    height = bar.get_height()
                    if height > 0:
                        ax2.text(bar.get_x() + bar.get_width()/2, height + max(values)*0.01,
                               f'{height:.0f}', ha='center', va='bottom',
                               fontsize=8, fontweight='bold', color=year_color)
            
            # Configuration des axes pour style mensuel
            ax2.set_xticks(x_positions)
            ax2.set_xticklabels([month_names[m-1] for m in available_months])
            ax2.set_title(f'ğŸ“Š {metric_info["emoji"]} {metric_info["name"]} (barres mensuelles) - {len(available_years)} annÃ©es Ã  {VILLE}',
                         fontsize=16, fontweight='bold', color='#2c3e50', pad=20)
            
            # LÃ©gende moderne
            legend = ax2.legend(bbox_to_anchor=(1.02, 1), loc='upper left',
                               frameon=True, shadow=True, fancybox=True,
                               framealpha=0.95, edgecolor='#bdc3c7')
            legend.get_frame().set_facecolor('#ffffff')
        
        # Style commun des axes
        ax2.set_ylabel(f'{metric_info["emoji"]} {metric_info["name"]} ({metric_info["unit"]})',
                      fontsize=14, color='#2c3e50', fontweight='bold')
        ax2.set_xlabel('ğŸ“… PÃ©riode', fontsize=14, color='#2c3e50', fontweight='bold')
        
        ax2.spines['top'].set_visible(False)
        ax2.spines['right'].set_visible(False)
        ax2.spines['left'].set_color('#bdc3c7')
        ax2.spines['bottom'].set_color('#bdc3c7')
        ax2.tick_params(colors='#34495e', labelsize=11)
        
        plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45, fontsize=10)
        ax2.grid(True, alpha=0.3, linestyle=':', linewidth=1, axis='y')
        plt.tight_layout()
        
        # Envoyer le deuxiÃ¨me graphique (barres)
        caption2 = f"ğŸ“Š Graphique en barres\n{base_caption}"
        await send_graph(message.chat.id, fig2, caption2)
        
    except ValueError as e:
        await message.reply("Le nombre de jours doit Ãªtre un nombre entier valide.")
    except Exception as e:
        await log_message(f"Erreur dans graphdata_command: {str(e)}\n{traceback.format_exc()}")
        await message.reply("Erreur lors de la gÃ©nÃ©ration des graphiques.")

@router.message(Command("heatmap"))
async def get_heatmap_command(message: types.Message):
    """GÃ©nÃ¨re une heatmap calendaire des tempÃ©ratures. Usage: /heatmap [annÃ©e]"""
    try:
        # Parser les arguments
        args = message.text.split()
        current_year = pd.Timestamp.now(tz='UTC').year
        
        # Gestion du paramÃ¨tre "all"
        if len(args) == 2 and args[1].lower() == 'all':
            target_year = 'all'
        elif len(args) == 2:
            try:
                target_year = int(args[1])
                if target_year < 2020 or target_year > current_year + 1:
                    await message.reply(f"AnnÃ©e invalide. Utilisez une annÃ©e entre 2020 et {current_year}, ou 'all' pour toutes les annÃ©es.")
                    return
            except ValueError:
                await message.reply(f"Format invalide. Utilisez: /heatmap [annÃ©e] ou /heatmap all")
                return
        else:
            target_year = current_year
        
        # Lire les donnÃ©es
        if not os.path.exists(csv_filename) or os.path.getsize(csv_filename) == 0:
            await message.reply("Aucune donnÃ©e mÃ©tÃ©o disponible.")
            return
        
        df = pd.read_csv(csv_filename)
        if df.empty:
            await message.reply("Aucune donnÃ©e disponible.")
            return
        
        df['time'] = pd.to_datetime(df['time'], utc=True, errors='coerce')
        df.dropna(subset=['time'], inplace=True)
        
        # Filtrer pour ne garder que les mois complets (incluant le mois en cours) pour la tempÃ©rature
        df_complete = filter_complete_months_only(df, exclude_current_month=False, metric_column='temperature_2m')
        
        if 'temperature_2m' not in df_complete.columns:
            await message.reply("DonnÃ©es de tempÃ©rature non disponibles.")
            return
        
        if target_year == 'all':
            # Mode multi-annÃ©es : toutes les annÃ©es disponibles
            df_complete['local_time'] = df_complete['time'].dt.tz_convert('Europe/Berlin')
            df_complete['date'] = df_complete['local_time'].dt.date
            df_complete['year'] = df_complete['local_time'].dt.year
            
            available_years = sorted(df_complete['year'].unique())
            if len(available_years) == 0:
                await message.reply("Aucune donnÃ©e disponible.")
                return
                
            # Calculer moyennes journaliÃ¨res par annÃ©e
            daily_temps = df_complete.groupby(['year', 'date'])['temperature_2m'].mean().reset_index()
            
            if daily_temps.empty:
                await message.reply("Aucune donnÃ©e de tempÃ©rature valide.")
                return
            
            # CrÃ©er une heatmap multi-annÃ©es (annÃ©es x jours de l'annÃ©e)
            num_years = len(available_years)
            temp_matrix = np.full((366, num_years), np.nan)  # 366 jours max, n annÃ©es
            
            for year_idx, year in enumerate(available_years):
                year_data = daily_temps[daily_temps['year'] == year]
                for _, row in year_data.iterrows():
                    day_of_year = pd.to_datetime(row['date']).timetuple().tm_yday - 1  # 0-indexÃ©
                    if 0 <= day_of_year < 366:
                        temp_matrix[day_of_year, year_idx] = row['temperature_2m']
                        
            # Configuration pour mode multi-annÃ©es
            matrix_to_plot = temp_matrix.T  # Transposer pour avoir annÃ©es en Y
            xlabel_text = 'ğŸ“… Jour de l\'annÃ©e'
            ylabel_text = 'ğŸ“… AnnÃ©e'
            title_text = f'ğŸŒ¡ï¸ Calendrier thermique multi-annÃ©es - {VILLE}\nğŸ“Š {len(available_years)} annÃ©es de donnÃ©es'
            
            # Positions et labels pour l'axe X (jours de l'annÃ©e)
            month_starts = [1, 32, 60, 91, 121, 152, 182, 213, 244, 274, 305, 335]
            month_names = ['Jan', 'FÃ©v', 'Mar', 'Avr', 'Mai', 'Jun',
                          'Jul', 'AoÃ»', 'Sep', 'Oct', 'Nov', 'DÃ©c']
            x_positions = month_starts
            x_labels = month_names
            
            # Positions et labels pour l'axe Y (annÃ©es)
            y_positions = range(len(available_years))
            y_labels = [f'ğŸ“… {year}' for year in available_years]
            
        else:
            # Mode annÃ©e unique (code existant)
            df_year = df_complete[df_complete['time'].dt.year == target_year].copy()
            if df_year.empty:
                await message.reply(f"Aucune donnÃ©e disponible pour l'annÃ©e {target_year}.")
                return
            
            # Convertir en heure locale et calculer moyennes journaliÃ¨res
            df_year['local_time'] = df_year['time'].dt.tz_convert('Europe/Berlin')
            df_year['date'] = df_year['local_time'].dt.date
            daily_temps = df_year.groupby('date')['temperature_2m'].mean().reset_index()
            
            if daily_temps.empty:
                await message.reply(f"Aucune donnÃ©e de tempÃ©rature valide pour {target_year}.")
                return
            
            # CrÃ©er une sÃ©rie complÃ¨te pour l'annÃ©e
            start_date = datetime.date(target_year, 1, 1)
            end_date = datetime.date(target_year, 12, 31)
            all_dates = pd.date_range(start_date, end_date, freq='D').date
            
            # CrÃ©er un DataFrame complet avec NaN pour les jours manquants
            full_year = pd.DataFrame({'date': all_dates})
            full_year = full_year.merge(daily_temps, on='date', how='left')
            
            # PrÃ©parer les donnÃ©es pour la heatmap
            full_year['week'] = pd.to_datetime(full_year['date']).dt.isocalendar().week
            full_year['weekday'] = pd.to_datetime(full_year['date']).dt.weekday
            full_year['month'] = pd.to_datetime(full_year['date']).dt.month
            
            # CrÃ©er la matrice pour la heatmap (53 semaines x 7 jours)
            temp_matrix = np.full((53, 7), np.nan)
            
            for _, row in full_year.iterrows():
                week = int(row['week']) - 1  # 0-indexÃ©
                weekday = int(row['weekday'])  # 0=lundi, 6=dimanche
                if 0 <= week < 53 and 0 <= weekday < 7:
                    temp_matrix[week, weekday] = row['temperature_2m']
                    
            # Configuration pour mode annÃ©e unique
            matrix_to_plot = temp_matrix.T
            xlabel_text = 'ğŸ“… Mois'
            ylabel_text = 'ğŸ“‹ Jour de la semaine'
            title_text = f'ğŸŒ¡ï¸ Calendrier thermique {target_year} - {VILLE}'
            
            # Labels des jours avec emojis
            y_positions = range(7)
            y_labels = ['ğŸŒ… Lun', 'ğŸŒ… Mar', 'ğŸŒ… Mer', 'ğŸŒ… Jeu', 'ğŸŒ… Ven', 'ğŸ–ï¸ Sam', 'ğŸ–ï¸ Dim']
            
            # Labels des mois avec emojis saisonniers
            month_positions = []
            month_labels = []
            month_emojis = ['â„ï¸', 'â„ï¸', 'ğŸŒ¸', 'ğŸŒ¸', 'ğŸŒ¸', 'â˜€ï¸', 'â˜€ï¸', 'â˜€ï¸', 'ğŸ‚', 'ğŸ‚', 'ğŸ‚', 'â„ï¸']
            
            for month in range(1, 13):
                first_day_month = datetime.date(target_year, month, 1)
                week_num = first_day_month.isocalendar().week - 1
                if week_num < 53:
                    month_positions.append(week_num)
                    month_name = first_day_month.strftime('%b')
                    month_labels.append(f'{month_emojis[month-1]} {month_name}')
            
            x_positions = month_positions
            x_labels = month_labels
        
        # CrÃ©er le graphique moderne style GitHub
        if target_year == 'all':
            fig, ax = plt.subplots(1, 1, figsize=(18, 12))
        else:
            fig, ax = plt.subplots(1, 1, figsize=(16, 10))
        fig.patch.set_facecolor('#f8f9fa')
        
        # Calculer vmin/vmax pour la palette de couleurs
        if target_year == 'all':
            vmin, vmax = np.nanmin(temp_matrix), np.nanmax(temp_matrix)
        else:
            vmin, vmax = full_year['temperature_2m'].min(), full_year['temperature_2m'].max()
        
        # Heatmap moderne avec palette amÃ©liorÃ©e
        im = ax.imshow(matrix_to_plot, cmap='RdYlBu_r', aspect='auto',
                      vmin=vmin, vmax=vmax, interpolation='nearest')
        
        # Titre moderne avec style GitHub
        ax.set_title(title_text, fontsize=20, fontweight='bold', pad=30, color='#24292e')
        
        # Configuration des axes selon le mode
        ax.set_yticks(y_positions)
        ax.set_yticklabels(y_labels, fontsize=11, color='#586069')
        ax.set_xticks(x_positions)
        ax.set_xticklabels(x_labels, fontsize=11, color='#586069')
        ax.set_xlabel(xlabel_text, fontsize=14, color='#24292e', fontweight='bold')
        ax.set_ylabel(ylabel_text, fontsize=14, color='#24292e', fontweight='bold')
        
        # Colorbar moderne
        cbar = plt.colorbar(im, ax=ax, shrink=0.8, aspect=25, pad=0.02)
        cbar.set_label('ğŸŒ¡ï¸ TempÃ©rature (Â°C)', fontsize=12, color='#24292e',
                      rotation=270, labelpad=20)
        cbar.ax.tick_params(labelsize=10, colors='#586069')
        
        # Style moderne des bordures
        for spine in ax.spines.values():
            spine.set_color('#d1d5da')
            spine.set_linewidth(1)
        
        ax.tick_params(colors='#586069', length=0)
        
        # Grille subtile style GitHub (adaptÃ©e selon le mode)
        if target_year == 'all':
            ax.set_xticks(np.arange(-0.5, 366, 30), minor=True)
            ax.set_yticks(np.arange(-0.5, len(available_years), 1), minor=True)
        else:
            ax.set_xticks(np.arange(-0.5, 53, 1), minor=True)
            ax.set_yticks(np.arange(-0.5, 7, 1), minor=True)
        ax.grid(which='minor', color='#e1e4e8', linestyle='-', linewidth=0.5, alpha=0.8)
        
        plt.tight_layout()
        
        # Statistiques adaptÃ©es selon le mode
        if target_year == 'all':
            # Statistiques pour mode multi-annÃ©es
            valid_temps = df['temperature_2m'].dropna()
            if not valid_temps.empty:
                temp_min = valid_temps.min()
                temp_max = valid_temps.max()
                temp_mean = valid_temps.mean()
                data_points = len(valid_temps)
                
                caption = (f"ğŸŒ¡ï¸ Calendrier thermique multi-annÃ©es - {VILLE}\n"
                          f"ğŸ“Š {len(available_years)} annÃ©es â€¢ {data_points} points de donnÃ©es\n"
                          f"ğŸ“Š TempÃ©rature moyenne: {temp_mean:.1f}Â°C\n"
                          f"ğŸ“ˆ Maximum absolu: {temp_max:.1f}Â°C\n"
                          f"ğŸ“‰ Minimum absolu: {temp_min:.1f}Â°C")
            else:
                caption = f"ğŸŒ¡ï¸ Calendrier thermique multi-annÃ©es - {VILLE}\nâŒ Aucune donnÃ©e valide"
        else:
            # Statistiques pour mode annÃ©e unique
            valid_temps = full_year['temperature_2m'].dropna()
            if not valid_temps.empty:
                temp_min = valid_temps.min()
                temp_max = valid_temps.max()
                temp_mean = valid_temps.mean()
                data_coverage = len(valid_temps) / len(full_year) * 100
                
                caption = (f"ğŸŒ¡ï¸ Calendrier thermique {target_year} - {VILLE}\n"
                          f"ğŸ“Š TempÃ©rature moyenne: {temp_mean:.1f}Â°C\n"
                          f"ğŸ“ˆ Maximum: {temp_max:.1f}Â°C\n"
                          f"ğŸ“‰ Minimum: {temp_min:.1f}Â°C\n"
                          f"ğŸ“… Couverture donnÃ©es: {data_coverage:.1f}%")
            else:
                caption = f"ğŸŒ¡ï¸ Calendrier thermique {target_year} - {VILLE}\nâŒ Aucune donnÃ©e valide"
        
        await send_graph(message.chat.id, fig, caption)
        
    except ValueError as e:
        await message.reply("L'annÃ©e doit Ãªtre un nombre entier valide.")
    except Exception as e:
        await log_message(f"Erreur dans heatmap_command: {str(e)}\n{traceback.format_exc()}")
        await message.reply("Erreur lors de la gÃ©nÃ©ration du calendrier thermique.")

@router.message(Command("sunshinelist"))
async def get_sunshine_list_command(message: types.Message):
    """Affiche un rÃ©sumÃ© textuel mensuel de l'ensoleillement. Usage: /sunshinelist"""
    try:
        if not os.path.exists(csv_filename) or os.path.getsize(csv_filename) == 0:
            await message.reply("Aucune donnÃ©e disponible pour calculer l'ensoleillement.")
            return
            
        df = pd.read_csv(csv_filename)
        if df.empty:
            await message.reply("Aucune donnÃ©e disponible pour calculer l'ensoleillement (fichier vide).")
            return

        df['time'] = pd.to_datetime(df['time'], utc=True, errors='coerce')
        df.dropna(subset=['time'], inplace=True)

        if df.empty:
            await message.reply("Aucune donnÃ©e temporelle valide pour calculer l'ensoleillement.")
            return

        # calculate_monthly_sunshine fait dÃ©jÃ  le filtrage des mois complets
        monthly_sunshine = calculate_monthly_sunshine(df)
        
        if monthly_sunshine.empty:
            await message.reply(f"Pas encore de donnÃ©es d'ensoleillement calculÃ©es pour {VILLE}.")
            return

        # Trier par date (l'index est dÃ©jÃ  YYYY-MM, donc tri alphabÃ©tique fonctionne)
        monthly_sunshine = monthly_sunshine.sort_index()
        
        # DÃ©tecter le premier mois avec des donnÃ©es (peut Ãªtre partiel)
        first_month = monthly_sunshine.index[0] if not monthly_sunshine.empty else None
        current_month_year_str = pd.Timestamp.now(tz='Europe/Berlin').strftime('%Y-%m')
        
        response = f"â˜€ï¸ RÃ©sumÃ© mensuel de l'ensoleillement estimÃ© pour {VILLE} :\n"
        response += f"ğŸ“… DÃ©but des mesures : {first_month} (donnÃ©es possiblement partielles)\n\n"
        
        for i, (date_str, hours) in enumerate(monthly_sunshine.items()):
            # Convertir YYYY-MM en nom de mois et annÃ©e pour affichage
            try:
                month_display = pd.to_datetime(date_str + "-01").strftime('%B %Y')
            except ValueError:
                month_display = date_str # Fallback si le format est inattendu
            
            is_current = date_str == current_month_year_str
            is_first = i == 0
            
            if is_current:
                month_marker = "ğŸ“ "
            elif is_first:
                month_marker = "ğŸš€ "  # Premier mois
            else:
                month_marker = "ğŸ“… "
            
            response += f"{month_marker}{month_display}: {hours:.1f} heures\n"
        
        await message.reply(response)
        
    except pd.errors.EmptyDataError:
        await message.reply("Le fichier de donnÃ©es est vide, impossible de calculer l'ensoleillement.")
    except FileNotFoundError:
        await message.reply("Fichier de donnÃ©es non trouvÃ© pour calculer l'ensoleillement.")
    except Exception as e:
        await log_message(f"Error in get_sunshine_compare_command: {str(e)}\n{traceback.format_exc()}")
        await message.reply("Erreur lors de l'obtention du rÃ©sumÃ© de l'ensoleillement.")

@router.message(Command("yearcompare"))
async def get_year_compare_command(message: types.Message):
    """Compare les donnÃ©es mÃ©tÃ©o entre diffÃ©rentes annÃ©es. Usage: /yearcompare [mÃ©trique]"""
    try:
        # Parser les arguments
        args = message.text.split()
        metric_arg = args[1].lower() if len(args) == 2 else 'temperature'
        
        # Mapping des mÃ©triques
        metric_mapping = {
            'temperature': 'temperature_2m',
            'temp': 'temperature_2m',
            'rain': 'precipitation',
            'precipitation': 'precipitation',
            'wind': 'windspeed_10m',
            'pressure': 'pressure_msl',
            'uv': 'uv_index',
            'humidity': 'relativehumidity_2m'
        }
        
        if metric_arg not in metric_mapping:
            await message.reply(
                f"MÃ©trique '{metric_arg}' non reconnue.\n"
                f"Utilisez: temperature, rain, wind, pressure, uv, humidity\n"
                f"Exemple: /yearcompare temperature"
            )
            return
        
        column_name = metric_mapping[metric_arg]
        metric_info = get_metric_info(column_name)
        
        # Lire les donnÃ©es
        if not os.path.exists(csv_filename) or os.path.getsize(csv_filename) == 0:
            await message.reply("Aucune donnÃ©e mÃ©tÃ©o disponible.")
            return
        
        df = pd.read_csv(csv_filename)
        if df.empty:
            await message.reply("Aucune donnÃ©e disponible.")
            return
        
        df['time'] = pd.to_datetime(df['time'], utc=True, errors='coerce')
        df.dropna(subset=['time'], inplace=True)
        
        if column_name not in df.columns:
            await message.reply(f"DonnÃ©es pour {metric_info['name']} non disponibles.")
            return
        
        # Convertir en heure locale et extraire date/heure AVANT le filtrage
        df['local_time'] = df['time'].dt.tz_convert('Europe/Berlin')
        df['year'] = df['local_time'].dt.year
        df['month'] = df['local_time'].dt.month
        df['month_day'] = df['local_time'].dt.strftime('%m-%d')
        df['day_of_year'] = df['local_time'].dt.dayofyear
        
        # Filtrer pour ne garder que les mois complets (incluant le mois en cours) pour cette mÃ©trique
        df_complete = filter_complete_months_only(df, exclude_current_month=False, metric_column=column_name)
        df = df_complete.copy()
        await log_message("Filtrage automatique des mois incomplets pour /yearcompare")
        
        # RecrÃ©er les colonnes temporelles car filter_complete_months_only les supprime
        df['local_time'] = df['time'].dt.tz_convert('Europe/Berlin')
        df['year'] = df['local_time'].dt.year
        df['month'] = df['local_time'].dt.month
        df['month_day'] = df['local_time'].dt.strftime('%m-%d')
        df['day_of_year'] = df['local_time'].dt.dayofyear
        
        # VÃ©rifier qu'on a au moins une annÃ©e de donnÃ©es
        available_years = sorted(df['year'].unique())
        if len(available_years) < 1:
            await message.reply("Aucune annÃ©e de donnÃ©es complÃ¨te disponible.")
            return
        
        # Adapter le message selon le nombre d'annÃ©es
        if len(available_years) == 1:
            await log_message(f"Affichage d'une seule annÃ©e ({available_years[0]}) pour /yearcompare")
        
        current_year = pd.Timestamp.now(tz='Europe/Berlin').year
        current_day_of_year = pd.Timestamp.now(tz='Europe/Berlin').dayofyear
        
        # Calculer moyennes journaliÃ¨res par annÃ©e
        daily_means = df.groupby(['year', 'day_of_year'])[column_name].mean().reset_index()
        
        # === GRAPHIQUE 1: COURBE DE COMPARAISON ANNUELLE ===
        fig1, ax1 = plt.subplots(1, 1, figsize=(16, 10))
        fig1.patch.set_facecolor('#f8f9fa')
        
        # Palette de couleurs moderne et distincte
        modern_colors = ['#e74c3c', '#3498db', '#2ecc71', '#f39c12', '#9b59b6',
                        '#1abc9c', '#34495e', '#e67e22', '#95a5a6', '#16a085']
        
        # Tracer chaque annÃ©e avec style moderne
        for i, year in enumerate(available_years):
            year_data = daily_means[daily_means['year'] == year]
            
            if not year_data.empty:
                color = modern_colors[i % len(modern_colors)]
                
                # Style spÃ©cial pour l'annÃ©e courante
                if year == current_year:
                    ax1.plot(year_data['day_of_year'], year_data[column_name],
                           color=color, linewidth=4, label=f'ğŸ“ {year} (actuelle)',
                           alpha=0.95, zorder=5, marker='o', markersize=3,
                           markevery=30)
                else:
                    ax1.plot(year_data['day_of_year'], year_data[column_name],
                           color=color, linewidth=2.5, label=f'ğŸ“… {year}',
                           alpha=0.8, zorder=3)
        
        # Ligne verticale moderne pour "aujourd'hui"
        ax1.axvline(x=current_day_of_year, color='#e74c3c', linestyle='--',
                  linewidth=3, alpha=0.9, zorder=10,
                  label=f"ğŸ“ Aujourd'hui (jour {current_day_of_year})")
        
        # Zone d'intÃ©rÃªt moderne avec gradient
        highlight_start = max(1, current_day_of_year - 15)
        highlight_end = min(366, current_day_of_year + 15)
        ax1.axvspan(highlight_start, highlight_end, alpha=0.15, color='#e74c3c',
                  label='ğŸ” PÃ©riode actuelle Â±15j', zorder=1)
        
        # Titre moderne avec emojis
        ax1.set_title(f'{metric_info["emoji"]} Comparaison annuelle (courbe) - {metric_info["name"]} Ã  {VILLE}\n'
                    f'ğŸ“Š Analyse de {len(available_years)} annÃ©es de donnÃ©es (mois complets uniquement)',
                    fontsize=18, fontweight='bold', color='#2c3e50', pad=25)
        
        # Labels modernes avec emojis
        ax1.set_xlabel('ğŸ“… Jour de l\'annÃ©e', fontsize=14, color='#2c3e50', fontweight='bold')
        ax1.set_ylabel(f'{metric_info["emoji"]} {metric_info["name"]} ({metric_info["unit"]})',
                     fontsize=14, color='#2c3e50', fontweight='bold')
        
        # Style moderne des axes
        ax1.spines['top'].set_visible(False)
        ax1.spines['right'].set_visible(False)
        ax1.spines['left'].set_color('#bdc3c7')
        ax1.spines['bottom'].set_color('#bdc3c7')
        ax1.tick_params(colors='#34495e', labelsize=11)
        
        # LÃ©gende moderne
        legend = ax1.legend(bbox_to_anchor=(1.02, 1), loc='upper left',
                          frameon=True, shadow=True, fancybox=True,
                          framealpha=0.95, edgecolor='#bdc3c7')
        legend.get_frame().set_facecolor('#ffffff')
        
        # Marques des mois sur l'axe X
        month_starts = [1, 32, 60, 91, 121, 152, 182, 213, 244, 274, 305, 335]
        month_names = ['Jan', 'FÃ©v', 'Mar', 'Avr', 'Mai', 'Jun',
                      'Jul', 'AoÃ»', 'Sep', 'Oct', 'Nov', 'DÃ©c']
        ax1.set_xticks(month_starts)
        ax1.set_xticklabels(month_names)
        
        plt.tight_layout()
        
        # Statistiques pour la pÃ©riode actuelle
        current_period_data = daily_means[
            (daily_means['day_of_year'] >= highlight_start) &
            (daily_means['day_of_year'] <= highlight_end)
        ]
        
        stats_by_year = {}
        for year in available_years:
            year_period = current_period_data[current_period_data['year'] == year]
            if not year_period.empty:
                stats_by_year[year] = year_period[column_name].mean()
        
        # PrÃ©parer le texte des statistiques
        stats_text = f"ğŸ“Š Moyennes pour la pÃ©riode actuelle (Â±15j):\n"
        for year, avg_val in sorted(stats_by_year.items()):
            marker = " ğŸ‘ˆ" if year == current_year else ""
            stats_text += f"{year}: {avg_val:.1f}{metric_info['unit']}{marker}\n"
        
        # Tendance gÃ©nÃ©rale
        if len(stats_by_year) >= 3:
            years_list = list(stats_by_year.keys())
            values_list = list(stats_by_year.values())
            
            # RÃ©gression linÃ©aire simple
            if len(values_list) > 1:
                slope = (values_list[-1] - values_list[0]) / (years_list[-1] - years_list[0])
                trend = "â†—ï¸ hausse" if slope > 0 else "â†˜ï¸ baisse" if slope < 0 else "â¡ï¸ stable"
                stats_text += f"\nğŸ“ˆ Tendance gÃ©nÃ©rale: {trend} ({slope:.2f}{metric_info['unit']}/an)"
        
        base_caption = (f"{metric_info['emoji']} Comparaison {metric_info['name']} - {len(available_years)} annÃ©es\n"
                       f"ğŸ“… AnnÃ©es: {min(available_years)}-{max(available_years)} (mois complets uniquement)\n"
                       f"{stats_text}")
        
        # Envoyer le premier graphique (courbe)
        caption1 = f"ğŸ“Š Comparaison annuelle (courbe)\n{base_caption}"
        await send_graph(message.chat.id, fig1, caption1)
        
        # === GRAPHIQUE 2: BARRES MENSUELLES PAR ANNÃ‰E ===
        fig2, ax2 = plt.subplots(1, 1, figsize=(16, 10))
        fig2.patch.set_facecolor('#f8f9fa')
        
        # Calculer valeurs mensuelles selon le type de mÃ©trique
        if metric_arg in ['rain', 'precipitation']:
            monthly_data = df.groupby(['year', 'month'])[column_name].sum().reset_index()
        else:
            monthly_data = df.groupby(['year', 'month'])[column_name].mean().reset_index()
        
        if not monthly_data.empty:
            # Style barres : barres groupÃ©es par annÃ©e pour chaque mois
            available_years_bars = sorted(monthly_data['year'].unique())
            available_months = sorted(monthly_data['month'].unique())
            
            # Noms des mois
            month_names_bars = ['Jan', 'FÃ©v', 'Mar', 'Avr', 'Mai', 'Jun',
                      'Jul', 'AoÃ»', 'Sep', 'Oct', 'Nov', 'DÃ©c']
            
            # Couleurs pour les annÃ©es (mÃªmes que le premier graphique)
            year_colors = modern_colors[:len(available_years_bars)]
            
            # CrÃ©er les barres groupÃ©es
            x_positions = np.arange(len(available_months))
            n_years = len(available_years_bars)
            width = 0.8 / n_years
            
            for i, year in enumerate(available_years_bars):
                year_data = monthly_data[monthly_data['year'] == year]
                values = []
                
                for month in available_months:
                    month_row = year_data[year_data['month'] == month]
                    if not month_row.empty:
                        values.append(month_row[column_name].iloc[0])
                    else:
                        values.append(0)
                
                year_color = year_colors[i % len(year_colors)]
                offset = (i - n_years/2 + 0.5) * width
                
                # Style spÃ©cial pour l'annÃ©e courante
                if year == current_year:
                    bars = ax2.bar(x_positions + offset, values, width,
                                  label=f'ğŸ“ {year} (actuelle)', color=year_color,
                                  alpha=0.9, edgecolor='white', linewidth=2,
                                  zorder=5)
                    # Ajouter des valeurs sur les barres de l'annÃ©e courante
                    for j, bar in enumerate(bars):
                        if values[j] > 0:
                            ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(values)*0.01,
                                   f'{values[j]:.0f}', ha='center', va='bottom',
                                   fontsize=9, fontweight='bold', color=year_color)
                else:
                    ax2.bar(x_positions + offset, values, width,
                           label=f'ğŸ“… {year}', color=year_color,
                           alpha=0.7, edgecolor='white', linewidth=1,
                           zorder=3)
            
            # Mise en Ã©vidence du mois actuel
            current_month = pd.Timestamp.now(tz='Europe/Berlin').month
            if current_month in available_months:
                month_idx = available_months.index(current_month)
                ax2.axvspan(month_idx - 0.4, month_idx + 0.4,
                           alpha=0.2, color='#f39c12', zorder=1,
                           label=f"ğŸ“ Mois actuel ({month_names_bars[current_month-1]})")
            
            # Configuration des axes pour style mensuel
            ax2.set_xticks(x_positions)
            ax2.set_xticklabels([month_names_bars[m-1] for m in available_months])
            ax2.set_title(f'ğŸ“Š {metric_info["emoji"]} {metric_info["name"]} (barres mensuelles) - {len(available_years_bars)} annÃ©es Ã  {VILLE}\n'
                         f'ğŸ“Š Comparaison par mois (mois complets uniquement)',
                         fontsize=16, fontweight='bold', color='#2c3e50', pad=20)
            
            # LÃ©gende moderne
            legend = ax2.legend(bbox_to_anchor=(1.02, 1), loc='upper left',
                               frameon=True, shadow=True, fancybox=True,
                               framealpha=0.95, edgecolor='#bdc3c7')
            legend.get_frame().set_facecolor('#ffffff')
        
        # Style commun des axes
        ax2.set_ylabel(f'{metric_info["emoji"]} {metric_info["name"]} ({metric_info["unit"]})',
                      fontsize=14, color='#2c3e50', fontweight='bold')
        ax2.set_xlabel('ğŸ“… Mois', fontsize=14, color='#2c3e50', fontweight='bold')
        
        ax2.spines['top'].set_visible(False)
        ax2.spines['right'].set_visible(False)
        ax2.spines['left'].set_color('#bdc3c7')
        ax2.spines['bottom'].set_color('#bdc3c7')
        ax2.tick_params(colors='#34495e', labelsize=11)
        
        plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45, fontsize=10)
        ax2.grid(True, alpha=0.3, linestyle=':', linewidth=1, axis='y')
        plt.tight_layout()
        
        # Envoyer le deuxiÃ¨me graphique (barres)
        caption2 = f"ğŸ“Š Comparaison mensuelle (barres)\n{base_caption}"
        await send_graph(message.chat.id, fig2, caption2)
        
    except ValueError as e:
        await message.reply("ParamÃ¨tres invalides. VÃ©rifiez la syntaxe de la commande.")
    except Exception as e:
        await log_message(f"Erreur dans yearcompare_command: {str(e)}\n{traceback.format_exc()}")
        await message.reply("Erreur lors de la gÃ©nÃ©ration de la comparaison annuelle.")


# --- Fonction principale pour dÃ©marrer le bot ---
async def main():
    # Inclure le routeur principal dans le dispatcher
    dp.include_router(router)

    # Lancer la tÃ¢che de fond pour vÃ©rifier la mÃ©tÃ©o
    # Elle utilisera l'instance globale `bot` pour envoyer des messages
    asyncio.create_task(schedule_jobs())
    
    # DÃ©marrer le polling du bot
    # skip_updates=True est utile pour ignorer les mises Ã  jour reÃ§ues pendant que le bot Ã©tait hors ligne
    await log_message("Bot dÃ©marrÃ© et prÃªt Ã  recevoir les commandes.")
    await dp.start_polling(bot, skip_updates=True)


if __name__ == "__main__":
    # Configurer le logging de base pour voir les messages d'aiogram et les vÃ´tres
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
    
    # Nettoyer le CSV au dÃ©marrage
    clean_csv_file()
    
    try:
        asyncio.run(main())
    except (KeyboardInterrupt, SystemExit):
        asyncio.run(log_message("Bot arrÃªtÃ© manuellement.")) # Log l'arrÃªt
        logging.info("Bot arrÃªtÃ©.")
    except Exception as e:
        # Log l'erreur fatale qui a empÃªchÃ© le bot de tourner
        asyncio.run(log_message(f"Erreur fatale au niveau principal du bot: {str(e)}\n{traceback.format_exc()}"))
        logging.critical(f"Erreur fatale: {e}", exc_info=True)