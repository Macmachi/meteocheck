'''
*
* PROJET : MeteoCheck
* AUTEUR : Rymentz
* VERSIONS : v1.9.4
* NOTES : None
*
'''
import os
import pandas as pd
import asyncio
import datetime
import aiofiles
import aiohttp # Utilis√© pour les requ√™tes HTTP asynchrones
import sys
import traceback
import configparser
import json
import pytz # Pour la gestion des fuseaux horaires
import logging # Ajout pour un meilleur logging
import matplotlib
matplotlib.use('Agg')  # Backend non-interactif pour serveurs
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import seaborn as sns
import numpy as np
import io
from datetime import datetime as dt

# Configuration style moderne pour les graphiques
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

# Configuration des polices pour √©viter les warnings emoji
import warnings
import matplotlib.font_manager as fm

# D√©sactiver les warnings sp√©cifiques aux glyphes manquants
warnings.filterwarnings('ignore', category=UserWarning, module='matplotlib')

# Trouver une police syst√®me qui supporte mieux les caract√®res Unicode
available_fonts = [f.name for f in fm.fontManager.ttflist]
emoji_compatible_fonts = ['Segoe UI Emoji', 'Apple Color Emoji', 'Noto Color Emoji', 'DejaVu Sans', 'Liberation Sans']
selected_font = 'sans-serif'  # Fallback par d√©faut

for font in emoji_compatible_fonts:
    if font in available_fonts:
        selected_font = font
        break

plt.rcParams.update({
    'figure.facecolor': '#f8f9fa',
    'axes.facecolor': '#ffffff',
    'axes.edgecolor': '#dee2e6',
    'axes.linewidth': 0.8,
    'axes.grid': True,
    'grid.color': '#e9ecef',
    'grid.alpha': 0.6,
    'font.family': ['sans-serif'],
    'font.sans-serif': [selected_font, 'DejaVu Sans', 'Liberation Sans', 'Arial'],
    'font.size': 10,
    'axes.titlesize': 14,
    'axes.labelsize': 11,
    'xtick.labelsize': 9,
    'ytick.labelsize': 9,
    'legend.fontsize': 10,
    'figure.titlesize': 16,
    'axes.unicode_minus': False  # √âviter les probl√®mes avec les caract√®res Unicode
})

# Imports sp√©cifiques √† aiogram 3.x
from aiogram import Bot, Dispatcher, types, Router
from aiogram.fsm.storage.memory import MemoryStorage
from aiogram.fsm.context import FSMContext # Si vous pr√©voyez d'utiliser FSM plus tard
from aiogram.filters import Command
from aiogram.exceptions import TelegramAPIError # Pour la gestion des erreurs de l'API Telegram
from aiogram.types import BufferedInputFile # Pour l'envoi de fichiers en m√©moire

# Configuration and setup
script_dir = os.path.dirname(os.path.realpath(__file__))
os.chdir(script_dir)
config_path = os.path.join(script_dir, 'config.ini')

config = configparser.ConfigParser()
config.read(config_path)

TOKEN_TELEGRAM = config['KEYS']['TELEGRAM_BOT_TOKEN']
VILLE = config['LOCATION']['VILLE']
LATITUDE = config['LOCATION']['LATITUDE']
LONGITUDE = config['LOCATION']['LONGITUDE']

weather_url = f"https://api.open-meteo.com/v1/forecast?latitude={LATITUDE}&longitude={LONGITUDE}&hourly=temperature_2m,precipitation_probability,precipitation,pressure_msl,windspeed_10m,uv_index,relativehumidity_2m&timezone=GMT&forecast_days=2&past_days=2&models=best_match&timeformat=unixtime"

# ================================
# SYST√àME DE CACHE PR√âVISIONS
# ================================
cached_forecast_data = {
    'df_seven_hours': pd.DataFrame(),
    'df_twenty_four_hours': pd.DataFrame(),
    'last_update': None,
    'cache_duration_minutes': 5  # Cache valide pendant 5 minutes
}

def is_cache_valid():
    """V√©rifie si le cache des pr√©visions est encore valide."""
    if cached_forecast_data['last_update'] is None:
        return False
    
    now = pd.Timestamp.now(tz='UTC')
    time_since_update = (now - cached_forecast_data['last_update']).total_seconds() / 60
    return time_since_update < cached_forecast_data['cache_duration_minutes']

async def get_cached_forecast_data():
    """Retourne les donn√©es de pr√©vision depuis le cache si valide, sinon depuis l'API."""
    if is_cache_valid():
        # Cache valide, retourner les donn√©es stock√©es
        return (cached_forecast_data['df_seven_hours'].copy(),
                cached_forecast_data['df_twenty_four_hours'].copy())
    else:
        # Cache expir√©, appeler l'API et mettre √† jour le cache
        await log_message("Cache des pr√©visions expir√©, r√©cup√©ration depuis l'API...")
        df_seven, df_twenty_four = await get_weather_data()
        
        # Mettre √† jour le cache
        cached_forecast_data['df_seven_hours'] = df_seven.copy()
        cached_forecast_data['df_twenty_four_hours'] = df_twenty_four.copy()
        cached_forecast_data['last_update'] = pd.Timestamp.now(tz='UTC')
        
        await log_message(f"Cache des pr√©visions mis √† jour avec {len(df_seven)} + {len(df_twenty_four)} entr√©es")
        return df_seven, df_twenty_four

# Initialisation du Bot et du Dispatcher pour aiogram 3.x
bot = Bot(token=TOKEN_TELEGRAM)
storage = MemoryStorage()
dp = Dispatcher(storage=storage)
router = Router() # Cr√©ation d'un routeur principal pour les handlers

csv_filename = "weather_data.csv"

# Initialize CSV file if not exists
if not os.path.exists(csv_filename):
    df_initial = pd.DataFrame(columns=['time', 'temperature_2m', 'precipitation_probability', 'precipitation', 'pressure_msl', 'windspeed_10m', 'uv_index', 'relativehumidity_2m'])
    df_initial.to_csv(csv_filename, index=False)

# Logging functions
def log_uncaught_exceptions(exc_type, exc_value, exc_traceback):
    error_message = "".join(traceback.format_exception(exc_type, exc_value, exc_traceback))
    try:
        # Essayer d'obtenir la boucle d'√©v√©nements en cours pour y soumettre la t√¢che de log
        loop = asyncio.get_running_loop()
        loop.create_task(log_message(f"Uncaught exception: {error_message}"))
    except RuntimeError:  # Aucune boucle d'√©v√©nements en cours (par exemple, si l'erreur se produit tr√®s t√¥t)
        # Ex√©cuter de mani√®re synchrone comme fallback (cr√©e une nouvelle boucle temporaire)
        asyncio.run(log_message(f"Uncaught exception (no running loop): {error_message}"))

sys.excepthook = log_uncaught_exceptions

async def log_message(message: str):
    async with aiofiles.open("log_meteocheck.log", mode='a', encoding='utf-8') as f:
        await f.write(f"{datetime.datetime.now(pytz.UTC)} - {message}\n")

def clean_csv_file():
    try:
        df = pd.read_csv(csv_filename)
        if df.empty:
            print("Fichier CSV vide, rien √† nettoyer.")
            return

        correct_columns = ['time', 'temperature_2m', 'precipitation_probability', 'precipitation', 'pressure_msl', 'windspeed_10m', 'uv_index', 'relativehumidity_2m']
        
        df = df.reindex(columns=correct_columns)
        
        # S'assurer que la colonne 'time' existe avant de la manipuler
        if 'time' in df.columns:
            df['time'] = df['time'].astype(str).str.replace(' ', 'T', regex=False).str.replace('+00:00', 'Z', regex=False)
            df['time'] = pd.to_datetime(df['time'], utc=True, errors='coerce')
            
            invalid_entries = df['time'].isna().sum()
            df = df.dropna(subset=['time'])
            if invalid_entries > 0:
                print(f"{invalid_entries} entr√©es invalides supprim√©es du CSV apr√®s conversion de date.")
            
            df = df.sort_values('time')
            df['time'] = df['time'].dt.strftime('%Y-%m-%dT%H:%M:%SZ')
        else:
            print("Colonne 'time' manquante dans le CSV. Impossible de nettoyer les dates.")

        df.to_csv(csv_filename, index=False)
        print("Fichier CSV nettoy√© avec succ√®s.")
    except pd.errors.EmptyDataError:
        print("Fichier CSV vide ou mal format√© lors du nettoyage.")
    except Exception as e:
        print(f"Erreur lors du nettoyage du fichier CSV : {str(e)}")
        # Log l'erreur pour un d√©bogage plus facile
        asyncio.run(log_message(f"Erreur critique lors du nettoyage du CSV: {str(e)}"))


# Alert tracking
sent_alerts = {
    'temperature': None,
    'precipitation': None,
    'windspeed': None,
    'uv_index': None,
    'pressure_msl': None,
    'data_freshness': None  # Pour tracking des alertes de fra√Æcheur des donn√©es
}

# Advanced record tracking system
predicted_records = {
    'temperature_2m': {'max': {}, 'min': {}},
    'precipitation': {'max': {}},
    'windspeed_10m': {'max': {}},
    'pressure_msl': {'max': {}},
    'uv_index': {'max': {}}
}

# Structure: predicted_records[metric][type][record_id] = {
#   'value': float,
#   'time': datetime,
#   'confidence': float,
#   'first_detected': datetime,
#   'last_seen': datetime,
#   'notified': bool
# }

# History of sent record alerts (to avoid spam but allow important updates)
record_alert_history = []
# Structure: [{'type': str, 'metric': str, 'value': float, 'time': datetime, 'sent_at': datetime}]

# Alert and message sending functions
async def schedule_jobs():
    """T√¢che planifi√©e pour v√©rifier la m√©t√©o p√©riodiquement."""
    while True:
        await check_weather()
        # V√©rifier les changements dans les records pr√©vus (notifications d'annulation)
        await check_predicted_record_changes()
        # V√©rifier la fra√Æcheur des donn√©es (alerte si >24h)
        await check_data_freshness()
        await asyncio.sleep(60)

async def send_alert(message_text, row=None, alert_column=None):
    """Envoie une alerte √† tous les utilisateurs enregistr√©s."""
    if row is not None and alert_column is not None:
        # La fonction check_records envoie elle-m√™me des alertes si un record est battu.
        # Pour √©viter les alertes en double, on ne fait pas d'await ici directement.
        # check_records appellera send_alert pour le message de record.
        await check_records(row, alert_column)

    try:
        # Utilisation de aiofiles pour lire chat_ids.json de mani√®re asynchrone
        if os.path.exists('chat_ids.json'):
            async with aiofiles.open('chat_ids.json', 'r') as file:
                content = await file.read()
                chats = json.loads(content)
        else:
            chats = []

        send_tasks = [send_message_with_retry(chat_id, message_text) for chat_id in chats]
        await asyncio.gather(*send_tasks)
        await log_message(f"Sent alert: {message_text}")
    except FileNotFoundError:
        await log_message("Erreur dans send_alert: chat_ids.json non trouv√©.")
    except json.JSONDecodeError:
        await log_message("Erreur dans send_alert: Impossible de d√©coder chat_ids.json.")
    except Exception as e:
        await log_message(f"Error in send_alert: {str(e)}")

async def send_message_with_retry(chat_id, message_text, max_retries=3):
    """Tente d'envoyer un message avec plusieurs essais en cas d'erreur API."""
    for attempt in range(max_retries):
        try:
            await bot.send_message(chat_id=chat_id, text=message_text)
            return
        except TelegramAPIError as e: # Utilisation de l'exception import√©e
            await log_message(f"Tentative {attempt + 1} d'envoi au chat {chat_id} √©chou√©e: {e}")
            if attempt < max_retries - 1:
                await asyncio.sleep(1) # Attendre avant de r√©essayer
            else:
                await log_message(f"√âchec final de l'envoi du message au chat {chat_id} apr√®s {max_retries} tentatives : {e}")
                # Ne pas print directement, mais logger l'√©chec
        except Exception as e_general: # Capturer d'autres exceptions potentielles
            await log_message(f"Erreur inattendue lors de l'envoi au chat {chat_id} (tentative {attempt+1}): {e_general}")
            if attempt < max_retries - 1:
                await asyncio.sleep(1)
            else:
                await log_message(f"√âchec final (erreur inattendue) de l'envoi au chat {chat_id} apr√®s {max_retries} tentatives: {e_general}")


async def send_summary_base(chat_id, df_period, period_name, ville_name):
    """Fonction de base pour g√©n√©rer et envoyer des r√©sum√©s."""
    if df_period.empty:
        await log_message(f"Aucune donn√©e disponible pour {period_name}")
        await bot.send_message(chat_id, f"Pas de donn√©es disponibles pour {period_name}.")
        return
    
    summary = generate_summary(df_period)
    await log_message(f"R√©sum√© pour {period_name} g√©n√©r√© avec succ√®s")
    
    message_text = f"R√©sum√© {period_name} pour {ville_name}:\n\n{summary}"
    await bot.send_message(chat_id, message_text)
    await log_message(f"R√©sum√© {period_name} envoy√© avec succ√®s √† chat_id: {chat_id}")

async def send_month_summary(chat_id):
    try:
        await log_message(f"D√©but de send_month_summary pour chat_id: {chat_id}")
        df = pd.read_csv(csv_filename)
        df['time'] = pd.to_datetime(df['time'], utc=True, errors='coerce').dropna()
        
        now = pd.Timestamp.now(tz='UTC')
        # Mois dernier : du premier jour du mois pr√©c√©dent au premier jour du mois actuel (exclus)
        first_day_current_month = now.replace(day=1, hour=0, minute=0, second=0, microsecond=0)
        first_day_last_month = (first_day_current_month - pd.DateOffset(months=1))
        
        df_last_month = df[(df['time'] >= first_day_last_month) & (df['time'] < first_day_current_month)]
        await log_message(f"Donn√©es filtr√©es pour le mois dernier ({first_day_last_month.strftime('%Y-%m')}): {len(df_last_month)} entr√©es")
        
        await send_summary_base(chat_id, df_last_month, "du mois dernier", VILLE)
    
    except pd.errors.EmptyDataError:
        await handle_summary_error(chat_id, "Le fichier CSV est vide ou mal format√©.")
    except FileNotFoundError:
        await handle_summary_error(chat_id, f"Le fichier {csv_filename} n'a pas √©t√© trouv√©.")
    except aiohttp.ClientError as e: # Erreur r√©seau lors de l'envoi du message
        await handle_summary_error(chat_id, f"Erreur de connexion lors de l'envoi du message: {str(e)}", is_network_error=True)
    except Exception as e:
        await handle_summary_error(chat_id, f"Erreur inattendue dans send_month_summary: {str(e)}")

async def send_year_summary(chat_id):
    try:
        await log_message(f"D√©but de send_year_summary pour chat_id: {chat_id}")
        df = pd.read_csv(csv_filename)
        df['time'] = pd.to_datetime(df['time'], utc=True, errors='coerce').dropna()
        
        now = pd.Timestamp.now(tz='UTC')
        current_year = now.year
        df_current_year = df[(df['time'].dt.year == current_year) & (df['time'] < now)]
        await log_message(f"Donn√©es filtr√©es pour l'ann√©e en cours ({current_year}): {len(df_current_year)} entr√©es")

        await send_summary_base(chat_id, df_current_year, "de l'ann√©e en cours", VILLE)

    except pd.errors.EmptyDataError:
        await handle_summary_error(chat_id, "Le fichier CSV est vide ou mal format√©.")
    except FileNotFoundError:
        await handle_summary_error(chat_id, f"Le fichier {csv_filename} n'a pas √©t√© trouv√©.")
    except aiohttp.ClientError as e:
        await handle_summary_error(chat_id, f"Erreur de connexion lors de l'envoi du message: {str(e)}", is_network_error=True)
    except Exception as e:
        await handle_summary_error(chat_id, f"Erreur inattendue dans send_year_summary: {str(e)}")

async def send_all_summary(chat_id):
    try:
        await log_message(f"D√©but de send_all_summary pour chat_id: {chat_id}")
        df = pd.read_csv(csv_filename)
        df['time'] = pd.to_datetime(df['time'], utc=True, errors='coerce').dropna()
        
        await log_message(f"Donn√©es lues pour le r√©sum√© complet: {len(df)} entr√©es")
        await send_summary_base(chat_id, df, "de toutes les donn√©es m√©t√©o", VILLE)

    except pd.errors.EmptyDataError:
        await handle_summary_error(chat_id, "Le fichier CSV est vide ou mal format√©.")
    except FileNotFoundError:
        await handle_summary_error(chat_id, f"Le fichier {csv_filename} n'a pas √©t√© trouv√©.")
    except aiohttp.ClientError as e:
        await handle_summary_error(chat_id, f"Erreur de connexion lors de l'envoi du message: {str(e)}", is_network_error=True)
    except Exception as e:
        await handle_summary_error(chat_id, f"Erreur inattendue dans send_all_summary: {str(e)}")

async def handle_summary_error(chat_id, error_msg, is_network_error=False):
    """G√®re les erreurs communes pour les fonctions de r√©sum√©."""
    await log_message(error_msg)
    if is_network_error:
        await bot.send_message(chat_id, "Erreur de connexion. Veuillez r√©essayer plus tard.")
    else:
        await bot.send_message(chat_id, f"Erreur : {error_msg}")


async def get_weather_data():
    """R√©cup√®re les donn√©es m√©t√©o de l'API et met √† jour le CSV."""
    try:
        now = pd.Timestamp.now(tz='UTC').floor('h')
        async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=60)) as session:
            async with session.get(weather_url) as resp:
                resp.raise_for_status() # L√®ve une exception pour les codes HTTP 4xx/5xx
                data = await resp.json()
                
                if 'hourly' not in data or not isinstance(data['hourly'], dict):
                    await log_message("Format de donn√©es API inattendu: 'hourly' manquant ou incorrect.")
                    return pd.DataFrame(), pd.DataFrame()

                columns = ['time', 'temperature_2m', 'precipitation_probability', 'precipitation', 'pressure_msl', 'windspeed_10m', 'uv_index', 'relativehumidity_2m']
                
                # V√©rifier que toutes les colonnes attendues sont pr√©sentes dans les donn√©es API
                for col in columns:
                    if col not in data['hourly']:
                        await log_message(f"Colonne API manquante: '{col}' dans data['hourly']")
                        # Retourner des DataFrames vides si une colonne essentielle manque
                        if col == 'time': return pd.DataFrame(), pd.DataFrame()
                        # Pour les autres colonnes, on pourrait initialiser avec des NaN si n√©cessaire
                        # mais pour la coh√©rence, retourner vide est plus s√ªr.
                        return pd.DataFrame(), pd.DataFrame()

                df_api = pd.DataFrame({col: data['hourly'][col] for col in columns})
                df_api['time'] = pd.to_datetime(df_api['time'], unit='s', utc=True)
                
                # Lecture du CSV existant
                if os.path.exists(csv_filename) and os.path.getsize(csv_filename) > 0:
                    try:
                        df_existing = pd.read_csv(csv_filename)
                        df_existing['time'] = pd.to_datetime(df_existing['time'], utc=True, errors='coerce')
                        df_existing.dropna(subset=['time'], inplace=True) # S'assurer que les dates sont valides
                    except pd.errors.EmptyDataError:
                         df_existing = pd.DataFrame(columns=columns)
                         df_existing['time'] = pd.to_datetime(df_existing['time'], utc=True) # Assurer le dtype
                else:
                    df_existing = pd.DataFrame(columns=columns)
                    df_existing['time'] = pd.to_datetime(df_existing['time'], utc=True) # Assurer le dtype

                # Donn√©es des derni√®res 24h de l'API pour combler les manques
                twenty_four_hours_ago = now - pd.Timedelta(hours=24)
                last_twenty_four_hours_df_api = df_api[(df_api['time'] >= twenty_four_hours_ago) & (df_api['time'] < now)].copy() # .copy() pour √©viter SettingWithCopyWarning

                if not last_twenty_four_hours_df_api.empty:
                    missing_data = last_twenty_four_hours_df_api[~last_twenty_four_hours_df_api['time'].isin(df_existing['time'])].copy()
                    if not missing_data.empty:
                        missing_data['time'] = missing_data['time'].dt.strftime('%Y-%m-%dT%H:%M:%SZ')
                        # S'assurer que le header n'est √©crit que si le fichier est vide ou n'existe pas
                        header_needed = not os.path.exists(csv_filename) or os.path.getsize(csv_filename) == 0
                        missing_data.to_csv(csv_filename, mode='a', header=header_needed, index=False)
                        await log_message(f"Enregistrement de {len(missing_data)} nouvelles donn√©es manquantes dans le CSV.")
                        
                        # V√©rifier les records sur les nouvelles donn√©es historiques r√©elles
                        for _, row in missing_data.iterrows():
                            # Reconvertir le temps en datetime pour check_records
                            row_copy = row.copy()
                            row_copy['time'] = pd.to_datetime(row_copy['time'], utc=True)
                            
                            # V√©rifier les records pour les m√©triques principales
                            for metric in ['temperature_2m', 'precipitation', 'windspeed_10m', 'pressure_msl', 'uv_index']:
                                if metric in row_copy and pd.notna(row_copy[metric]):
                                    await check_records(row_copy, metric, is_forecast=False)
                
                # Pr√©visions pour les prochaines heures
                seven_hours_later = now + pd.Timedelta(hours=7)
                next_seven_hours_df = df_api[(df_api['time'] > now) & (df_api['time'] <= seven_hours_later)].copy()
                
                twenty_four_hours_later = now + pd.Timedelta(hours=24)
                next_twenty_four_hours_df = df_api[(df_api['time'] > now) & (df_api['time'] <= twenty_four_hours_later)].copy()
                
                return next_seven_hours_df, next_twenty_four_hours_df

    except aiohttp.ClientError as e: # Erreurs r√©seau sp√©cifiques √† aiohttp
        await log_message(f"Erreur r√©seau dans get_weather_data: {str(e)}")
    except json.JSONDecodeError as e:
        await log_message(f"Erreur de d√©codage JSON dans get_weather_data: {str(e)}")
    except KeyError as e:
        await log_message(f"Cl√© manquante dans les donn√©es API (get_weather_data): {str(e)}")
    except Exception as e:
        await log_message(f"Erreur inattendue dans get_weather_data: {str(e)}\n{traceback.format_exc()}")
    return pd.DataFrame(), pd.DataFrame()


async def check_weather():
    """V√©rifie la m√©t√©o et envoie des alertes si n√©cessaire."""
    await log_message("Fonction check_weather ex√©cut√©e")
    try:
        df_next_seven_hours, df_next_twenty_four_hours = await get_weather_data()
        
        # Mettre √† jour le cache des pr√©visions
        cached_forecast_data['df_seven_hours'] = df_next_seven_hours.copy()
        cached_forecast_data['df_twenty_four_hours'] = df_next_twenty_four_hours.copy()
        cached_forecast_data['last_update'] = pd.Timestamp.now(tz='UTC')
        
        if df_next_seven_hours.empty and df_next_twenty_four_hours.empty:
            await log_message("Aucune donn√©e obtenue de get_weather_data dans check_weather. Prochaine v√©rification dans 1 minute.")
            return

        # Alertes pour les 7 prochaines heures
        for _, row in df_next_seven_hours.iterrows():
            # S'assurer que row est bien une Series Pandas et non un tuple si iterrows est mal utilis√©
            if not isinstance(row, pd.Series): 
                await log_message(f"Format de ligne inattendu dans df_next_seven_hours: {type(row)}")
                continue

            time_local = row['time'].tz_convert('Europe/Berlin')
            # Comparaison de date uniquement pour sent_alerts
            alert_date_key = time_local.date()

            if row['temperature_2m'] > 35 or row['temperature_2m'] < -10:
                if sent_alerts['temperature'] != alert_date_key:
                    emoji = "üî•" if row['temperature_2m'] > 35 else "‚ùÑÔ∏è"
                    await send_alert(f"{emoji} Alerte m√©t√©o : Temp√©rature pr√©vue de {row['temperature_2m']:.1f}¬∞C √† {time_local.strftime('%H:%M')} √† {VILLE}.", row, 'temperature_2m')
                    sent_alerts['temperature'] = alert_date_key
            
            if row['precipitation_probability'] > 80 and row['precipitation'] > 15:
                if sent_alerts['precipitation'] != alert_date_key:
                    await send_alert(f"üåßÔ∏è Alerte m√©t√©o : Fortes pluies pr√©vues de {row['precipitation']:.1f}mm √† {time_local.strftime('%H:%M')} √† {VILLE}.", row, 'precipitation')
                    sent_alerts['precipitation'] = alert_date_key
            
            if row['windspeed_10m'] > 60: # km/h
                if sent_alerts['windspeed'] != alert_date_key:
                    emoji = "üå™Ô∏è" if row['windspeed_10m'] > 75 else "üí®"
                    wind_type = "temp√©tueux" if row['windspeed_10m'] > 75 else "fort"
                    await send_alert(f"{emoji} Alerte m√©t√©o : Vent {wind_type} pr√©vu de {row['windspeed_10m']:.1f}km/h √† {time_local.strftime('%H:%M')} √† {VILLE}.", row, 'windspeed_10m')
                    sent_alerts['windspeed'] = alert_date_key
            
            if row['uv_index'] > 8:
                if sent_alerts['uv_index'] != alert_date_key:
                    await send_alert(f"‚òÄÔ∏è Alerte m√©t√©o : Index UV pr√©vu de {row['uv_index']:.1f} √† {time_local.strftime('%H:%M')} √† {VILLE}.", row, 'uv_index')
                    sent_alerts['uv_index'] = alert_date_key

        # D√©tection de bombe m√©t√©orologique am√©lior√©e pour les 24 prochaines heures
        if len(df_next_twenty_four_hours) >= 24:
            await detect_meteorological_bomb(df_next_twenty_four_hours)
    
    except KeyError as e:
        await log_message(f"Erreur de cl√© dans check_weather (probablement une colonne manquante dans le DataFrame): {str(e)}")
    except Exception as e:
        await log_message(f"Erreur inattendue dans check_weather: {str(e)}\n{traceback.format_exc()}")


async def detect_meteorological_bomb(df_forecast):
    """D√©tection avanc√©e de bombe m√©t√©orologique selon les crit√®res scientifiques.
    
    Crit√®res officiels :
    - Latitude 46¬∞N (votre ville) : seuil ~22 hPa/24h (ajust√© par sin(latitude))
    - Recherche de la plus forte baisse sur toute p√©riode de 24h cons√©cutives
    - Conditions m√©t√©o associ√©es : vents forts + pr√©cipitations
    """
    global sent_alerts
    
    try:
        if len(df_forecast) < 24:
            return
            
        # Calcul du seuil ajust√© par latitude (formule scientifique standard)
        CITY_LAT = float(LATITUDE)  # Latitude depuis config.ini
        base_threshold = 24.0  # hPa/24h √† 60¬∞N (r√©f√©rence)
        latitude_factor = np.sin(np.radians(60)) / np.sin(np.radians(CITY_LAT))
        adjusted_threshold = base_threshold * latitude_factor  # ~22.1 hPa pour 46¬∞N
        
        # Recherche de la plus forte baisse sur toutes les fen√™tres de 24h
        max_pressure_drop = 0
        bomb_start_idx = None
        bomb_end_idx = None
        
        for start_idx in range(len(df_forecast) - 23):
            end_idx = start_idx + 23
            pressure_start = df_forecast.iloc[start_idx]['pressure_msl']
            pressure_end = df_forecast.iloc[end_idx]['pressure_msl']
            pressure_drop = pressure_start - pressure_end
            
            if pressure_drop > max_pressure_drop:
                max_pressure_drop = pressure_drop
                bomb_start_idx = start_idx
                bomb_end_idx = end_idx
        
        # V√©rification du seuil de bombe m√©t√©orologique
        if max_pressure_drop >= adjusted_threshold and bomb_start_idx is not None:
            bomb_start_time = df_forecast.iloc[bomb_start_idx]['time']
            bomb_end_time = df_forecast.iloc[bomb_end_idx]['time']
            bomb_start_local = bomb_start_time.tz_convert('Europe/Berlin')
            bomb_end_local = bomb_end_time.tz_convert('Europe/Berlin')
            
            alert_date_key = bomb_start_local.date()
            
            if sent_alerts['pressure_msl'] != alert_date_key:
                # Analyse des conditions m√©t√©o associ√©es
                bomb_period = df_forecast.iloc[bomb_start_idx:bomb_end_idx+1]
                max_wind = bomb_period['windspeed_10m'].max()
                total_precip = bomb_period['precipitation'].sum()
                
                # Classification de l'intensit√©
                if max_pressure_drop >= adjusted_threshold * 1.5:  # ~33 hPa
                    intensity = "EXTR√äME"
                    emoji = "üå™Ô∏èüíÄ"
                elif max_pressure_drop >= adjusted_threshold * 1.2:  # ~27 hPa
                    intensity = "MAJEURE"
                    emoji = "üå™Ô∏è‚ö†Ô∏è"
                else:
                    intensity = "MOD√âR√âE"
                    emoji = "üå™Ô∏è"
                
                # Message d'alerte d√©taill√©
                message = (
                    f"{emoji} BOMBE M√âT√âOROLOGIQUE {intensity} D√âTECT√âE !\n\n"
                    f"üìâ Chute de pression : {max_pressure_drop:.1f} hPa en 24h\n"
                    f"üéØ Seuil scientifique (46¬∞N) : {adjusted_threshold:.1f} hPa\n"
                    f"‚è∞ P√©riode : {bomb_start_local.strftime('%d/%m %H:%M')} ‚Üí {bomb_end_local.strftime('%d/%m %H:%M')}\n"
                    f"üí® Vent max pr√©vu : {max_wind:.1f} km/h\n"
                    f"üåßÔ∏è Pr√©cipitations : {total_precip:.1f} mm\n\n"
                    f"‚ö†Ô∏è RISQUES : Vents violents, pluies torrentielles, conditions dangereuses"
                )
                
                # Envoyer l'alerte sans v√©rification de records (√©viter r√©cursion)
                await send_alert(message)
                sent_alerts['pressure_msl'] = alert_date_key
                
                await log_message(f"Bombe m√©t√©orologique d√©tect√©e : {max_pressure_drop:.1f} hPa en 24h (seuil: {adjusted_threshold:.1f})")
        
        # Alerte pr√©ventive si proche du seuil (80% du seuil)
        elif max_pressure_drop >= adjusted_threshold * 0.8:
            bomb_start_time = df_forecast.iloc[bomb_start_idx]['time']
            bomb_start_local = bomb_start_time.tz_convert('Europe/Berlin')
            alert_date_key = bomb_start_local.date()
            
            if sent_alerts['pressure_msl'] != alert_date_key:
                await send_alert(
                    f"‚ö†Ô∏è Surveillance m√©t√©o : Forte baisse de pression pr√©vue de {max_pressure_drop:.1f} hPa en 24h "
                    f"(proche du seuil de bombe m√©t√©orologique: {adjusted_threshold:.1f} hPa). "
                    f"D√©but pr√©vu : {bomb_start_local.strftime('%d/%m √† %H:%M')}."
                )
                sent_alerts['pressure_msl'] = alert_date_key
                
    except Exception as e:
        await log_message(f"Erreur dans detect_meteorological_bomb: {str(e)}\n{traceback.format_exc()}")

async def check_data_freshness():
    """V√©rifie si la derni√®re donn√©e historis√©e date de plus de 24h et envoie une alerte."""
    global sent_alerts
    
    try:
        # V√©rifier que le fichier CSV existe et n'est pas vide
        if not os.path.exists(csv_filename) or os.path.getsize(csv_filename) == 0:
            await log_message("Fichier CSV inexistant ou vide pour v√©rification fra√Æcheur donn√©es.")
            return
        
        # Lire le CSV et obtenir la derni√®re entr√©e
        df = pd.read_csv(csv_filename)
        if df.empty:
            await log_message("CSV vide pour v√©rification fra√Æcheur donn√©es.")
            return
        
        # Convertir la colonne time et trier par date
        df['time'] = pd.to_datetime(df['time'], utc=True, errors='coerce')
        df.dropna(subset=['time'], inplace=True)
        
        if df.empty:
            await log_message("Aucune donn√©e temporelle valide pour v√©rification fra√Æcheur donn√©es.")
            return
        
        # Obtenir la derni√®re entr√©e chronologique
        df_sorted = df.sort_values('time')
        last_entry = df_sorted.iloc[-1]
        last_data_time = last_entry['time']
        
        # Heure actuelle
        now = pd.Timestamp.now(tz='UTC')
        
        # Calculer la diff√©rence en heures
        time_diff = now - last_data_time
        hours_since_last_data = time_diff.total_seconds() / 3600
        
        # Seuil de 24 heures
        alert_threshold_hours = 24
        
        # Convertir en heure locale pour l'affichage
        last_data_local = last_data_time.tz_convert('Europe/Berlin')
        last_data_str = last_data_local.strftime('%d/%m/%Y √† %H:%M')
        
        # V√©rifier si une alerte doit √™tre envoy√©e
        current_date = now.date()
        
        if hours_since_last_data > alert_threshold_hours:
            # √âviter le spam : ne pas envoyer plus d'une alerte par jour
            if sent_alerts['data_freshness'] != current_date:
                # Formater le message d'alerte
                if hours_since_last_data > 48:
                    urgency_emoji = "üö®"
                    urgency_text = "CRITIQUE"
                    days_old = int(hours_since_last_data // 24)
                    time_description = f"{days_old} jour{'s' if days_old > 1 else ''}"
                elif hours_since_last_data > 36:
                    urgency_emoji = "‚ö†Ô∏è"
                    urgency_text = "URGENT"
                    time_description = f"{hours_since_last_data:.1f} heures"
                else:
                    urgency_emoji = "‚è∞"
                    urgency_text = "ATTENTION"
                    time_description = f"{hours_since_last_data:.1f} heures"
                
                alert_message = (
                    f"{urgency_emoji} {urgency_text} - Donn√©es m√©t√©o obsol√®tes !\n\n"
                    f"üìä Derni√®re donn√©e historis√©e : {last_data_str}\n"
                    f"‚è±Ô∏è √Çge des donn√©es : {time_description}\n"
                    f"üî¥ Seuil d√©pass√© : {alert_threshold_hours}h\n\n"
                    f"ü§ñ L'API OpenMeteo a peut-√™tre chang√© ou le service est interrompu.\n"
                    f"üîß V√©rification et correction n√©cessaires."
                )
                
                # Envoyer l'alerte
                await send_alert(alert_message)
                sent_alerts['data_freshness'] = current_date
                
                await log_message(f"Alerte fra√Æcheur donn√©es envoy√©e: {hours_since_last_data:.1f}h depuis derni√®re donn√©e")
            else:
                await log_message(f"Donn√©es obsol√®tes ({hours_since_last_data:.1f}h) mais alerte d√©j√† envoy√©e aujourd'hui")
        else:
            # Donn√©es fra√Æches : r√©initialiser le tracking si n√©cessaire
            if sent_alerts['data_freshness'] is not None:
                await log_message(f"Donn√©es redevenues fra√Æches ({hours_since_last_data:.1f}h), r√©initialisation tracking alertes")
                sent_alerts['data_freshness'] = None
            
    except pd.errors.EmptyDataError:
        await log_message("Fichier CSV vide lors de la v√©rification de fra√Æcheur.")
    except Exception as e:
        await log_message(f"Erreur dans check_data_freshness: {str(e)}\n{traceback.format_exc()}")


def calculate_confidence_score(forecast_time, current_time):
    """Calcule un score de confiance bas√© sur la proximit√© temporelle de la pr√©vision.
    
    Args:
        forecast_time: Datetime de la pr√©vision
        current_time: Datetime actuel
    
    Returns:
        float: Score entre 0 et 1 (1 = tr√®s fiable, 0 = peu fiable)
    """
    try:
        time_diff_hours = abs((forecast_time - current_time).total_seconds()) / 3600
        
        if time_diff_hours <= 3:
            return 1.0  # Tr√®s fiable (0-3h)
        elif time_diff_hours <= 12:
            return 0.8  # Fiable (3-12h)
        elif time_diff_hours <= 24:
            return 0.6  # Mod√©r√©ment fiable (12-24h)
        elif time_diff_hours <= 48:
            return 0.4  # Peu fiable (24-48h)
        else:
            return 0.2  # Tr√®s peu fiable (48h+)
    except:
        return 0.5  # Fallback

async def check_predicted_record_changes():
    """V√©rifie les changements dans les records pr√©vus et notifie si n√©cessaire."""
    global predicted_records
    
    try:
        current_time = pd.Timestamp.now(tz='UTC')
        changes_detected = []
        
        for metric in predicted_records:
            for record_type in predicted_records[metric]:
                records_to_remove = []
                
                for record_id, record_info in predicted_records[metric][record_type].items():
                    # V√©rifier si le record est trop ancien sans mise √† jour
                    time_since_last_seen = (current_time - record_info['last_seen']).total_seconds() / 3600
                    time_until_forecast = (record_info['time'] - current_time).total_seconds() / 3600
                    
                    # D√©lai d'expiration adaptatif selon la proximit√© du record
                    if time_until_forecast <= 6:
                        # Record tr√®s proche : expiration apr√®s 2h sans mise √† jour
                        expiration_hours = 2
                    elif time_until_forecast <= 24:
                        # Record proche : expiration apr√®s 6h sans mise √† jour
                        expiration_hours = 6
                    else:
                        # Record lointain : expiration apr√®s 12h sans mise √† jour
                        expiration_hours = 12
                    
                    # V√©rifier si le record a expir√© (pas vu depuis trop longtemps)
                    if time_since_last_seen > expiration_hours:
                        # Record disparu - notification rapide d'annulation
                        if record_info['notified']:
                            changes_detected.append({
                                'type': 'expired',
                                'metric': metric,
                                'record_type': record_type,
                                'value': record_info['value'],
                                'time': record_info['time'],
                                'confidence': record_info['confidence'],
                                'missing_hours': time_since_last_seen
                            })
                        records_to_remove.append(record_id)
                    
                    # Nettoyage suppl√©mentaire : supprimer les records pass√©s
                    elif time_until_forecast < -2:  # Record pass√© depuis plus de 2h
                        records_to_remove.append(record_id)
                
                # Supprimer les records expir√©s
                for record_id in records_to_remove:
                    del predicted_records[metric][record_type][record_id]
        
        # Envoyer les notifications de changements
        for change in changes_detected:
            await notify_record_change(change)
            
    except Exception as e:
        await log_message(f"Erreur dans check_predicted_record_changes: {str(e)}")

async def notify_record_change(change_info):
    """Notifie un changement dans les records pr√©vus."""
    try:
        metric_info = get_metric_info(change_info['metric'])
        time_local = change_info['time'].tz_convert('Europe/Berlin')
        
        if change_info['type'] == 'expired':
            confidence_text = f"{change_info['confidence']*100:.0f}%"
            missing_hours = change_info.get('missing_hours', 0)
            
            # D√©terminer l'urgence du message selon la proximit√©
            time_until_forecast = (change_info['time'] - pd.Timestamp.now(tz='UTC')).total_seconds() / 3600
            
            if time_until_forecast <= 6:
                urgency_emoji = "‚ö†Ô∏è"
                urgency_text = "URGENT - "
            elif time_until_forecast <= 24:
                urgency_emoji = "üìâ"
                urgency_text = ""
            else:
                urgency_emoji = "üìã"
                urgency_text = ""
            
            message = (
                f"{urgency_emoji} {urgency_text}Mise √† jour pr√©visions : Le record potentiel de {metric_info['name']} "
                f"({change_info['value']:.1f}{metric_info['unit']}) pr√©vu pour "
                f"{time_local.strftime('%d/%m √† %H:%M')} n'appara√Æt plus dans les pr√©visions depuis "
                f"{missing_hours:.1f}h. (Confiance √©tait de {confidence_text})"
            )
            await send_alert(message)
            await log_message(f"Record potentiel expir√© notifi√©: {change_info['metric']} {change_info['value']} (disparu depuis {missing_hours:.1f}h)")
            
    except Exception as e:
        await log_message(f"Erreur dans notify_record_change: {str(e)}")

async def update_predicted_records(row_alert, alert_column, is_forecast=True):
    """Met √† jour le syst√®me de suivi des records pr√©vus."""
    global predicted_records
    
    if not is_forecast:
        return  # On ne suit que les pr√©visions
    
    try:
        # V√©rifier que la m√©trique est support√©e
        if alert_column not in predicted_records:
            await log_message(f"M√©trique {alert_column} non support√©e pour le suivi des records pr√©vus.")
            return
        
        current_time = pd.Timestamp.now(tz='UTC')
        forecast_time = row_alert['time']
        confidence = calculate_confidence_score(forecast_time, current_time)
        
        # Identifier les types de records √† v√©rifier selon la m√©trique
        record_types = ['max']
        if alert_column == 'temperature_2m' and 'min' in predicted_records[alert_column]:
            record_types.append('min')
        
        for record_type in record_types:
            # V√©rifier que le type de record existe pour cette m√©trique
            if record_type not in predicted_records[alert_column]:
                continue
                
            value = row_alert[alert_column]
            
            # Cr√©er un ID unique pour ce record bas√© sur la m√©trique, type et valeur
            record_id = f"{alert_column}_{record_type}_{value:.2f}_{forecast_time.strftime('%Y%m%d%H')}"
            
            # V√©rifier si c'est un nouveau record ou une mise √† jour
            existing_record = predicted_records[alert_column][record_type].get(record_id)
            
            if existing_record:
                # Mise √† jour d'un record existant
                existing_record['last_seen'] = current_time
                existing_record['confidence'] = max(existing_record['confidence'], confidence)
            else:
                # Nouveau record potentiel
                predicted_records[alert_column][record_type][record_id] = {
                    'value': value,
                    'time': forecast_time,
                    'confidence': confidence,
                    'first_detected': current_time,
                    'last_seen': current_time,
                    'notified': False
                }
                
    except Exception as e:
        await log_message(f"Erreur dans update_predicted_records: {str(e)}")

async def should_notify_record(record_info, metric, record_type):
    """D√©termine si un record doit √™tre notifi√© en √©vitant le spam."""
    global record_alert_history
    
    try:
        current_time = pd.Timestamp.now(tz='UTC')
        
        # Crit√®res pour notifier :
        # 1. Confiance suffisante (>= 0.6)
        # 2. Pas d√©j√† notifi√© r√©cemment pour une valeur similaire
        # 3. Record pas trop lointain (< 48h, limite de l'API)
        
        if record_info['confidence'] < 0.6:
            return False
        
        time_diff_hours = abs((record_info['time'] - current_time).total_seconds()) / 3600
        if time_diff_hours > 48:  # Limite de l'API
            return False
        
        # V√©rifier l'historique r√©cent (d√©lai adaptatif selon proximit√© du record)
        # Plus le record est proche, plus on peut notifier fr√©quemment les changements
        if time_diff_hours <= 3:
            # Record dans les 3h : notifications toutes les 30 minutes
            lookback_hours = 0.5
        elif time_diff_hours <= 12:
            # Record dans les 12h : notifications toutes les 2h
            lookback_hours = 2
        elif time_diff_hours <= 24:
            # Record dans les 24h : notifications toutes les 6h
            lookback_hours = 6
        else:
            # Record plus lointain : notifications toutes les 12h
            lookback_hours = 12
            
        cutoff_time = current_time - pd.Timedelta(hours=lookback_hours)
        recent_alerts = [
            alert for alert in record_alert_history 
            if alert['sent_at'] > cutoff_time 
            and alert['metric'] == metric 
            and alert['type'] == record_type
        ]
        
        # √âviter les notifications r√©p√©titives pour des valeurs similaires
        for alert in recent_alerts:
            value_diff = abs(alert['value'] - record_info['value'])
            # Seuils adaptatifs selon la m√©trique
            if metric == 'temperature_2m':
                threshold = 0.1  # 0.1¬∞C pour temp√©rature
            elif metric == 'precipitation':
                threshold = 0.5  # 0.5mm pour pr√©cipitations
            elif metric == 'windspeed_10m':
                threshold = 2.0  # 2 km/h pour vent
            elif metric == 'pressure_msl':
                threshold = 1.0  # 1 hPa pour pression
            elif metric == 'uv_index':
                threshold = 0.2  # 0.2 pour UV
            else:
                threshold = 0.5  # D√©faut
                
            if value_diff < threshold:
                return False
        
        return True
        
    except Exception as e:
        await log_message(f"Erreur dans should_notify_record: {str(e)}")
        return False

async def log_record_alert(metric, record_type, value, forecast_time):
    """Enregistre l'envoi d'une alerte de record."""
    global record_alert_history
    
    try:
        current_time = pd.Timestamp.now(tz='UTC')
        
        # Ajouter √† l'historique
        record_alert_history.append({
            'type': record_type,
            'metric': metric,
            'value': value,
            'time': forecast_time,
            'sent_at': current_time
        })
        
        # Nettoyer l'historique (garder seulement les 48 derni√®res heures)
        cutoff_time = current_time - pd.Timedelta(hours=48)
        record_alert_history = [
            alert for alert in record_alert_history 
            if alert['sent_at'] > cutoff_time
        ]
        
    except Exception as e:
        await log_message(f"Erreur dans log_record_alert: {str(e)}")

async def check_records(row_alert, alert_column, is_forecast=True):
    """V√©rifie si une valeur entrante bat un record annuel ET historique absolu.
    Args:
        is_forecast: True pour pr√©visions (message 'potentiel'), False pour donn√©es historiques (message 'nouveau record')
    
    V√©rifie 2 types de records :
    - Record annuel : comparaison avec l'ann√©e en cours uniquement
    - Record historique absolu : comparaison avec tout l'historique disponible
    
    Version am√©lior√©e avec gestion intelligente des notifications pour les pr√©visions.
    """
    try:
        if not os.path.exists(csv_filename) or os.path.getsize(csv_filename) == 0:
            await log_message("Fichier CSV vide ou inexistant, impossible de v√©rifier les records.")
            return

        df = pd.read_csv(csv_filename)
        if df.empty:
            await log_message("Fichier CSV lu mais vide, impossible de v√©rifier les records.")
            return

        df['time'] = pd.to_datetime(df['time'], utc=True, errors='coerce')
        df.dropna(subset=['time'], inplace=True)

        # S'assurer que la colonne d'alerte existe et est num√©rique
        if alert_column not in df.columns:
            await log_message(f"Colonne {alert_column} non trouv√©e dans le CSV pour v√©rifier les records.")
            return
        if not pd.api.types.is_numeric_dtype(df[alert_column]):
            await log_message(f"Colonne {alert_column} n'est pas num√©rique dans le CSV pour v√©rifier les records.")
            return

        current_year = pd.Timestamp.now(tz='UTC').year
        df_current_year = df[df['time'].dt.year == current_year].copy()
        time_local = row_alert['time'].tz_convert('Europe/Berlin')

        # Mettre √† jour le suivi des records pr√©vus si c'est une pr√©vision
        if is_forecast:
            await update_predicted_records(row_alert, alert_column, is_forecast)

        record_detected = False

        # === V√âRIFICATION RECORDS ANNUELS (ann√©e courante) ===
        if df_current_year.empty:
            await log_message(f"Aucune donn√©e pour l'ann√©e en cours ({current_year}), impossible de v√©rifier les records annuels pour {alert_column}.")
            # Si c'est la premi√®re donn√©e de l'ann√©e, elle √©tablit le record initial
            if not is_forecast:  # Seulement pour les donn√©es r√©elles
                await send_alert(f"üèÜ Info m√©t√©o : Premi√®re donn√©e de l'ann√©e pour {alert_column} : {row_alert[alert_column]} √† {time_local.strftime('%H:%M')}.")
        else:
            # V√©rification du record max annuel
            max_value_year = df_current_year[alert_column].max()
            if pd.notna(row_alert[alert_column]) and row_alert[alert_column] > max_value_year:
                # Trouver la date de l'ancien record
                max_idx = df_current_year[alert_column].idxmax()
                previous_record_time = df_current_year.loc[max_idx, 'time'].tz_convert('Europe/Berlin')
                previous_record_date = previous_record_time.strftime('%d/%m/%Y')
                
                record_detected = True
                record_info = {
                    'value': row_alert[alert_column],
                    'time': row_alert['time'],
                    'confidence': calculate_confidence_score(row_alert['time'], pd.Timestamp.now(tz='UTC')) if is_forecast else 1.0,
                    'notified': False
                }
                
                if is_forecast:
                    # Pour les pr√©visions, v√©rifier si on doit notifier
                    if await should_notify_record(record_info, alert_column, 'max'):
                        prefix = "Potentiel nouveau"
                        suffix = "pr√©vu"
                        confidence_text = f" (confiance: {record_info['confidence']*100:.0f}%)" if record_info['confidence'] < 1.0 else ""
                        await send_alert(f"üèÜ Alerte m√©t√©o : {prefix} record annuel {current_year} (max) pour {alert_column} : {row_alert[alert_column]} (pr√©c√©dent: {max_value_year} le {previous_record_date}) {suffix} √† {time_local.strftime('%H:%M')}{confidence_text}.")
                        await log_record_alert(alert_column, 'max', row_alert[alert_column], row_alert['time'])
                        # Marquer comme notifi√© dans le syst√®me de suivi
                        for record_id, stored_record in predicted_records[alert_column]['max'].items():
                            if abs(stored_record['value'] - row_alert[alert_column]) < 0.01:
                                stored_record['notified'] = True
                                break
                else:
                    # Pour les donn√©es historiques, toujours notifier
                    prefix = "Nouveau"
                    suffix = "confirm√©"
                    await send_alert(f"üèÜ Alerte m√©t√©o : {prefix} record annuel {current_year} (max) pour {alert_column} : {row_alert[alert_column]} (pr√©c√©dent: {max_value_year} le {previous_record_date}) {suffix} √† {time_local.strftime('%H:%M')}.")

            # V√©rification du record min annuel (sp√©cifiquement pour la temp√©rature)
            if alert_column == 'temperature_2m':
                min_value_year = df_current_year[alert_column].min()
                if pd.notna(row_alert[alert_column]) and row_alert[alert_column] < min_value_year:
                    # Trouver la date de l'ancien record
                    min_idx = df_current_year[alert_column].idxmin()
                    previous_record_time = df_current_year.loc[min_idx, 'time'].tz_convert('Europe/Berlin')
                    previous_record_date = previous_record_time.strftime('%d/%m/%Y')
                    
                    record_detected = True
                    record_info = {
                        'value': row_alert[alert_column],
                        'time': row_alert['time'],
                        'confidence': calculate_confidence_score(row_alert['time'], pd.Timestamp.now(tz='UTC')) if is_forecast else 1.0,
                        'notified': False
                    }
                    
                    if is_forecast:
                        # Pour les pr√©visions, v√©rifier si on doit notifier
                        if await should_notify_record(record_info, alert_column, 'min'):
                            prefix = "Potentiel nouveau"
                            suffix = "pr√©vu"
                            confidence_text = f" (confiance: {record_info['confidence']*100:.0f}%)" if record_info['confidence'] < 1.0 else ""
                            await send_alert(f"üèÜ Alerte m√©t√©o : {prefix} record annuel {current_year} (min) pour {alert_column} : {row_alert[alert_column]} (pr√©c√©dent: {min_value_year} le {previous_record_date}) {suffix} √† {time_local.strftime('%H:%M')}{confidence_text}.")
                            await log_record_alert(alert_column, 'min', row_alert[alert_column], row_alert['time'])
                            # Marquer comme notifi√© dans le syst√®me de suivi
                            for record_id, stored_record in predicted_records[alert_column]['min'].items():
                                if abs(stored_record['value'] - row_alert[alert_column]) < 0.01:
                                    stored_record['notified'] = True
                                    break
                    else:
                        # Pour les donn√©es historiques, toujours notifier
                        prefix = "Nouveau"
                        suffix = "confirm√©"
                        await send_alert(f"üèÜ Alerte m√©t√©o : {prefix} record annuel {current_year} (min) pour {alert_column} : {row_alert[alert_column]} (pr√©c√©dent: {min_value_year} le {previous_record_date}) {suffix} √† {time_local.strftime('%H:%M')}.")

        # === V√âRIFICATION RECORDS HISTORIQUES ABSOLUS (tout l'historique) ===
        available_years = sorted(df['time'].dt.year.unique())
        first_year = min(available_years)
        
        # Record max historique absolu
        max_value_absolute = df[alert_column].max()
        if pd.notna(row_alert[alert_column]) and row_alert[alert_column] > max_value_absolute:
            # Trouver la date de l'ancien record historique absolu
            max_absolute_idx = df[alert_column].idxmax()
            previous_absolute_record_time = df.loc[max_absolute_idx, 'time'].tz_convert('Europe/Berlin')
            previous_absolute_record_date = previous_absolute_record_time.strftime('%d/%m/%Y')
            
            record_detected = True
            record_info = {
                'value': row_alert[alert_column],
                'time': row_alert['time'],
                'confidence': calculate_confidence_score(row_alert['time'], pd.Timestamp.now(tz='UTC')) if is_forecast else 1.0,
                'notified': False
            }
            
            if is_forecast:
                # Pour les records historiques absolus, seuil de confiance plus √©lev√©
                if record_info['confidence'] >= 0.7 and await should_notify_record(record_info, alert_column, 'max'):
                    prefix = "Potentiel nouveau"
                    suffix = "pr√©vu"
                    confidence_text = f" (confiance: {record_info['confidence']*100:.0f}%)" if record_info['confidence'] < 1.0 else ""
                    await send_alert(f"üî• RECORD HISTORIQUE : {prefix} record absolu (max) pour {alert_column} : {row_alert[alert_column]} (pr√©c√©dent: {max_value_absolute} le {previous_absolute_record_date}) {suffix} √† {time_local.strftime('%H:%M')} ! Donn√©es depuis {first_year}{confidence_text}.")
                    await log_record_alert(alert_column, 'max_absolute', row_alert[alert_column], row_alert['time'])
            else:
                # Pour les donn√©es historiques, toujours notifier
                prefix = "Nouveau"
                suffix = "confirm√©"
                await send_alert(f"üî• RECORD HISTORIQUE : {prefix} record absolu (max) pour {alert_column} : {row_alert[alert_column]} (pr√©c√©dent: {max_value_absolute} le {previous_absolute_record_date}) {suffix} √† {time_local.strftime('%H:%M')} ! Donn√©es depuis {first_year}.")

        # Record min historique absolu (sp√©cifiquement pour la temp√©rature)
        if alert_column == 'temperature_2m':
            min_value_absolute = df[alert_column].min()
            if pd.notna(row_alert[alert_column]) and row_alert[alert_column] < min_value_absolute:
                # Trouver la date de l'ancien record historique absolu (min)
                min_absolute_idx = df[alert_column].idxmin()
                previous_absolute_min_record_time = df.loc[min_absolute_idx, 'time'].tz_convert('Europe/Berlin')
                previous_absolute_min_record_date = previous_absolute_min_record_time.strftime('%d/%m/%Y')
                
                record_detected = True
                record_info = {
                    'value': row_alert[alert_column],
                    'time': row_alert['time'],
                    'confidence': calculate_confidence_score(row_alert['time'], pd.Timestamp.now(tz='UTC')) if is_forecast else 1.0,
                    'notified': False
                }
                
                if is_forecast:
                    # Pour les records historiques absolus, seuil de confiance plus √©lev√©
                    if record_info['confidence'] >= 0.7 and await should_notify_record(record_info, alert_column, 'min'):
                        prefix = "Potentiel nouveau"
                        suffix = "pr√©vu"
                        confidence_text = f" (confiance: {record_info['confidence']*100:.0f}%)" if record_info['confidence'] < 1.0 else ""
                        await send_alert(f"ü•∂ RECORD HISTORIQUE : {prefix} record absolu (min) pour {alert_column} : {row_alert[alert_column]} (pr√©c√©dent: {min_value_absolute} le {previous_absolute_min_record_date}) {suffix} √† {time_local.strftime('%H:%M')} ! Donn√©es depuis {first_year}{confidence_text}.")
                        await log_record_alert(alert_column, 'min_absolute', row_alert[alert_column], row_alert['time'])
                else:
                    # Pour les donn√©es historiques, toujours notifier
                    prefix = "Nouveau"
                    suffix = "confirm√©"
                    await send_alert(f"ü•∂ RECORD HISTORIQUE : {prefix} record absolu (min) pour {alert_column} : {row_alert[alert_column]} (pr√©c√©dent: {min_value_absolute} le {previous_absolute_min_record_date}) {suffix} √† {time_local.strftime('%H:%M')} ! Donn√©es depuis {first_year}.")

    except pd.errors.EmptyDataError:
        await log_message("Fichier CSV vide lors de la v√©rification des records.")
    except FileNotFoundError:
        await log_message(f"Fichier {csv_filename} non trouv√© lors de la v√©rification des records.")
    except KeyError as e:
        await log_message(f"Erreur de cl√© dans check_records (colonne manquante?): {str(e)}")
    except Exception as e:
        await log_message(f"Erreur inattendue dans check_records: {str(e)}\n{traceback.format_exc()}")


def calculate_sunshine_hours(df_calc):
    """Calcule les heures d'ensoleillement estim√©es √† partir d'un DataFrame.
    Optimis√© pour la localisation configur√©e avec calculs astronomiques am√©lior√©s."""
    # Cr√©er une copie pour √©viter SettingWithCopyWarning si df_calc est une slice
    df = df_calc.copy()
    
    # Assurer que 'time' est datetime et localis√©
    if not pd.api.types.is_datetime64_any_dtype(df['time']):
        df['time'] = pd.to_datetime(df['time'], utc=True, errors='coerce')
        df.dropna(subset=['time'], inplace=True)

    if df['time'].dt.tz is None:
         df['time'] = df['time'].dt.tz_localize('UTC')

    df['local_time'] = df['time'].dt.tz_convert('Europe/Berlin')
    
    # Coordonn√©es de la ville pour calculs astronomiques plus pr√©cis
    CITY_LAT = float(LATITUDE)  # Latitude depuis config.ini
    
    # Calcul approximatif du lever/coucher du soleil pour la localisation
    # Bas√© sur l'√©quation du temps et la d√©clinaison solaire
    def get_daylight_hours_city(day_of_year):
        """Calcule les heures approximatives de lever/coucher du soleil pour la ville."""
        import math
        
        # D√©clinaison solaire (approximation)
        declination = 23.45 * math.sin(math.radians(360 * (284 + day_of_year) / 365))
        
        # Angle horaire du coucher du soleil
        try:
            cos_hour_angle = -math.tan(math.radians(CITY_LAT)) * math.tan(math.radians(declination))
            # Limiter entre -1 et 1 pour √©viter les erreurs de domaine
            cos_hour_angle = max(-1, min(1, cos_hour_angle))
            hour_angle = math.degrees(math.acos(cos_hour_angle))
            
            # Heures de lever et coucher (approximatives, en heures d√©cimales)
            sunrise_hour = 12 - hour_angle / 15
            sunset_hour = 12 + hour_angle / 15
            
            # Ajustements pour l'√©quation du temps et l'heure d'√©t√© (approximatifs)
            # Correction pour le fuseau horaire Europe/Berlin
            sunrise_hour += 0.5  # Correction approximative
            sunset_hour += 0.5
            
            return max(4, sunrise_hour), min(22, sunset_hour)  # Limites raisonnables
        except:
            # Fallback vers les valeurs saisonni√®res si le calcul √©choue
            if 80 <= day_of_year <= 266:  # Printemps/√ât√© approximatif
                return 6, 20
            else:  # Automne/Hiver
                return 8, 17
    
    # Calcul du jour de l'ann√©e et application des heures de jour pr√©cises
    df['day_of_year'] = df['local_time'].dt.dayofyear
    df['hour'] = df['local_time'].dt.hour + df['local_time'].dt.minute / 60.0
    df['is_daytime'] = False
    
    # Appliquer le calcul astronomique pour chaque jour unique
    for day_of_year in df['day_of_year'].unique():
        if pd.notna(day_of_year):
            sunrise, sunset = get_daylight_hours_city(int(day_of_year))
            day_mask = df['day_of_year'] == day_of_year
            df.loc[day_mask, 'is_daytime'] = (df.loc[day_mask, 'hour'] >= sunrise) & (df.loc[day_mask, 'hour'] <= sunset)
    
    # Crit√®res d'ensoleillement am√©lior√©s pour la r√©gion
    if 'uv_index' in df.columns and pd.api.types.is_numeric_dtype(df['uv_index']):
        # Seuils UV adaptatifs selon la saison pour la localisation
        def get_uv_threshold(month):
            """Seuils UV optimis√©s pour la latitude et climat local."""
            if month in [12, 1, 2]:      # Hiver : soleil plus faible
                return 1.0
            elif month in [3, 4, 10, 11]: # Inter-saisons
                return 1.5
            else:                         # Printemps/√ât√© : seuil plus √©lev√©
                return 2.0
        
        df['month'] = df['local_time'].dt.month
        df['uv_threshold'] = df['month'].apply(get_uv_threshold)
        
        # Conditions d'ensoleillement : jour + UV suffisant + pas de forte pluie
        uv_condition = df['uv_index'].fillna(0) > df['uv_threshold']
        
        # Condition m√©t√©o : pas de fortes pr√©cipitations (nuages √©pais)
        if 'precipitation' in df.columns and pd.api.types.is_numeric_dtype(df['precipitation']):
            no_heavy_rain = df['precipitation'].fillna(0) < 2.0  # Moins de 2mm/h
        else:
            no_heavy_rain = True
        
        # Condition d'humidit√© : √©viter les brouillards √©pais (climat lacustre)
        if 'relativehumidity_2m' in df.columns and pd.api.types.is_numeric_dtype(df['relativehumidity_2m']):
            no_thick_fog = df['relativehumidity_2m'].fillna(100) < 95  # Moins de 95% d'humidit√©
        else:
            no_thick_fog = True
        
        # Combinaison des conditions pour un ensoleillement effectif
        df['is_sunny'] = df['is_daytime'] & uv_condition & no_heavy_rain & no_thick_fog
        sunshine_hours = df['is_sunny'].sum()
    else:
        # Fallback si pas de donn√©es UV : estimation bas√©e sur les conditions m√©t√©o seules
        if ('precipitation' in df.columns and
            'relativehumidity_2m' in df.columns and
            pd.api.types.is_numeric_dtype(df['precipitation']) and
            pd.api.types.is_numeric_dtype(df['relativehumidity_2m'])):
            
            # Estimation sans UV : conditions m√©t√©o favorables
            good_weather = (df['precipitation'].fillna(0) < 1.0) & (df['relativehumidity_2m'].fillna(100) < 85)
            df['is_sunny'] = df['is_daytime'] & good_weather
            sunshine_hours = df['is_sunny'].sum() * 0.7  # Facteur de correction sans UV
        else:
            # Estimation tr√®s approximative bas√©e sur les heures de jour seules
            sunshine_hours = df['is_daytime'].sum() * 0.4  # 40% d'ensoleillement moyen

    return sunshine_hours


def calculate_monthly_sunshine(df_calc):
    """Calcule les heures d'ensoleillement par mois."""
    df = df_calc.copy()
    if df.empty:
        return pd.Series(dtype=float)

    if not pd.api.types.is_datetime64_any_dtype(df['time']):
        df['time'] = pd.to_datetime(df['time'], utc=True, errors='coerce')
    df.dropna(subset=['time'], inplace=True)
    if df['time'].dt.tz is None:
         df['time'] = df['time'].dt.tz_localize('UTC')
    
    # Grouper par mois et appliquer le calcul d'ensoleillement
    # apply peut √™tre lent sur de gros dataframes, mais pour des donn√©es mensuelles, c'est acceptable.
    monthly_sunshine = df.groupby(pd.Grouper(key='time', freq='MS')).apply(calculate_sunshine_hours) # MS for Month Start
    
    # Formatter l'index pour la lisibilit√©
    if not monthly_sunshine.empty:
        monthly_sunshine.index = monthly_sunshine.index.strftime('%Y-%m')
    
    return monthly_sunshine


def generate_summary(df_summary):
    """G√©n√®re un texte de r√©sum√© m√©t√©o √† partir d'un DataFrame."""
    df = df_summary.copy() # Travailler sur une copie
    if df.empty:
        return "Aucune donn√©e √† r√©sumer."

    # Assurer que 'time' est datetime et UTC
    if not pd.api.types.is_datetime64_any_dtype(df['time']):
        df['time'] = pd.to_datetime(df['time'], utc=True, errors='coerce')
    df.dropna(subset=['time'], inplace=True)
    if df['time'].dt.tz is None:
        df['time'] = df['time'].dt.tz_localize('UTC')

    # Calculs statistiques (s'assurer que les colonnes existent et sont num√©riques)
    # Fonction utilitaire pour obtenir une statistique ou une valeur par d√©faut
    def get_stat(df_stat, column, operation):
        if column not in df_stat.columns or not pd.api.types.is_numeric_dtype(df_stat[column]) or df_stat[column].isnull().all():
            return pd.NA, pd.NaT if operation in ['idxmax', 'idxmin'] else pd.NA
        
        if operation == 'max': return df_stat[column].max()
        if operation == 'min': return df_stat[column].min()
        if operation == 'idxmax': return df_stat[column].idxmax() if not df_stat[column].empty else pd.NaT
        if operation == 'idxmin': return df_stat[column].idxmin() if not df_stat[column].empty else pd.NaT
        if operation == 'mean': return df_stat[column].mean()
        if operation == 'sum': return df_stat[column].sum()
        if operation == 'nunique_rainy': # Cas sp√©cial pour les jours de pluie
            df_stat['day_for_rain'] = df_stat['time'].dt.date
            daily_precip = df_stat.groupby('day_for_rain')[column].sum()
            return daily_precip[daily_precip > 0.1].count()
        return pd.NA

    # Pr√©cipitations journali√®res
    if 'precipitation' in df.columns and pd.api.types.is_numeric_dtype(df['precipitation']):
        df['day'] = df['time'].dt.date
        # Calculer la somme des pr√©cipitations par jour, g√©rer les NaN en les rempla√ßant par 0 pour la somme
        df['daily_precipitation'] = df.groupby('day')['precipitation'].transform(lambda x: x.fillna(0).sum())
    else:
        df['daily_precipitation'] = 0 # Colonne par d√©faut si 'precipitation' manque

    # Calculs mensuels pour ensoleillement et pr√©cipitations
    df['local_time'] = df['time'].dt.tz_convert('Europe/Berlin')
    df['year_month'] = df['local_time'].dt.to_period('M')
    
    # Calculer l'ensoleillement mensuel
    sunniest_month = "N/A"
    rainiest_month = "N/A"
    
    try:
        monthly_sunshine = df.groupby('year_month').apply(calculate_sunshine_hours)
        if not monthly_sunshine.empty:
            sunniest_period = monthly_sunshine.idxmax()
            sunniest_month = f"{sunniest_period.strftime('%B %Y')} ({monthly_sunshine.max():.1f}h)"
    except Exception:
        pass
    
    # Calculer les pr√©cipitations mensuelles
    try:
        if 'precipitation' in df.columns and pd.api.types.is_numeric_dtype(df['precipitation']):
            monthly_precip = df.groupby('year_month')['precipitation'].sum()
            if not monthly_precip.empty:
                rainiest_period = monthly_precip.idxmax()
                rainiest_month = f"{rainiest_period.strftime('%B %Y')} ({monthly_precip.max():.1f}mm)"
    except Exception:
        pass

    max_temp, idx_hot_day = get_stat(df, 'temperature_2m', 'max'), get_stat(df, 'temperature_2m', 'idxmax')
    min_temp, idx_cold_day = get_stat(df, 'temperature_2m', 'min'), get_stat(df, 'temperature_2m', 'idxmin')
    max_precipitation, idx_rain_day = get_stat(df, 'daily_precipitation', 'max'), get_stat(df, 'daily_precipitation', 'idxmax')
    max_uv_index, idx_uv_day = get_stat(df, 'uv_index', 'max'), get_stat(df, 'uv_index', 'idxmax')
    max_wind_speed, idx_wind_day = get_stat(df, 'windspeed_10m', 'max'), get_stat(df, 'windspeed_10m', 'idxmax')
    avg_temp = get_stat(df, 'temperature_2m', 'mean')
    max_humidity, idx_humid_day = get_stat(df, 'relativehumidity_2m', 'max'), get_stat(df, 'relativehumidity_2m', 'idxmax')
    min_humidity, idx_dry_day = get_stat(df, 'relativehumidity_2m', 'min'), get_stat(df, 'relativehumidity_2m', 'idxmin')
    rainy_days = get_stat(df, 'precipitation', 'nunique_rainy')


    # Formatter les dates pour l'affichage (convertir en 'Europe/Berlin')
    def format_date_from_idx(idx, df_ref):
        if pd.isna(idx) or idx not in df_ref.index: return "N/A"
        return df_ref.loc[idx, 'time'].tz_convert('Europe/Berlin').strftime("%Y-%m-%d")

    hot_day_berlin = format_date_from_idx(idx_hot_day, df)
    cold_day_berlin = format_date_from_idx(idx_cold_day, df)
    # Pour rain_day, l'index vient de 'daily_precipitation' qui peut avoir un index diff√©rent apr√®s groupby.
    # On utilise l'index original du DataFrame o√π 'daily_precipitation' a √©t√© assign√©.
    rain_day_berlin = format_date_from_idx(idx_rain_day, df) if pd.notna(idx_rain_day) else "N/A"

    uv_day_berlin = format_date_from_idx(idx_uv_day, df)
    wind_day_berlin = format_date_from_idx(idx_wind_day, df)
    humid_day_berlin = format_date_from_idx(idx_humid_day, df)
    dry_day_berlin = format_date_from_idx(idx_dry_day, df)

    # Cr√©er le r√©sum√© en g√©rant les valeurs N/A
    summary_parts = [
        f"üå°Ô∏è Jour le plus chaud: {hot_day_berlin} ({max_temp:.1f}¬∞C)" if pd.notna(max_temp) else "üå°Ô∏è Jour le plus chaud: N/A",
        f"‚ùÑÔ∏è Jour le plus froid: {cold_day_berlin} ({min_temp:.1f}¬∞C)" if pd.notna(min_temp) else "‚ùÑÔ∏è Jour le plus froid: N/A",
        f"üåßÔ∏è Jour le plus pluvieux: {rain_day_berlin} ({max_precipitation:.1f}mm)" if pd.notna(max_precipitation) else "üåßÔ∏è Jour le plus pluvieux: N/A",
        f"‚òÄÔ∏è Jour avec l'index UV le plus √©lev√©: {uv_day_berlin} (index {max_uv_index:.1f})" if pd.notna(max_uv_index) else "‚òÄÔ∏è Index UV max: N/A",
        f"üí® Jour le plus venteux: {wind_day_berlin} ({max_wind_speed:.1f} km/h)" if pd.notna(max_wind_speed) else "üí® Vent max: N/A",
        f"üåÇ Nombre de jours de pluie (>0.1mm): {rainy_days}" if pd.notna(rainy_days) else "üåÇ Jours de pluie: N/A",
        f"üå°Ô∏è Temp√©rature moyenne: {avg_temp:.1f}¬∞C" if pd.notna(avg_temp) else "üå°Ô∏è Temp. moyenne: N/A",
        f"üåßÔ∏è Mois le plus pluvieux: {rainiest_month}",
        f"üí¶ Jour le plus humide: {humid_day_berlin} ({max_humidity:.1f}%)" if pd.notna(max_humidity) else "üí¶ Humidit√© max: N/A",
        f"üèúÔ∏è Jour le plus sec: {dry_day_berlin} ({min_humidity:.1f}%)" if pd.notna(min_humidity) else "üèúÔ∏è Humidit√© min: N/A",
        f"‚òÄÔ∏è Mois le plus ensoleill√©: {sunniest_month}"
    ]
    return "\n".join(summary_parts)

# --- Fonctions utilitaires pour graphiques et dates ---
def parse_date_input(date_str):
    """Parse et valide une date d'entr√©e (format YYYY-MM-DD)."""
    try:
        return pd.to_datetime(date_str, format='%Y-%m-%d', utc=True)
    except (ValueError, TypeError):
        return None

async def create_graph_image(fig):
    """Convertit une figure matplotlib en BytesIO pour Telegram."""
    buf = io.BytesIO()
    fig.savefig(buf, format='png', dpi=150, bbox_inches='tight')
    buf.seek(0)
    plt.close(fig)
    return buf

async def send_graph(chat_id, fig, caption):
    """Envoie un graphique via Telegram."""
    try:
        buf = await create_graph_image(fig)
        input_file = BufferedInputFile(buf.getvalue(), filename="graph.png")
        await bot.send_photo(chat_id=chat_id, photo=input_file, caption=caption)
        await log_message(f"Graphique envoy√© avec succ√®s √† chat_id: {chat_id}")
    except Exception as e:
        await log_message(f"Erreur envoi graphique √† {chat_id}: {str(e)}")
        await bot.send_message(chat_id, f"Erreur lors de la g√©n√©ration du graphique: {str(e)}")

def get_metric_info(metric):
    """Retourne les informations d'affichage pour une m√©trique."""
    metrics = {
        'temperature_2m': {'name': 'Temp√©rature', 'unit': '¬∞C', 'emoji': 'üå°Ô∏è'},
        'precipitation': {'name': 'Pr√©cipitations', 'unit': 'mm', 'emoji': 'üåßÔ∏è'},
        'windspeed_10m': {'name': 'Vitesse du vent', 'unit': 'km/h', 'emoji': 'üí®'},
        'pressure_msl': {'name': 'Pression', 'unit': 'hPa', 'emoji': 'üéà'},
        'uv_index': {'name': 'Indice UV', 'unit': '', 'emoji': '‚òÄÔ∏è'},
        'relativehumidity_2m': {'name': 'Humidit√©', 'unit': '%', 'emoji': 'üí¶'},
        'precipitation_probability': {'name': 'Probabilit√© pluie', 'unit': '%', 'emoji': 'üå¶Ô∏è'}
    }
    return metrics.get(metric, {'name': metric, 'unit': '', 'emoji': 'üìä'})

# --- D√©finition des Handlers avec le Router ---
@router.message(Command("start"))
async def start_command(message: types.Message):
    chat_id = message.chat.id
    is_new_user = True
    
    chats = []
    # Utilisation de aiofiles pour lire/√©crire chat_ids.json
    if os.path.exists('chat_ids.json'):
        try:
            async with aiofiles.open('chat_ids.json', 'r', encoding='utf-8') as file:
                content = await file.read()
                chats = json.loads(content)
            if chat_id in chats:
                is_new_user = False
            else:
                chats.append(chat_id)
        except (json.JSONDecodeError, FileNotFoundError) as e:
            await log_message(f"Erreur lecture chat_ids.json pour start: {e}. Initialisation avec nouveau user.")
            chats = [chat_id] # repartir d'une liste fra√Æche
    else:
        chats = [chat_id]
    
    try:
        async with aiofiles.open('chat_ids.json', 'w', encoding='utf-8') as file:
            await file.write(json.dumps(chats))
    except Exception as e:
        await log_message(f"Erreur √©criture chat_ids.json pour start: {e}")

    welcome_ville = VILLE if VILLE else "votre localit√©" # Fallback si VILLE n'est pas d√©fini
    if is_new_user:
        welcome_message = (
            f"Bienvenue sur le bot m√©t√©o de {welcome_ville}! üå§Ô∏è\n\n"
            "üìä **Commandes de base :**\n"
            "/weather - Derni√®res donn√©es m√©t√©o enregistr√©es\n"
            "/forecast - Pr√©visions pour les prochaines heures\n"
            "/sunshine - Graphique barres ensoleillement par mois/ann√©e\n\n"
            "üìÖ **R√©sum√©s par p√©riode :**\n"
            "/month - R√©sum√© du mois dernier\n"
            "/year - R√©sum√© de l'ann√©e en cours\n"
            "/all - R√©sum√© de toutes les donn√©es\n"
            "/daterange YYYY-MM-DD YYYY-MM-DD - Ex: /daterange 2024-01-01 2024-12-31\n\n"
            "üìà **Graphiques et analyses :**\n"
            "/forecastgraph - Graphique des pr√©visions 24h\n"
            "/graph <m√©trique> [jours] - Ex: /graph temperature 30\n"
            "   M√©triques: temperature, rain, wind, pressure, uv, humidity\n"
            "/heatmap [ann√©e|all] - Ex: /heatmap 2024 ou /heatmap all\n"
            "/yearcompare [m√©trique] - Ex: /yearcompare temperature\n"
            "   M√©triques: temperature, rain, wind, pressure, uv, humidity\n"
            "/sunshinelist - Liste texte ensoleillement mensuel\n"
            "/top10 <m√©trique> - Ex: /top10 temperature\n"
            "   M√©triques: temperature, rain, wind, pressure, uv, humidity\n\n"
            f"üí° **Exemples rapides :**\n"
            f"/graph rain 7 - Pluie des 7 derniers jours\n"
            f"/sunshinelist - √âvolution ensoleillement\n"
            f"/top10 wind - Vents les plus forts\n"
            f"/daterange 2024-06-01 2024-08-31 - √ât√© 2024\n\n"
            f"N'h√©sitez pas √† explorer ces fonctionnalit√©s pour analyser la m√©t√©o √† {welcome_ville}!"
        )
        await message.reply(welcome_message)
    else:
        welcome_back_message = (
            "Vous avez d√©j√† lanc√© le bot ! üå§Ô∏è\n\n"
            "üìã **Rappel des commandes principales :**\n"
            "‚Ä¢ /weather - M√©t√©o actuelle\n"
            "‚Ä¢ /forecast - Pr√©visions\n"
            "‚Ä¢ /graph temp 7 - Graphique temp√©rature 7 jours\n"
            "‚Ä¢ /heatmap 2024 - Calendrier thermique 2024\n"
            "‚Ä¢ /top10 rain - Top 10 pr√©cipitations\n"
            "‚Ä¢ /daterange 2024-01-01 2024-12-31 - R√©sum√© p√©riode\n\n"
            "üí° **M√©triques disponibles :**\n"
            "temperature, rain, wind, pressure, uv, humidity\n\n"
            "Quelle information m√©t√©o souhaitez-vous obtenir aujourd'hui?"
        )
        await message.reply(welcome_back_message)

@router.message(Command("weather"))
async def get_latest_info_command(message: types.Message):
    try:
        await log_message("D√©but de get_latest_info_command")
        
        if not os.path.exists(csv_filename) or os.path.getsize(csv_filename) == 0:
            await log_message("Fichier CSV inexistant ou vide pour /weather.")
            await message.reply("Aucune donn√©e m√©t√©o disponible pour le moment.")
            return

        df = pd.read_csv(csv_filename)
        await log_message("CSV lu avec succ√®s pour /weather")
        
        if df.empty:
            await log_message("Le DataFrame est vide pour /weather")
            await message.reply("Aucune donn√©e disponible.")
        else:
            # S'assurer que la colonne 'time' est bien en datetime pour le tri avant de prendre la derni√®re
            df['time'] = pd.to_datetime(df['time'], utc=True, errors='coerce')
            df.dropna(subset=['time'], inplace=True)
            df.sort_values(by='time', inplace=True)

            if df.empty: # Peut devenir vide apr√®s dropna
                 await message.reply("Aucune donn√©e valide disponible apr√®s nettoyage.")
                 return

            latest_info = df.iloc[-1].to_dict()
            # La date est d√©j√† en UTC, la convertir pour affichage
            time_display = pd.to_datetime(latest_info['time'], utc=True).tz_convert('Europe/Berlin').strftime("%Y-%m-%d %H:%M:%S")
            
            response_parts = [f"üå°Ô∏è M√©t√©o la plus r√©cente enregistr√©e √† {VILLE} :\n"]
            response_parts.append(f"üìÖ {time_display}\n")
            response_parts.append(f"üå°Ô∏è Temp√©rature: {latest_info.get('temperature_2m', 'N/A')}¬∞C")
            response_parts.append(f"üåßÔ∏è Probabilit√© de pluie: {latest_info.get('precipitation_probability', 'N/A')}%")
            response_parts.append(f"üíß Pr√©cipitations: {latest_info.get('precipitation', 'N/A')}mm")
            response_parts.append(f"üí® Vent: {latest_info.get('windspeed_10m', 'N/A')}km/h")
            response_parts.append(f"‚òÄÔ∏è Indice UV: {latest_info.get('uv_index', 'N/A')}")
            response_parts.append(f"üéà Pression: {latest_info.get('pressure_msl', 'N/A')} hPa") # Chang√© emoji
            response_parts.append(f"üí¶ Humidit√©: {latest_info.get('relativehumidity_2m', 'N/A')}%")
            
            await log_message("R√©ponse /weather pr√©par√©e, tentative d'envoi")
            await message.reply("\n".join(response_parts))
            await log_message("R√©ponse /weather envoy√©e avec succ√®s")

    except pd.errors.EmptyDataError:
        await log_message("Fichier CSV vide pour /weather (EmptyDataError).")
        await message.reply("Aucune donn√©e m√©t√©o disponible (fichier vide).")
    except FileNotFoundError:
        await log_message(f"Fichier {csv_filename} non trouv√© pour /weather.")
        await message.reply("Source de donn√©es m√©t√©o non trouv√©e.")
    except Exception as e:
        await log_message(f"Error in get_latest_info_command: {str(e)}\n{traceback.format_exc()}")
        await message.reply(f"Erreur lors de l'obtention des informations : {str(e)}")


@router.message(Command("forecast"))
async def get_forecast_command(message: types.Message): # Renomm√© pour clart√©
    try:
        # Utiliser le cache au lieu d'appeler directement l'API
        df_next_seven_hours, _ = await get_cached_forecast_data()
        if df_next_seven_hours.empty:
            await message.reply("Aucune donn√©e de pr√©vision disponible pour le moment.")
            return
        
        # Prendre les 6 prochaines heures de pr√©vision
        forecast_df = df_next_seven_hours.head(6)
        response = f"üîÆ Pr√©visions m√©t√©o pour {VILLE} (prochaines heures):\n\n"
        
        for _, row in forecast_df.iterrows():
            time_local = row['time'].tz_convert('Europe/Berlin').strftime("%H:%M")
            temp = row.get('temperature_2m', float('nan'))
            precip = row.get('precipitation', float('nan'))
            precip_prob = row.get('precipitation_probability', float('nan'))
            wind = row.get('windspeed_10m', float('nan'))
            uv = row.get('uv_index', float('nan'))
            humidity = row.get('relativehumidity_2m', float('nan'))
            
            temp_emoji = "ü•µ" if temp > 30 else "ü•∂" if temp < 10 else "üå°Ô∏è"
            precip_emoji = "üåßÔ∏è" if precip > 0.1 else "‚òÄÔ∏è" # Seuil pour pluie
            wind_emoji = "üå¨Ô∏è" if wind > 30 else "üçÉ" # Seuil pour vent fort
            
            response += f"‚è∞ {time_local}:\n"
            response += f"{temp_emoji} {temp:.1f}¬∞C | "
            response += f"{precip_emoji} {precip:.1f}mm ({precip_prob:.0f}%) | "
            response += f"{wind_emoji} {wind:.1f}km/h | "
            response += f"‚òÄÔ∏è UV: {uv:.1f} | "
            response += f"üí¶ {humidity:.0f}%\n\n"
        
        await message.reply(response)
    except Exception as e:
        await log_message(f"Error in get_forecast_command: {str(e)}\n{traceback.format_exc()}")
        await message.reply("Erreur lors de l'obtention des pr√©visions.")


@router.message(Command("sunshine"))
async def get_sunshine_summary_command(message: types.Message):
    """G√©n√®re un graphique en barres de l'ensoleillement mensuel par ann√©e."""
    try:
        if not os.path.exists(csv_filename) or os.path.getsize(csv_filename) == 0:
            await message.reply("Aucune donn√©e disponible pour calculer l'ensoleillement.")
            return
            
        df = pd.read_csv(csv_filename)
        if df.empty:
            await message.reply("Aucune donn√©e disponible pour calculer l'ensoleillement (fichier vide).")
            return

        df['time'] = pd.to_datetime(df['time'], utc=True, errors='coerce')
        df.dropna(subset=['time'], inplace=True)

        if df.empty:
            await message.reply("Aucune donn√©e temporelle valide pour calculer l'ensoleillement.")
            return

        # Convertir en heure locale et extraire ann√©e/mois
        df['local_time'] = df['time'].dt.tz_convert('Europe/Berlin')
        df['year'] = df['local_time'].dt.year
        df['month'] = df['local_time'].dt.month
        
        # V√©rifier qu'on a au moins quelques mois de donn√©es
        available_years = sorted(df['year'].unique())
        if len(available_years) == 0:
            await message.reply(f"Pas encore de donn√©es d'ensoleillement calcul√©es pour {VILLE}.")
            return

        # Calculer l'ensoleillement mensuel pour chaque ann√©e
        monthly_sunshine_data = []
        
        for year in available_years:
            year_data = df[df['year'] == year].copy()
            if not year_data.empty:
                # Grouper par mois et calculer l'ensoleillement pour chaque mois
                for month in range(1, 13):
                    month_data = year_data[year_data['month'] == month]
                    if not month_data.empty and len(month_data) >= 24:  # Au moins une journ√©e de donn√©es
                        sunshine_hours = calculate_sunshine_hours(month_data)
                        monthly_sunshine_data.append({
                            'year': year,
                            'month': month,
                            'sunshine_hours': sunshine_hours
                        })

        if not monthly_sunshine_data:
            await message.reply("Pas assez de donn√©es pour calculer l'ensoleillement mensuel.")
            return

        sunshine_df = pd.DataFrame(monthly_sunshine_data)
        
        # Pr√©parer les donn√©es pour le graphique en barres group√©es
        pivot_data = sunshine_df.pivot(index='month', columns='year', values='sunshine_hours')
        
        # Cr√©er le graphique moderne en barres group√©es
        fig, ax = plt.subplots(1, 1, figsize=(16, 10))
        fig.patch.set_facecolor('#f8f9fa')
        
        # Palette de couleurs moderne pour l'ensoleillement
        sunshine_colors = ['#f39c12', '#e67e22', '#d35400', '#f1c40f', '#f4d03f',
                          '#3498db', '#2980b9', '#9b59b6', '#8e44ad', '#2ecc71']
        
        # Noms des mois
        month_names = ['Jan', 'F√©v', 'Mar', 'Avr', 'Mai', 'Jun',
                      'Jul', 'Ao√ª', 'Sep', 'Oct', 'Nov', 'D√©c']
        
        # Cr√©er les barres group√©es
        x = np.arange(len(month_names))  # positions des mois
        n_years = len(available_years)
        width = 0.8 / n_years  # largeur de chaque barre
        
        current_year = pd.Timestamp.now(tz='Europe/Berlin').year
        
        # Tracer les barres pour chaque ann√©e
        for i, year in enumerate(available_years):
            if year in pivot_data.columns:
                values = []
                for month in range(1, 13):
                    if month in pivot_data.index and pd.notna(pivot_data.loc[month, year]):
                        values.append(pivot_data.loc[month, year])
                    else:
                        values.append(0)  # 0 pour les mois sans donn√©es
                
                color = sunshine_colors[i % len(sunshine_colors)]
                offset = (i - n_years/2 + 0.5) * width
                
                # Style sp√©cial pour l'ann√©e courante
                if year == current_year:
                    bars = ax.bar(x + offset, values, width,
                                 label=f'‚òÄÔ∏è {year} (actuelle)', color=color,
                                 alpha=0.9, edgecolor='white', linewidth=2,
                                 zorder=5)
                    # Ajouter des valeurs sur les barres de l'ann√©e courante
                    for j, bar in enumerate(bars):
                        if values[j] > 0:
                            ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,
                                   f'{values[j]:.0f}h', ha='center', va='bottom',
                                   fontsize=9, fontweight='bold', color=color)
                else:
                    ax.bar(x + offset, values, width,
                          label=f'üå§Ô∏è {year}', color=color,
                          alpha=0.7, edgecolor='white', linewidth=1,
                          zorder=3)
        
        # Mise en √©vidence du mois actuel
        current_month = pd.Timestamp.now(tz='Europe/Berlin').month
        ax.axvspan(current_month - 1 - 0.4, current_month - 1 + 0.4,
                  alpha=0.2, color='#f39c12', zorder=1,
                  label=f"üìç Mois actuel ({month_names[current_month-1]})")
        
        # Titre moderne avec emojis
        ax.set_title(f'‚òÄÔ∏è Ensoleillement mensuel par ann√©e - {VILLE}\n'
                    f'üìä Comparaison de {len(available_years)} ann√©es de donn√©es',
                    fontsize=18, fontweight='bold', color='#2c3e50', pad=25)
        
        # Labels modernes avec emojis
        ax.set_xlabel('üìÖ Mois', fontsize=14, color='#2c3e50', fontweight='bold')
        ax.set_ylabel('‚òÄÔ∏è Heures d\'ensoleillement', fontsize=14, color='#2c3e50', fontweight='bold')
        
        # Configurer l'axe X avec les noms des mois
        ax.set_xticks(x)
        ax.set_xticklabels(month_names)
        
        # Style moderne des axes
        ax.spines['top'].set_visible(False)
        ax.spines['right'].set_visible(False)
        ax.spines['left'].set_color('#bdc3c7')
        ax.spines['bottom'].set_color('#bdc3c7')
        ax.tick_params(colors='#34495e', labelsize=11)
        
        # L√©gende moderne
        legend = ax.legend(bbox_to_anchor=(1.02, 1), loc='upper left',
                          frameon=True, shadow=True, fancybox=True,
                          framealpha=0.95, edgecolor='#bdc3c7')
        legend.get_frame().set_facecolor('#ffffff')
        
        # Zones saisonni√®res en arri√®re-plan
        ax.axvspan(-0.5, 1.5, alpha=0.05, color='#74b9ff')    # Hiver
        ax.axvspan(1.5, 4.5, alpha=0.05, color='#55a3ff')     # Printemps
        ax.axvspan(4.5, 7.5, alpha=0.05, color='#fdcb6e')     # √ât√©
        ax.axvspan(7.5, 10.5, alpha=0.05, color='#e17055')    # Automne
        ax.axvspan(10.5, 11.5, alpha=0.05, color='#74b9ff')   # Hiver
        
        # Grille moderne
        ax.grid(True, alpha=0.3, linestyle=':', linewidth=1, axis='y')
        
        plt.tight_layout()
        
        # Statistiques pour la l√©gende
        stats_text = ""
        if len(available_years) > 1:
            # Calculer la moyenne par mois sur toutes les ann√©es
            monthly_averages = sunshine_df.groupby('month')['sunshine_hours'].mean()
            best_month = monthly_averages.idxmax()
            worst_month = monthly_averages.idxmin()
            
            stats_text += f"üìä Statistiques globales:\n"
            stats_text += f"‚òÄÔ∏è Meilleur mois: {month_names[best_month-1]} ({monthly_averages[best_month]:.1f}h)\n"
            stats_text += f"‚òÅÔ∏è Moins ensoleill√©: {month_names[worst_month-1]} ({monthly_averages[worst_month]:.1f}h)\n"
            
            # Donn√©es pour le mois actuel
            current_month_data = sunshine_df[sunshine_df['month'] == current_month]
            if not current_month_data.empty:
                current_month_avg = current_month_data['sunshine_hours'].mean()
                stats_text += f"üìç Mois actuel (moy.): {current_month_avg:.1f}h"
        
        caption = (f"‚òÄÔ∏è Ensoleillement mensuel en barres - {len(available_years)} ann√©es\n"
                  f"üìÖ Ann√©es: {min(available_years)}-{max(available_years)}\n"
                  f"{stats_text}")
        
        await send_graph(message.chat.id, fig, caption)
        
    except pd.errors.EmptyDataError:
        await message.reply("Le fichier de donn√©es est vide, impossible de calculer l'ensoleillement.")
    except FileNotFoundError:
        await message.reply("Fichier de donn√©es non trouv√© pour calculer l'ensoleillement.")
    except Exception as e:
        await log_message(f"Error in get_sunshine_summary_command: {str(e)}\n{traceback.format_exc()}")
        await message.reply("Erreur lors de l'obtention du r√©sum√© de l'ensoleillement.")


@router.message(Command("month"))
async def get_month_summary_command(message: types.Message): # Renomm√©
    await send_month_summary(message.chat.id)

@router.message(Command("year"))
async def get_year_summary_command(message: types.Message): # Renomm√©
    await send_year_summary(message.chat.id)

@router.message(Command("all"))
async def get_all_summary_command(message: types.Message): # Renomm√©
    await send_all_summary(message.chat.id)

@router.message(Command("daterange"))
async def get_daterange_summary_command(message: types.Message):
    """G√©n√®re un r√©sum√© entre deux dates. Usage: /daterange 2024-01-01 2024-12-31"""
    try:
        # Parser les arguments
        args = message.text.split()
        if len(args) != 3:
            await message.reply(
                "Usage: /daterange YYYY-MM-DD YYYY-MM-DD\n"
                "Exemple: /daterange 2024-01-01 2024-12-31"
            )
            return
        
        start_date = parse_date_input(args[1])
        end_date = parse_date_input(args[2])
        
        if not start_date or not end_date:
            await message.reply(
                "Format de date invalide. Utilisez YYYY-MM-DD\n"
                "Exemple: /daterange 2024-01-01 2024-12-31"
            )
            return
        
        if start_date > end_date:
            await message.reply("La date de d√©but doit √™tre ant√©rieure √† la date de fin.")
            return
        
        # Lire et filtrer les donn√©es
        if not os.path.exists(csv_filename) or os.path.getsize(csv_filename) == 0:
            await message.reply("Aucune donn√©e m√©t√©o disponible.")
            return
        
        df = pd.read_csv(csv_filename)
        if df.empty:
            await message.reply("Aucune donn√©e disponible dans le fichier.")
            return
        
        df['time'] = pd.to_datetime(df['time'], utc=True, errors='coerce')
        df.dropna(subset=['time'], inplace=True)
        
        # Filtrer selon la p√©riode
        df_period = df[(df['time'] >= start_date) & (df['time'] <= end_date)].copy()
        
        if df_period.empty:
            period_str = f"{start_date.strftime('%Y-%m-%d')} √† {end_date.strftime('%Y-%m-%d')}"
            await message.reply(f"No data available for the selected period ({period_str}).")
            return
        
        # G√©n√©rer le r√©sum√©
        summary = generate_summary(df_period)
        period_str = f"du {start_date.strftime('%d/%m/%Y')} au {end_date.strftime('%d/%m/%Y')}"
        
        message_text = f"üìÖ R√©sum√© m√©t√©o {period_str} pour {VILLE}:\n\n{summary}"
        await message.reply(message_text)
        await log_message(f"R√©sum√© p√©riode {period_str} envoy√© √† chat_id: {message.chat.id}")
        
    except Exception as e:
        await log_message(f"Erreur dans daterange_command: {str(e)}\n{traceback.format_exc()}")
        await message.reply("Erreur lors de la g√©n√©ration du r√©sum√© pour cette p√©riode.")

@router.message(Command("top10"))
async def get_top10_command(message: types.Message):
    """Affiche le top 10 des valeurs pour une m√©trique. Usage: /top10 temperature"""
    try:
        # Parser les arguments
        args = message.text.split()
        if len(args) != 2:
            metrics_list = "temperature, rain, wind, pressure, uv, humidity"
            await message.reply(
                f"Usage: /top10 <m√©trique>\n"
                f"M√©triques disponibles: {metrics_list}\n"
                f"Exemple: /top10 temperature"
            )
            return
        
        metric_arg = args[1].lower()
        
        # Mapping des arguments vers les colonnes CSV
        metric_mapping = {
            'temperature': 'temperature_2m',
            'temp': 'temperature_2m',
            'rain': 'precipitation',
            'precipitation': 'precipitation',
            'wind': 'windspeed_10m',
            'pressure': 'pressure_msl',
            'uv': 'uv_index',
            'humidity': 'relativehumidity_2m'
        }
        
        if metric_arg not in metric_mapping:
            await message.reply(
                f"M√©trique '{metric_arg}' non reconnue.\n"
                f"Utilisez: temperature, rain, wind, pressure, uv, humidity"
            )
            return
        
        column_name = metric_mapping[metric_arg]
        metric_info = get_metric_info(column_name)
        
        # Lire les donn√©es
        if not os.path.exists(csv_filename) or os.path.getsize(csv_filename) == 0:
            await message.reply("Aucune donn√©e m√©t√©o disponible.")
            return
        
        df = pd.read_csv(csv_filename)
        if df.empty:
            await message.reply("Aucune donn√©e disponible.")
            return
        
        df['time'] = pd.to_datetime(df['time'], utc=True, errors='coerce')
        df.dropna(subset=['time'], inplace=True)
        
        if column_name not in df.columns:
            await message.reply(f"Donn√©es pour {metric_info['name']} non disponibles.")
            return
        
        # Nettoyer les donn√©es et enlever les NaN
        df_clean = df.dropna(subset=[column_name]).copy()
        if df_clean.empty:
            await message.reply(f"Aucune donn√©e valide pour {metric_info['name']}.")
            return
        
        # Top 10 des valeurs maximales
        top_max = df_clean.nlargest(10, column_name)
        # Top 10 des valeurs minimales (pour temp√©rature principalement)
        top_min = df_clean.nsmallest(10, column_name) if metric_arg in ['temperature', 'temp'] else None
        
        # Construire le message
        response = f"{metric_info['emoji']} **Top 10 - {metric_info['name']}** √† {VILLE}\n\n"
        
        # Top maximales
        response += f"üî• **Valeurs les plus √©lev√©es:**\n"
        for i, (_, row) in enumerate(top_max.iterrows(), 1):
            time_local = row['time'].tz_convert('Europe/Berlin')
            date_str = time_local.strftime('%d/%m/%Y √† %H:%M')
            value = row[column_name]
            response += f"{i:2d}. {value:.1f}{metric_info['unit']} - {date_str}\n"
        
        # Top minimales (seulement pour temp√©rature)
        if top_min is not None:
            response += f"\n‚ùÑÔ∏è **Valeurs les plus basses:**\n"
            for i, (_, row) in enumerate(top_min.iterrows(), 1):
                time_local = row['time'].tz_convert('Europe/Berlin')
                date_str = time_local.strftime('%d/%m/%Y √† %H:%M')
                value = row[column_name]
                response += f"{i:2d}. {value:.1f}{metric_info['unit']} - {date_str}\n"
        
        await message.reply(response)
        await log_message(f"Top 10 {metric_info['name']} envoy√© √† chat_id: {message.chat.id}")
        
    except Exception as e:
        await log_message(f"Erreur dans top10_command: {str(e)}\n{traceback.format_exc()}")
        await message.reply("Erreur lors de la g√©n√©ration du top 10.")

@router.message(Command("forecastgraph"))
async def get_forecast_graph_command(message: types.Message):
    """G√©n√®re un graphique des pr√©visions m√©t√©o pour les prochaines 24h."""
    try:
        # Utiliser le cache au lieu d'appeler directement l'API
        _, df_next_twenty_four_hours = await get_cached_forecast_data()
        
        if df_next_twenty_four_hours.empty:
            await message.reply("Aucune donn√©e de pr√©vision disponible pour le moment.")
            return
        
        # Limiter aux 24 prochaines heures
        forecast_df = df_next_twenty_four_hours.head(24).copy()
        
        if forecast_df.empty:
            await message.reply("Donn√©es de pr√©vision insuffisantes.")
            return
        
        # Convertir en heure locale pour l'affichage
        forecast_df['local_time'] = forecast_df['time'].dt.tz_convert('Europe/Berlin')
        
        # Cr√©er le graphique avec style moderne
        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10))
        fig.suptitle(f'üå§Ô∏è Pr√©visions m√©t√©o pour {VILLE} - Prochaines 24h',
                    fontsize=18, fontweight='bold', y=0.95, color='#2c3e50')
        
        # Graphique temp√©rature avec gradient
        temps = forecast_df['local_time']
        temperatures = forecast_df['temperature_2m']
        
        # Ligne principale temp√©rature avec gradient de couleur
        points = ax1.scatter(temps, temperatures, c=temperatures, cmap='RdYlBu_r',
                           s=60, alpha=0.8, edgecolors='white', linewidth=1.5, zorder=5)
        ax1.plot(temps, temperatures, linewidth=3, alpha=0.7, color='#34495e', zorder=4)
        
        # Zone de fond gradient selon temp√©rature
        for i in range(len(forecast_df)-1):
            temp = forecast_df.iloc[i]['temperature_2m']
            if temp > 25:
                color = '#ff6b6b'  # Rouge moderne
                alpha = 0.15
            elif temp < 5:
                color = '#74b9ff'  # Bleu moderne
                alpha = 0.15
            else:
                color = '#55a3ff'  # Vert moderne
                alpha = 0.08
            ax1.axvspan(temps.iloc[i], temps.iloc[i+1], color=color, alpha=alpha)
        
        ax1.set_ylabel('üå°Ô∏è Temp√©rature (¬∞C)', fontsize=12, color='#2c3e50')
        ax1.tick_params(colors='#34495e')
        
        # Colorbar pour la temp√©rature
        cbar = plt.colorbar(points, ax=ax1, pad=0.02, aspect=30)
        cbar.set_label('¬∞C', rotation=0, labelpad=15, color='#2c3e50')
        
        # Graphique pr√©cipitations moderne avec gradient MeteoSuisse
        def get_precipitation_color(precip_mm):
            """Couleurs gradu√©es selon l'intensit√© des pr√©cipitations (style MeteoSuisse)."""
            if precip_mm < 0.1:
                return '#f8f9fa'      # Blanc/transparent (pas de pluie)
            elif precip_mm < 1.0:
                return '#cce7ff'      # Bleu tr√®s clair (bruine)
            elif precip_mm < 2.5:
                return '#74b9ff'      # Bleu clair (faible)
            elif precip_mm < 5.0:
                return '#4a90e2'      # Bleu moyen (mod√©r√©)
            elif precip_mm < 10.0:
                return '#2563eb'      # Bleu fonc√© (fort)
            elif precip_mm < 25.0:
                return '#7c3aed'      # Violet (tr√®s fort)
            elif precip_mm < 50.0:
                return '#dc2626'      # Rouge (intense)
            else:
                return '#991b1b'      # Rouge fonc√© (extr√™me)
        
        colors_precip = [get_precipitation_color(p) for p in forecast_df['precipitation']]
        bars = ax2.bar(temps, forecast_df['precipitation'], width=0.03,
                      color=colors_precip, alpha=0.9, edgecolor='white', linewidth=0.5)
        
        # Ajouter l√©gende des couleurs pr√©cipitations (style MeteoSuisse)
        max_precip = forecast_df['precipitation'].max()
        if max_precip > 0.1:  # Seulement si il y a des pr√©cipitations
            legend_text = "Pr√©cipitations: "
            if max_precip >= 25.0:
                legend_text += "üî¥ Extr√™me"
            elif max_precip >= 10.0:
                legend_text += "üü£ Tr√®s fort"
            elif max_precip >= 5.0:
                legend_text += "üîµ Fort"
            elif max_precip >= 2.5:
                legend_text += "üü¶ Mod√©r√©"
            elif max_precip >= 1.0:
                legend_text += "üíô Faible"
            else:
                legend_text += "üíß Bruine"
            
            ax2.text(0.02, 0.95, legend_text, transform=ax2.transAxes,
                    fontsize=10, verticalalignment='top',
                    bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))
        
        # Ligne probabilit√© avec style moderne
        ax2_twin = ax2.twinx()
        ax2_twin.plot(temps, forecast_df['precipitation_probability'],
                     color='#00b894', linewidth=3, marker='o', markersize=4,
                     alpha=0.9, label='Probabilit√© pluie', markerfacecolor='white',
                     markeredgecolor='#00b894', markeredgewidth=2)
        
        ax2.set_ylabel('üíß Pr√©cipitations (mm)', color='#2c3e50')
        ax2_twin.set_ylabel('‚òî Probabilit√© (%)', color='#00b894')
        ax2.set_xlabel('üïê Heure locale', color='#2c3e50')
        
        # Style des axes
        for ax in [ax1, ax2, ax2_twin]:
            ax.tick_params(colors='#34495e')
            ax.spines['top'].set_visible(False)
            ax.spines['right'].set_visible(False) if ax != ax2_twin else None
            ax.spines['left'].set_color('#bdc3c7')
            ax.spines['bottom'].set_color('#bdc3c7')
        
        # Formatage des axes temporels
        for ax in [ax1, ax2]:
            ax.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))
            ax.xaxis.set_major_locator(mdates.HourLocator(interval=3))
            plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)
        
        # L√©gendes
        lines1, labels1 = ax2.get_legend_handles_labels()
        lines2, labels2 = ax2_twin.get_legend_handles_labels()
        ax2.legend(lines1 + lines2, labels1 + labels2, loc='upper left')
        
        plt.tight_layout()
        
        # Ajouter des informations textuelles
        temp_moy = forecast_df['temperature_2m'].mean()
        precip_total = forecast_df['precipitation'].sum()
        
        caption = (f"üîÆ Pr√©visions 24h pour {VILLE}\n"
                  f"üå°Ô∏è Temp√©rature moyenne: {temp_moy:.1f}¬∞C\n"
                  f"üåßÔ∏è Pr√©cipitations totales pr√©vues: {precip_total:.1f}mm")
        
        await send_graph(message.chat.id, fig, caption)
        
    except Exception as e:
        await log_message(f"Erreur dans forecastgraph_command: {str(e)}\n{traceback.format_exc()}")
        await message.reply("Erreur lors de la g√©n√©ration du graphique de pr√©visions.")

@router.message(Command("graph"))
async def get_graph_data_command(message: types.Message):
    """G√©n√®re 2 graphiques pour une m√©trique sp√©cifique (courbe + barres). Usage: /graph temperature"""
    try:
        # Parser les arguments
        args = message.text.split()
        if len(args) not in [2, 3]:
            await message.reply(
                "Usage: /graph <m√©trique> [jours]\n"
                "M√©triques: temperature, rain, wind, pressure, uv, humidity\n"
                "Exemple: /graph temperature 30"
            )
            return
        
        metric_arg = args[1].lower()
        days = int(args[2]) if len(args) == 3 else 30
        
        if days <= 0 or days > 365:
            await message.reply("Le nombre de jours doit √™tre entre 1 et 365.")
            return
        
        # Mapping des arguments
        metric_mapping = {
            'temperature': 'temperature_2m',
            'temp': 'temperature_2m',
            'rain': 'precipitation',
            'precipitation': 'precipitation',
            'wind': 'windspeed_10m',
            'pressure': 'pressure_msl',
            'uv': 'uv_index',
            'humidity': 'relativehumidity_2m'
        }
        
        if metric_arg not in metric_mapping:
            await message.reply(
                f"M√©trique '{metric_arg}' non reconnue.\n"
                f"Utilisez: temperature, rain, wind, pressure, uv, humidity"
            )
            return
        
        column_name = metric_mapping[metric_arg]
        metric_info = get_metric_info(column_name)
        
        # Lire et filtrer les donn√©es
        if not os.path.exists(csv_filename) or os.path.getsize(csv_filename) == 0:
            await message.reply("Aucune donn√©e m√©t√©o disponible.")
            return
        
        df = pd.read_csv(csv_filename)
        if df.empty:
            await message.reply("Aucune donn√©e disponible.")
            return
        
        df['time'] = pd.to_datetime(df['time'], utc=True, errors='coerce')
        df.dropna(subset=['time'], inplace=True)
        
        if column_name not in df.columns:
            await message.reply(f"Donn√©es pour {metric_info['name']} non disponibles.")
            return
        
        # Filtrer les derniers N jours
        now = pd.Timestamp.now(tz='UTC')
        start_date = now - pd.Timedelta(days=days)
        df_period = df[(df['time'] >= start_date) & (df['time'] <= now)].copy()
        
        if df_period.empty:
            await message.reply(f"Aucune donn√©e disponible pour les {days} derniers jours.")
            return
        
        # Nettoyer les donn√©es
        df_period = df_period.dropna(subset=[column_name])
        if df_period.empty:
            await message.reply(f"Aucune donn√©e valide pour {metric_info['name']} sur cette p√©riode.")
            return
        
        # Convertir en heure locale
        df_period['local_time'] = df_period['time'].dt.tz_convert('Europe/Berlin')
        
        # Couleurs modernes selon la m√©trique
        colors = {
            'temperature_2m': '#e74c3c',      # Rouge moderne
            'precipitation': '#3498db',       # Bleu moderne
            'windspeed_10m': '#2ecc71',      # Vert moderne
            'pressure_msl': '#9b59b6',       # Violet moderne
            'uv_index': '#f39c12',           # Orange moderne
            'relativehumidity_2m': '#1abc9c' # Turquoise moderne
        }
        
        color = colors.get(column_name, '#34495e')
        
        # Statistiques communes
        data_values = df_period[column_name]
        mean_val = data_values.mean()
        max_val = data_values.max()
        min_val = data_values.min()
        
        base_caption = (f"{metric_info['emoji']} {metric_info['name']} - {days} derniers jours\n"
                       f"üìä Moyenne: {mean_val:.1f}{metric_info['unit']}\n"
                       f"üìà Maximum: {max_val:.1f}{metric_info['unit']}\n"
                       f"üìâ Minimum: {min_val:.1f}{metric_info['unit']}")
        
        # === GRAPHIQUE 1: COURBE (style actuel) ===
        fig1, ax1 = plt.subplots(1, 1, figsize=(14, 8))
        
        if metric_arg in ['rain', 'precipitation']:
            # Graphique en barres pour les pr√©cipitations avec gradient MeteoSuisse
            def get_precipitation_color(precip_mm):
                """Couleurs gradu√©es selon l'intensit√© des pr√©cipitations (style MeteoSuisse)."""
                if precip_mm < 0.1:
                    return '#f8f9fa'      # Blanc/transparent (pas de pluie)
                elif precip_mm < 1.0:
                    return '#cce7ff'      # Bleu tr√®s clair (bruine)
                elif precip_mm < 2.5:
                    return '#74b9ff'      # Bleu clair (faible)
                elif precip_mm < 5.0:
                    return '#4a90e2'      # Bleu moyen (mod√©r√©)
                elif precip_mm < 10.0:
                    return '#2563eb'      # Bleu fonc√© (fort)
                elif precip_mm < 25.0:
                    return '#7c3aed'      # Violet (tr√®s fort)
                elif precip_mm < 50.0:
                    return '#dc2626'      # Rouge (intense)
                else:
                    return '#991b1b'      # Rouge fonc√© (extr√™me)
            
            colors_precip = [get_precipitation_color(p) for p in df_period[column_name]]
            bars = ax1.bar(df_period['local_time'], df_period[column_name],
                          width=0.02, color=colors_precip, alpha=0.9, edgecolor='white', linewidth=0.5)
            
            # Ajouter l√©gende des couleurs si pr√©cipitations significatives
            max_precip = df_period[column_name].max()
            if max_precip > 0.1:
                legend_text = "Intensit√© max: "
                if max_precip >= 25.0:
                    legend_text += "üî¥ Extr√™me"
                elif max_precip >= 10.0:
                    legend_text += "üü£ Tr√®s fort"
                elif max_precip >= 5.0:
                    legend_text += "üîµ Fort"
                elif max_precip >= 2.5:
                    legend_text += "üü¶ Mod√©r√©"
                elif max_precip >= 1.0:
                    legend_text += "üíô Faible"
                else:
                    legend_text += "üíß Bruine"
                
                ax1.text(0.02, 0.95, legend_text, transform=ax1.transAxes,
                        fontsize=10, verticalalignment='top',
                        bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))
        else:
            # Graphique en ligne moderne avec zone remplie
            ax1.fill_between(df_period['local_time'], df_period[column_name],
                            alpha=0.3, color=color, interpolate=True)
            ax1.plot(df_period['local_time'], df_period[column_name],
                    color=color, linewidth=3, alpha=0.9, marker='o',
                    markersize=2, markerfacecolor='white', markeredgecolor=color)
            
            # Moyenne mobile avec style moderne
            if len(df_period) > 24:
                df_period['moving_avg'] = df_period[column_name].rolling(window=24, center=True).mean()
                ax1.plot(df_period['local_time'], df_period['moving_avg'],
                        color='#2c3e50', linewidth=3, alpha=0.8,
                        linestyle='--', label='üìà Moyenne mobile 24h')
                ax1.legend(loc='upper right', frameon=True, shadow=True,
                          fancybox=True, framealpha=0.9)
        
        # Titre et style pour graphique 1
        ax1.set_title(f'üìä {metric_info["emoji"]} {metric_info["name"]} (courbe) - {days} derniers jours √† {VILLE}',
                     fontsize=16, fontweight='bold', color='#2c3e50', pad=20)
        ax1.set_ylabel(f'{metric_info["emoji"]} {metric_info["name"]} ({metric_info["unit"]})',
                      fontsize=12, color='#2c3e50')
        ax1.set_xlabel('üìÖ Date', fontsize=12, color='#2c3e50')
        
        # Style moderne des axes
        ax1.spines['top'].set_visible(False)
        ax1.spines['right'].set_visible(False)
        ax1.spines['left'].set_color('#bdc3c7')
        ax1.spines['bottom'].set_color('#bdc3c7')
        ax1.tick_params(colors='#34495e')
        
        # Formatage temporal et grille
        if days <= 7:
            ax1.xaxis.set_major_formatter(mdates.DateFormatter('%d/%m\n%H:%M'))
            ax1.xaxis.set_major_locator(mdates.HourLocator(interval=12))
        elif days <= 30:
            ax1.xaxis.set_major_formatter(mdates.DateFormatter('%d/%m'))
            ax1.xaxis.set_major_locator(mdates.DayLocator(interval=3))
        else:
            ax1.xaxis.set_major_formatter(mdates.DateFormatter('%d/%m'))
            ax1.xaxis.set_major_locator(mdates.WeekdayLocator(interval=1))
        
        plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45, fontsize=10)
        ax1.grid(True, alpha=0.3, linestyle=':', linewidth=0.5)
        plt.tight_layout()
        
        # Envoyer le premier graphique (courbe)
        caption1 = f"üìä Graphique en courbe\n{base_caption}"
        await send_graph(message.chat.id, fig1, caption1)
        
        # === GRAPHIQUE 2: BARRES VERTICALES (style sunshine - par mois/ann√©e) ===
        fig2, ax2 = plt.subplots(1, 1, figsize=(16, 10))
        fig2.patch.set_facecolor('#f8f9fa')
        
        # Pr√©parer donn√©es mensuelles group√©es par ann√©e (style sunshine)
        df_bars = df_period.copy()
        df_bars['year'] = df_bars['local_time'].dt.year
        df_bars['month'] = df_bars['local_time'].dt.month
        
        # Calculer valeurs mensuelles selon le type de m√©trique
        if metric_arg in ['rain', 'precipitation']:
            monthly_data = df_bars.groupby(['year', 'month'])[column_name].sum().reset_index()
        else:
            monthly_data = df_bars.groupby(['year', 'month'])[column_name].mean().reset_index()
        
        if monthly_data.empty:
            # Fallback vers donn√©es journali√®res si pas assez pour mensuel
            df_bars['date'] = df_bars['local_time'].dt.date
            if metric_arg in ['rain', 'precipitation']:
                daily_data = df_bars.groupby('date')[column_name].sum().reset_index()
            else:
                daily_data = df_bars.groupby('date')[column_name].mean().reset_index()
            
            daily_data['datetime'] = pd.to_datetime(daily_data['date'])
            bars = ax2.bar(daily_data['datetime'], daily_data[column_name],
                          width=0.8, color=color, alpha=0.8, edgecolor='white', linewidth=1)
            
            ax2.set_title(f'üìä {metric_info["emoji"]} {metric_info["name"]} (barres journali√®res) - {days} derniers jours √† {VILLE}',
                         fontsize=16, fontweight='bold', color='#2c3e50', pad=20)
            ax2.xaxis.set_major_formatter(mdates.DateFormatter('%d/%m'))
            ax2.xaxis.set_major_locator(mdates.DayLocator(interval=max(1, days//15)))
        else:
            # Style sunshine : barres group√©es par ann√©e pour chaque mois
            available_years = sorted(monthly_data['year'].unique())
            available_months = sorted(monthly_data['month'].unique())
            
            # Noms des mois
            month_names = ['Jan', 'F√©v', 'Mar', 'Avr', 'Mai', 'Jun',
                          'Jul', 'Ao√ª', 'Sep', 'Oct', 'Nov', 'D√©c']
            
            # Couleurs pour les ann√©es
            year_colors = ['#e74c3c', '#3498db', '#2ecc71', '#f39c12', '#9b59b6']
            
            # Cr√©er les barres group√©es
            x_positions = np.arange(len(available_months))
            n_years = len(available_years)
            width = 0.8 / n_years
            
            for i, year in enumerate(available_years):
                year_data = monthly_data[monthly_data['year'] == year]
                values = []
                
                for month in available_months:
                    month_row = year_data[year_data['month'] == month]
                    if not month_row.empty:
                        values.append(month_row[column_name].iloc[0])
                    else:
                        values.append(0)
                
                year_color = year_colors[i % len(year_colors)]
                offset = (i - n_years/2 + 0.5) * width
                
                bars = ax2.bar(x_positions + offset, values, width,
                              label=f'üìÖ {year}', color=year_color,
                              alpha=0.8, edgecolor='white', linewidth=1)
                
                # Ajouter valeurs sur les barres
                for j, bar in enumerate(bars):
                    height = bar.get_height()
                    if height > 0:
                        ax2.text(bar.get_x() + bar.get_width()/2, height + max(values)*0.01,
                               f'{height:.0f}', ha='center', va='bottom',
                               fontsize=8, fontweight='bold', color=year_color)
            
            # Configuration des axes pour style mensuel
            ax2.set_xticks(x_positions)
            ax2.set_xticklabels([month_names[m-1] for m in available_months])
            ax2.set_title(f'üìä {metric_info["emoji"]} {metric_info["name"]} (barres mensuelles) - {len(available_years)} ann√©es √† {VILLE}',
                         fontsize=16, fontweight='bold', color='#2c3e50', pad=20)
            
            # L√©gende moderne
            legend = ax2.legend(bbox_to_anchor=(1.02, 1), loc='upper left',
                               frameon=True, shadow=True, fancybox=True,
                               framealpha=0.95, edgecolor='#bdc3c7')
            legend.get_frame().set_facecolor('#ffffff')
        
        # Style commun des axes
        ax2.set_ylabel(f'{metric_info["emoji"]} {metric_info["name"]} ({metric_info["unit"]})',
                      fontsize=14, color='#2c3e50', fontweight='bold')
        ax2.set_xlabel('üìÖ P√©riode', fontsize=14, color='#2c3e50', fontweight='bold')
        
        ax2.spines['top'].set_visible(False)
        ax2.spines['right'].set_visible(False)
        ax2.spines['left'].set_color('#bdc3c7')
        ax2.spines['bottom'].set_color('#bdc3c7')
        ax2.tick_params(colors='#34495e', labelsize=11)
        
        plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45, fontsize=10)
        ax2.grid(True, alpha=0.3, linestyle=':', linewidth=1, axis='y')
        plt.tight_layout()
        
        # Envoyer le deuxi√®me graphique (barres)
        caption2 = f"üìä Graphique en barres\n{base_caption}"
        await send_graph(message.chat.id, fig2, caption2)
        
    except ValueError as e:
        await message.reply("Le nombre de jours doit √™tre un nombre entier valide.")
    except Exception as e:
        await log_message(f"Erreur dans graphdata_command: {str(e)}\n{traceback.format_exc()}")
        await message.reply("Erreur lors de la g√©n√©ration des graphiques.")

@router.message(Command("heatmap"))
async def get_heatmap_command(message: types.Message):
    """G√©n√®re une heatmap calendaire des temp√©ratures. Usage: /heatmap [ann√©e]"""
    try:
        # Parser les arguments
        args = message.text.split()
        current_year = pd.Timestamp.now(tz='UTC').year
        
        # Gestion du param√®tre "all"
        if len(args) == 2 and args[1].lower() == 'all':
            target_year = 'all'
        elif len(args) == 2:
            try:
                target_year = int(args[1])
                if target_year < 2020 or target_year > current_year + 1:
                    await message.reply(f"Ann√©e invalide. Utilisez une ann√©e entre 2020 et {current_year}, ou 'all' pour toutes les ann√©es.")
                    return
            except ValueError:
                await message.reply(f"Format invalide. Utilisez: /heatmap [ann√©e] ou /heatmap all")
                return
        else:
            target_year = current_year
        
        # Lire les donn√©es
        if not os.path.exists(csv_filename) or os.path.getsize(csv_filename) == 0:
            await message.reply("Aucune donn√©e m√©t√©o disponible.")
            return
        
        df = pd.read_csv(csv_filename)
        if df.empty:
            await message.reply("Aucune donn√©e disponible.")
            return
        
        df['time'] = pd.to_datetime(df['time'], utc=True, errors='coerce')
        df.dropna(subset=['time'], inplace=True)
        
        if 'temperature_2m' not in df.columns:
            await message.reply("Donn√©es de temp√©rature non disponibles.")
            return
        
        if target_year == 'all':
            # Mode multi-ann√©es : toutes les ann√©es disponibles
            df['local_time'] = df['time'].dt.tz_convert('Europe/Berlin')
            df['date'] = df['local_time'].dt.date
            df['year'] = df['local_time'].dt.year
            
            available_years = sorted(df['year'].unique())
            if len(available_years) == 0:
                await message.reply("Aucune donn√©e disponible.")
                return
                
            # Calculer moyennes journali√®res par ann√©e
            daily_temps = df.groupby(['year', 'date'])['temperature_2m'].mean().reset_index()
            
            if daily_temps.empty:
                await message.reply("Aucune donn√©e de temp√©rature valide.")
                return
            
            # Cr√©er une heatmap multi-ann√©es (ann√©es x jours de l'ann√©e)
            num_years = len(available_years)
            temp_matrix = np.full((366, num_years), np.nan)  # 366 jours max, n ann√©es
            
            for year_idx, year in enumerate(available_years):
                year_data = daily_temps[daily_temps['year'] == year]
                for _, row in year_data.iterrows():
                    day_of_year = pd.to_datetime(row['date']).timetuple().tm_yday - 1  # 0-index√©
                    if 0 <= day_of_year < 366:
                        temp_matrix[day_of_year, year_idx] = row['temperature_2m']
                        
            # Configuration pour mode multi-ann√©es
            matrix_to_plot = temp_matrix.T  # Transposer pour avoir ann√©es en Y
            xlabel_text = 'üìÖ Jour de l\'ann√©e'
            ylabel_text = 'üìÖ Ann√©e'
            title_text = f'üå°Ô∏è Calendrier thermique multi-ann√©es - {VILLE}\nüìä {len(available_years)} ann√©es de donn√©es'
            
            # Positions et labels pour l'axe X (jours de l'ann√©e)
            month_starts = [1, 32, 60, 91, 121, 152, 182, 213, 244, 274, 305, 335]
            month_names = ['Jan', 'F√©v', 'Mar', 'Avr', 'Mai', 'Jun',
                          'Jul', 'Ao√ª', 'Sep', 'Oct', 'Nov', 'D√©c']
            x_positions = month_starts
            x_labels = month_names
            
            # Positions et labels pour l'axe Y (ann√©es)
            y_positions = range(len(available_years))
            y_labels = [f'üìÖ {year}' for year in available_years]
            
        else:
            # Mode ann√©e unique (code existant)
            df_year = df[df['time'].dt.year == target_year].copy()
            if df_year.empty:
                await message.reply(f"Aucune donn√©e disponible pour l'ann√©e {target_year}.")
                return
            
            # Convertir en heure locale et calculer moyennes journali√®res
            df_year['local_time'] = df_year['time'].dt.tz_convert('Europe/Berlin')
            df_year['date'] = df_year['local_time'].dt.date
            daily_temps = df_year.groupby('date')['temperature_2m'].mean().reset_index()
            
            if daily_temps.empty:
                await message.reply(f"Aucune donn√©e de temp√©rature valide pour {target_year}.")
                return
            
            # Cr√©er une s√©rie compl√®te pour l'ann√©e
            start_date = datetime.date(target_year, 1, 1)
            end_date = datetime.date(target_year, 12, 31)
            all_dates = pd.date_range(start_date, end_date, freq='D').date
            
            # Cr√©er un DataFrame complet avec NaN pour les jours manquants
            full_year = pd.DataFrame({'date': all_dates})
            full_year = full_year.merge(daily_temps, on='date', how='left')
            
            # Pr√©parer les donn√©es pour la heatmap
            full_year['week'] = pd.to_datetime(full_year['date']).dt.isocalendar().week
            full_year['weekday'] = pd.to_datetime(full_year['date']).dt.weekday
            full_year['month'] = pd.to_datetime(full_year['date']).dt.month
            
            # Cr√©er la matrice pour la heatmap (53 semaines x 7 jours)
            temp_matrix = np.full((53, 7), np.nan)
            
            for _, row in full_year.iterrows():
                week = int(row['week']) - 1  # 0-index√©
                weekday = int(row['weekday'])  # 0=lundi, 6=dimanche
                if 0 <= week < 53 and 0 <= weekday < 7:
                    temp_matrix[week, weekday] = row['temperature_2m']
                    
            # Configuration pour mode ann√©e unique
            matrix_to_plot = temp_matrix.T
            xlabel_text = 'üìÖ Mois'
            ylabel_text = 'üìã Jour de la semaine'
            title_text = f'üå°Ô∏è Calendrier thermique {target_year} - {VILLE}'
            
            # Labels des jours avec emojis
            y_positions = range(7)
            y_labels = ['üåÖ Lun', 'üåÖ Mar', 'üåÖ Mer', 'üåÖ Jeu', 'üåÖ Ven', 'üèñÔ∏è Sam', 'üèñÔ∏è Dim']
            
            # Labels des mois avec emojis saisonniers
            month_positions = []
            month_labels = []
            month_emojis = ['‚ùÑÔ∏è', '‚ùÑÔ∏è', 'üå∏', 'üå∏', 'üå∏', '‚òÄÔ∏è', '‚òÄÔ∏è', '‚òÄÔ∏è', 'üçÇ', 'üçÇ', 'üçÇ', '‚ùÑÔ∏è']
            
            for month in range(1, 13):
                first_day_month = datetime.date(target_year, month, 1)
                week_num = first_day_month.isocalendar().week - 1
                if week_num < 53:
                    month_positions.append(week_num)
                    month_name = first_day_month.strftime('%b')
                    month_labels.append(f'{month_emojis[month-1]} {month_name}')
            
            x_positions = month_positions
            x_labels = month_labels
        
        # Cr√©er le graphique moderne style GitHub
        if target_year == 'all':
            fig, ax = plt.subplots(1, 1, figsize=(18, 12))
        else:
            fig, ax = plt.subplots(1, 1, figsize=(16, 10))
        fig.patch.set_facecolor('#f8f9fa')
        
        # Calculer vmin/vmax pour la palette de couleurs
        if target_year == 'all':
            vmin, vmax = np.nanmin(temp_matrix), np.nanmax(temp_matrix)
        else:
            vmin, vmax = full_year['temperature_2m'].min(), full_year['temperature_2m'].max()
        
        # Heatmap moderne avec palette am√©lior√©e
        im = ax.imshow(matrix_to_plot, cmap='RdYlBu_r', aspect='auto',
                      vmin=vmin, vmax=vmax, interpolation='nearest')
        
        # Titre moderne avec style GitHub
        ax.set_title(title_text, fontsize=20, fontweight='bold', pad=30, color='#24292e')
        
        # Configuration des axes selon le mode
        ax.set_yticks(y_positions)
        ax.set_yticklabels(y_labels, fontsize=11, color='#586069')
        ax.set_xticks(x_positions)
        ax.set_xticklabels(x_labels, fontsize=11, color='#586069')
        ax.set_xlabel(xlabel_text, fontsize=14, color='#24292e', fontweight='bold')
        ax.set_ylabel(ylabel_text, fontsize=14, color='#24292e', fontweight='bold')
        
        # Colorbar moderne
        cbar = plt.colorbar(im, ax=ax, shrink=0.8, aspect=25, pad=0.02)
        cbar.set_label('üå°Ô∏è Temp√©rature (¬∞C)', fontsize=12, color='#24292e',
                      rotation=270, labelpad=20)
        cbar.ax.tick_params(labelsize=10, colors='#586069')
        
        # Style moderne des bordures
        for spine in ax.spines.values():
            spine.set_color('#d1d5da')
            spine.set_linewidth(1)
        
        ax.tick_params(colors='#586069', length=0)
        
        # Grille subtile style GitHub (adapt√©e selon le mode)
        if target_year == 'all':
            ax.set_xticks(np.arange(-0.5, 366, 30), minor=True)
            ax.set_yticks(np.arange(-0.5, len(available_years), 1), minor=True)
        else:
            ax.set_xticks(np.arange(-0.5, 53, 1), minor=True)
            ax.set_yticks(np.arange(-0.5, 7, 1), minor=True)
        ax.grid(which='minor', color='#e1e4e8', linestyle='-', linewidth=0.5, alpha=0.8)
        
        plt.tight_layout()
        
        # Statistiques adapt√©es selon le mode
        if target_year == 'all':
            # Statistiques pour mode multi-ann√©es
            valid_temps = df['temperature_2m'].dropna()
            if not valid_temps.empty:
                temp_min = valid_temps.min()
                temp_max = valid_temps.max()
                temp_mean = valid_temps.mean()
                data_points = len(valid_temps)
                
                caption = (f"üå°Ô∏è Calendrier thermique multi-ann√©es - {VILLE}\n"
                          f"üìä {len(available_years)} ann√©es ‚Ä¢ {data_points} points de donn√©es\n"
                          f"üìä Temp√©rature moyenne: {temp_mean:.1f}¬∞C\n"
                          f"üìà Maximum absolu: {temp_max:.1f}¬∞C\n"
                          f"üìâ Minimum absolu: {temp_min:.1f}¬∞C")
            else:
                caption = f"üå°Ô∏è Calendrier thermique multi-ann√©es - {VILLE}\n‚ùå Aucune donn√©e valide"
        else:
            # Statistiques pour mode ann√©e unique
            valid_temps = full_year['temperature_2m'].dropna()
            if not valid_temps.empty:
                temp_min = valid_temps.min()
                temp_max = valid_temps.max()
                temp_mean = valid_temps.mean()
                data_coverage = len(valid_temps) / len(full_year) * 100
                
                caption = (f"üå°Ô∏è Calendrier thermique {target_year} - {VILLE}\n"
                          f"üìä Temp√©rature moyenne: {temp_mean:.1f}¬∞C\n"
                          f"üìà Maximum: {temp_max:.1f}¬∞C\n"
                          f"üìâ Minimum: {temp_min:.1f}¬∞C\n"
                          f"üìÖ Couverture donn√©es: {data_coverage:.1f}%")
            else:
                caption = f"üå°Ô∏è Calendrier thermique {target_year} - {VILLE}\n‚ùå Aucune donn√©e valide"
        
        await send_graph(message.chat.id, fig, caption)
        
    except ValueError as e:
        await message.reply("L'ann√©e doit √™tre un nombre entier valide.")
    except Exception as e:
        await log_message(f"Erreur dans heatmap_command: {str(e)}\n{traceback.format_exc()}")
        await message.reply("Erreur lors de la g√©n√©ration du calendrier thermique.")

@router.message(Command("sunshinelist"))
async def get_sunshine_list_command(message: types.Message):
    """Affiche un r√©sum√© textuel mensuel de l'ensoleillement. Usage: /sunshinelist"""
    try:
        if not os.path.exists(csv_filename) or os.path.getsize(csv_filename) == 0:
            await message.reply("Aucune donn√©e disponible pour calculer l'ensoleillement.")
            return
            
        df = pd.read_csv(csv_filename)
        if df.empty:
            await message.reply("Aucune donn√©e disponible pour calculer l'ensoleillement (fichier vide).")
            return

        df['time'] = pd.to_datetime(df['time'], utc=True, errors='coerce')
        df.dropna(subset=['time'], inplace=True)

        if df.empty:
            await message.reply("Aucune donn√©e temporelle valide pour calculer l'ensoleillement.")
            return

        monthly_sunshine = calculate_monthly_sunshine(df)
        
        if monthly_sunshine.empty:
            await message.reply(f"Pas encore de donn√©es d'ensoleillement calcul√©es pour {VILLE}.")
            return

        # Trier par date (l'index est d√©j√† YYYY-MM, donc tri alphab√©tique fonctionne)
        monthly_sunshine = monthly_sunshine.sort_index()
        
        # D√©tecter le premier mois avec des donn√©es (peut √™tre partiel)
        first_month = monthly_sunshine.index[0] if not monthly_sunshine.empty else None
        current_month_year_str = pd.Timestamp.now(tz='Europe/Berlin').strftime('%Y-%m')
        
        response = f"‚òÄÔ∏è R√©sum√© mensuel de l'ensoleillement estim√© pour {VILLE} :\n"
        response += f"üìÖ D√©but des mesures : {first_month} (donn√©es possiblement partielles)\n\n"
        
        for i, (date_str, hours) in enumerate(monthly_sunshine.items()):
            # Convertir YYYY-MM en nom de mois et ann√©e pour affichage
            try:
                month_display = pd.to_datetime(date_str + "-01").strftime('%B %Y')
            except ValueError:
                month_display = date_str # Fallback si le format est inattendu
            
            is_current = date_str == current_month_year_str
            is_first = i == 0
            
            if is_current:
                month_marker = "üìç "
            elif is_first:
                month_marker = "üöÄ "  # Premier mois
            else:
                month_marker = "üìÖ "
            
            response += f"{month_marker}{month_display}: {hours:.1f} heures\n"
        
        await message.reply(response)
        
    except pd.errors.EmptyDataError:
        await message.reply("Le fichier de donn√©es est vide, impossible de calculer l'ensoleillement.")
    except FileNotFoundError:
        await message.reply("Fichier de donn√©es non trouv√© pour calculer l'ensoleillement.")
    except Exception as e:
        await log_message(f"Error in get_sunshine_compare_command: {str(e)}\n{traceback.format_exc()}")
        await message.reply("Erreur lors de l'obtention du r√©sum√© de l'ensoleillement.")

@router.message(Command("yearcompare"))
async def get_year_compare_command(message: types.Message):
    """Compare les donn√©es m√©t√©o entre diff√©rentes ann√©es. Usage: /yearcompare [m√©trique]"""
    try:
        # Parser les arguments
        args = message.text.split()
        metric_arg = args[1].lower() if len(args) == 2 else 'temperature'
        
        # Mapping des m√©triques
        metric_mapping = {
            'temperature': 'temperature_2m',
            'temp': 'temperature_2m',
            'rain': 'precipitation',
            'precipitation': 'precipitation',
            'wind': 'windspeed_10m',
            'pressure': 'pressure_msl',
            'uv': 'uv_index',
            'humidity': 'relativehumidity_2m'
        }
        
        if metric_arg not in metric_mapping:
            await message.reply(
                f"M√©trique '{metric_arg}' non reconnue.\n"
                f"Utilisez: temperature, rain, wind, pressure, uv, humidity\n"
                f"Exemple: /yearcompare temperature"
            )
            return
        
        column_name = metric_mapping[metric_arg]
        metric_info = get_metric_info(column_name)
        
        # Lire les donn√©es
        if not os.path.exists(csv_filename) or os.path.getsize(csv_filename) == 0:
            await message.reply("Aucune donn√©e m√©t√©o disponible.")
            return
        
        df = pd.read_csv(csv_filename)
        if df.empty:
            await message.reply("Aucune donn√©e disponible.")
            return
        
        df['time'] = pd.to_datetime(df['time'], utc=True, errors='coerce')
        df.dropna(subset=['time'], inplace=True)
        
        if column_name not in df.columns:
            await message.reply(f"Donn√©es pour {metric_info['name']} non disponibles.")
            return
        
        # Convertir en heure locale et extraire date/heure
        df['local_time'] = df['time'].dt.tz_convert('Europe/Berlin')
        df['year'] = df['local_time'].dt.year
        df['month'] = df['local_time'].dt.month
        df['month_day'] = df['local_time'].dt.strftime('%m-%d')
        df['day_of_year'] = df['local_time'].dt.dayofyear
        
        # EXCLUSION d'ao√ªt 2023 (donn√©es incompl√®tes - d√©but des mesures)
        df = df[~((df['year'] == 2023) & (df['month'] == 8))].copy()
        await log_message("Exclusion d'ao√ªt 2023 (donn√©es incompl√®tes) pour /yearcompare")
        
        # V√©rifier qu'on a au moins 2 ann√©es de donn√©es
        available_years = sorted(df['year'].unique())
        if len(available_years) < 2:
            await message.reply("Pas assez d'ann√©es de donn√©es pour faire une comparaison (minimum 2 ann√©es).")
            return
        
        current_year = pd.Timestamp.now(tz='Europe/Berlin').year
        current_day_of_year = pd.Timestamp.now(tz='Europe/Berlin').dayofyear
        
        # Calculer moyennes journali√®res par ann√©e
        daily_means = df.groupby(['year', 'day_of_year'])[column_name].mean().reset_index()
        
        # === GRAPHIQUE 1: COURBE DE COMPARAISON ANNUELLE ===
        fig1, ax1 = plt.subplots(1, 1, figsize=(16, 10))
        fig1.patch.set_facecolor('#f8f9fa')
        
        # Palette de couleurs moderne et distincte
        modern_colors = ['#e74c3c', '#3498db', '#2ecc71', '#f39c12', '#9b59b6',
                        '#1abc9c', '#34495e', '#e67e22', '#95a5a6', '#16a085']
        
        # Tracer chaque ann√©e avec style moderne
        for i, year in enumerate(available_years):
            year_data = daily_means[daily_means['year'] == year]
            
            if not year_data.empty:
                color = modern_colors[i % len(modern_colors)]
                
                # Style sp√©cial pour l'ann√©e courante
                if year == current_year:
                    ax1.plot(year_data['day_of_year'], year_data[column_name],
                           color=color, linewidth=4, label=f'üìç {year} (actuelle)',
                           alpha=0.95, zorder=5, marker='o', markersize=3,
                           markevery=30)
                else:
                    ax1.plot(year_data['day_of_year'], year_data[column_name],
                           color=color, linewidth=2.5, label=f'üìÖ {year}',
                           alpha=0.8, zorder=3)
        
        # Ligne verticale moderne pour "aujourd'hui"
        ax1.axvline(x=current_day_of_year, color='#e74c3c', linestyle='--',
                  linewidth=3, alpha=0.9, zorder=10,
                  label=f"üìç Aujourd'hui (jour {current_day_of_year})")
        
        # Zone d'int√©r√™t moderne avec gradient
        highlight_start = max(1, current_day_of_year - 15)
        highlight_end = min(366, current_day_of_year + 15)
        ax1.axvspan(highlight_start, highlight_end, alpha=0.15, color='#e74c3c',
                  label='üîç P√©riode actuelle ¬±15j', zorder=1)
        
        # Titre moderne avec emojis
        ax1.set_title(f'{metric_info["emoji"]} Comparaison annuelle (courbe) - {metric_info["name"]} √† {VILLE}\n'
                    f'üìä Analyse de {len(available_years)} ann√©es de donn√©es (excl. ao√ªt 2023)',
                    fontsize=18, fontweight='bold', color='#2c3e50', pad=25)
        
        # Labels modernes avec emojis
        ax1.set_xlabel('üìÖ Jour de l\'ann√©e', fontsize=14, color='#2c3e50', fontweight='bold')
        ax1.set_ylabel(f'{metric_info["emoji"]} {metric_info["name"]} ({metric_info["unit"]})',
                     fontsize=14, color='#2c3e50', fontweight='bold')
        
        # Style moderne des axes
        ax1.spines['top'].set_visible(False)
        ax1.spines['right'].set_visible(False)
        ax1.spines['left'].set_color('#bdc3c7')
        ax1.spines['bottom'].set_color('#bdc3c7')
        ax1.tick_params(colors='#34495e', labelsize=11)
        
        # L√©gende moderne
        legend = ax1.legend(bbox_to_anchor=(1.02, 1), loc='upper left',
                          frameon=True, shadow=True, fancybox=True,
                          framealpha=0.95, edgecolor='#bdc3c7')
        legend.get_frame().set_facecolor('#ffffff')
        
        # Marques des mois sur l'axe X
        month_starts = [1, 32, 60, 91, 121, 152, 182, 213, 244, 274, 305, 335]
        month_names = ['Jan', 'F√©v', 'Mar', 'Avr', 'Mai', 'Jun',
                      'Jul', 'Ao√ª', 'Sep', 'Oct', 'Nov', 'D√©c']
        ax1.set_xticks(month_starts)
        ax1.set_xticklabels(month_names)
        
        plt.tight_layout()
        
        # Statistiques pour la p√©riode actuelle
        current_period_data = daily_means[
            (daily_means['day_of_year'] >= highlight_start) &
            (daily_means['day_of_year'] <= highlight_end)
        ]
        
        stats_by_year = {}
        for year in available_years:
            year_period = current_period_data[current_period_data['year'] == year]
            if not year_period.empty:
                stats_by_year[year] = year_period[column_name].mean()
        
        # Pr√©parer le texte des statistiques
        stats_text = f"üìä Moyennes pour la p√©riode actuelle (¬±15j):\n"
        for year, avg_val in sorted(stats_by_year.items()):
            marker = " üëà" if year == current_year else ""
            stats_text += f"{year}: {avg_val:.1f}{metric_info['unit']}{marker}\n"
        
        # Tendance g√©n√©rale
        if len(stats_by_year) >= 3:
            years_list = list(stats_by_year.keys())
            values_list = list(stats_by_year.values())
            
            # R√©gression lin√©aire simple
            if len(values_list) > 1:
                slope = (values_list[-1] - values_list[0]) / (years_list[-1] - years_list[0])
                trend = "‚ÜóÔ∏è hausse" if slope > 0 else "‚ÜòÔ∏è baisse" if slope < 0 else "‚û°Ô∏è stable"
                stats_text += f"\nüìà Tendance g√©n√©rale: {trend} ({slope:.2f}{metric_info['unit']}/an)"
        
        base_caption = (f"{metric_info['emoji']} Comparaison {metric_info['name']} - {len(available_years)} ann√©es\n"
                       f"üìÖ Ann√©es: {min(available_years)}-{max(available_years)} (excl. ao√ªt 2023)\n"
                       f"{stats_text}")
        
        # Envoyer le premier graphique (courbe)
        caption1 = f"üìä Comparaison annuelle (courbe)\n{base_caption}"
        await send_graph(message.chat.id, fig1, caption1)
        
        # === GRAPHIQUE 2: BARRES MENSUELLES PAR ANN√âE ===
        fig2, ax2 = plt.subplots(1, 1, figsize=(16, 10))
        fig2.patch.set_facecolor('#f8f9fa')
        
        # Calculer valeurs mensuelles selon le type de m√©trique
        if metric_arg in ['rain', 'precipitation']:
            monthly_data = df.groupby(['year', 'month'])[column_name].sum().reset_index()
        else:
            monthly_data = df.groupby(['year', 'month'])[column_name].mean().reset_index()
        
        if not monthly_data.empty:
            # Style barres : barres group√©es par ann√©e pour chaque mois
            available_years_bars = sorted(monthly_data['year'].unique())
            available_months = sorted(monthly_data['month'].unique())
            
            # Noms des mois
            month_names_bars = ['Jan', 'F√©v', 'Mar', 'Avr', 'Mai', 'Jun',
                      'Jul', 'Ao√ª', 'Sep', 'Oct', 'Nov', 'D√©c']
            
            # Couleurs pour les ann√©es (m√™mes que le premier graphique)
            year_colors = modern_colors[:len(available_years_bars)]
            
            # Cr√©er les barres group√©es
            x_positions = np.arange(len(available_months))
            n_years = len(available_years_bars)
            width = 0.8 / n_years
            
            for i, year in enumerate(available_years_bars):
                year_data = monthly_data[monthly_data['year'] == year]
                values = []
                
                for month in available_months:
                    month_row = year_data[year_data['month'] == month]
                    if not month_row.empty:
                        values.append(month_row[column_name].iloc[0])
                    else:
                        values.append(0)
                
                year_color = year_colors[i % len(year_colors)]
                offset = (i - n_years/2 + 0.5) * width
                
                # Style sp√©cial pour l'ann√©e courante
                if year == current_year:
                    bars = ax2.bar(x_positions + offset, values, width,
                                  label=f'üìç {year} (actuelle)', color=year_color,
                                  alpha=0.9, edgecolor='white', linewidth=2,
                                  zorder=5)
                    # Ajouter des valeurs sur les barres de l'ann√©e courante
                    for j, bar in enumerate(bars):
                        if values[j] > 0:
                            ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(values)*0.01,
                                   f'{values[j]:.0f}', ha='center', va='bottom',
                                   fontsize=9, fontweight='bold', color=year_color)
                else:
                    ax2.bar(x_positions + offset, values, width,
                           label=f'üìÖ {year}', color=year_color,
                           alpha=0.7, edgecolor='white', linewidth=1,
                           zorder=3)
            
            # Mise en √©vidence du mois actuel
            current_month = pd.Timestamp.now(tz='Europe/Berlin').month
            if current_month in available_months:
                month_idx = available_months.index(current_month)
                ax2.axvspan(month_idx - 0.4, month_idx + 0.4,
                           alpha=0.2, color='#f39c12', zorder=1,
                           label=f"üìç Mois actuel ({month_names_bars[current_month-1]})")
            
            # Configuration des axes pour style mensuel
            ax2.set_xticks(x_positions)
            ax2.set_xticklabels([month_names_bars[m-1] for m in available_months])
            ax2.set_title(f'üìä {metric_info["emoji"]} {metric_info["name"]} (barres mensuelles) - {len(available_years_bars)} ann√©es √† {VILLE}\n'
                         f'üìä Comparaison par mois (excl. ao√ªt 2023)',
                         fontsize=16, fontweight='bold', color='#2c3e50', pad=20)
            
            # L√©gende moderne
            legend = ax2.legend(bbox_to_anchor=(1.02, 1), loc='upper left',
                               frameon=True, shadow=True, fancybox=True,
                               framealpha=0.95, edgecolor='#bdc3c7')
            legend.get_frame().set_facecolor('#ffffff')
        
        # Style commun des axes
        ax2.set_ylabel(f'{metric_info["emoji"]} {metric_info["name"]} ({metric_info["unit"]})',
                      fontsize=14, color='#2c3e50', fontweight='bold')
        ax2.set_xlabel('üìÖ Mois', fontsize=14, color='#2c3e50', fontweight='bold')
        
        ax2.spines['top'].set_visible(False)
        ax2.spines['right'].set_visible(False)
        ax2.spines['left'].set_color('#bdc3c7')
        ax2.spines['bottom'].set_color('#bdc3c7')
        ax2.tick_params(colors='#34495e', labelsize=11)
        
        plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45, fontsize=10)
        ax2.grid(True, alpha=0.3, linestyle=':', linewidth=1, axis='y')
        plt.tight_layout()
        
        # Envoyer le deuxi√®me graphique (barres)
        caption2 = f"üìä Comparaison mensuelle (barres)\n{base_caption}"
        await send_graph(message.chat.id, fig2, caption2)
        
    except ValueError as e:
        await message.reply("Param√®tres invalides. V√©rifiez la syntaxe de la commande.")
    except Exception as e:
        await log_message(f"Erreur dans yearcompare_command: {str(e)}\n{traceback.format_exc()}")
        await message.reply("Erreur lors de la g√©n√©ration de la comparaison annuelle.")


# --- Fonction principale pour d√©marrer le bot ---
async def main():
    # Inclure le routeur principal dans le dispatcher
    dp.include_router(router)

    # Lancer la t√¢che de fond pour v√©rifier la m√©t√©o
    # Elle utilisera l'instance globale `bot` pour envoyer des messages
    asyncio.create_task(schedule_jobs())
    
    # D√©marrer le polling du bot
    # skip_updates=True est utile pour ignorer les mises √† jour re√ßues pendant que le bot √©tait hors ligne
    await log_message("Bot d√©marr√© et pr√™t √† recevoir les commandes.")
    await dp.start_polling(bot, skip_updates=True)


if __name__ == "__main__":
    # Configurer le logging de base pour voir les messages d'aiogram et les v√¥tres
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
    
    # Nettoyer le CSV au d√©marrage
    clean_csv_file()
    
    try:
        asyncio.run(main())
    except (KeyboardInterrupt, SystemExit):
        asyncio.run(log_message("Bot arr√™t√© manuellement.")) # Log l'arr√™t
        logging.info("Bot arr√™t√©.")
    except Exception as e:
        # Log l'erreur fatale qui a emp√™ch√© le bot de tourner
        asyncio.run(log_message(f"Erreur fatale au niveau principal du bot: {str(e)}\n{traceback.format_exc()}"))
        logging.critical(f"Erreur fatale: {e}", exc_info=True)